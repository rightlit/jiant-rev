{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "jiant-rev_koelectra_contest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85e4c2efc4fd471fb75cacc63e707310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d54f90f43c364807aae38c108f76616e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d883de7ee9e744899797ecb57232146e",
              "IPY_MODEL_a6224fdaebe9431c80710b18c14b336c",
              "IPY_MODEL_661035708dd34d518e748930c6b95faf"
            ]
          }
        },
        "d54f90f43c364807aae38c108f76616e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d883de7ee9e744899797ecb57232146e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3ad9b7cfcd84e81ab6c7ee769bebfb7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11f4d2e00fef4c988b15554cc577449d"
          }
        },
        "a6224fdaebe9431c80710b18c14b336c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08b273ad5f6e478caeff5d0a0f87a10d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28a0572d6f124d03bcfbd3d24481c8bb"
          }
        },
        "661035708dd34d518e748930c6b95faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf4e842d74c84bd8943d784728708028",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 105.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fd73341db914520b2f167d9a85ab908"
          }
        },
        "a3ad9b7cfcd84e81ab6c7ee769bebfb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11f4d2e00fef4c988b15554cc577449d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08b273ad5f6e478caeff5d0a0f87a10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28a0572d6f124d03bcfbd3d24481c8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf4e842d74c84bd8943d784728708028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fd73341db914520b2f167d9a85ab908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ffe67d9a9284ab08d434fe05a2b23d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5dd4085b405a46818acaa9f02b960486",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9db98dd5b1c4eb495cfa393596e84f6",
              "IPY_MODEL_991a3104b6e24c22afa7cfe45d09aa3d",
              "IPY_MODEL_ec6b06b5930047008ab09bf08fe11ff3"
            ]
          }
        },
        "5dd4085b405a46818acaa9f02b960486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9db98dd5b1c4eb495cfa393596e84f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ec06c30f0e54df388882f9052e7cef1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74af5f1d4c7644d69b139ddda586b17d"
          }
        },
        "991a3104b6e24c22afa7cfe45d09aa3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4bf000d38ba946b6a093863ec07208c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8ada40d507a46f1b1be50a5748e65f7"
          }
        },
        "ec6b06b5930047008ab09bf08fe11ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad1a36a29b924055b59ac4c152ebdff7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 42.86it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9751812dd8c4400fba1b1faa64ab36e3"
          }
        },
        "6ec06c30f0e54df388882f9052e7cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74af5f1d4c7644d69b139ddda586b17d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bf000d38ba946b6a093863ec07208c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8ada40d507a46f1b1be50a5748e65f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad1a36a29b924055b59ac4c152ebdff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9751812dd8c4400fba1b1faa64ab36e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fe210a0f74244459d2f22e360f4fe64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9aa3cb6b4e841ee96655846cee41dbb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0440ae61af94398823042c83c17e649",
              "IPY_MODEL_2e55ab982c9b4397bab48cc7e0f8603a",
              "IPY_MODEL_af5327b93d484cc8802c756c9ce5b728"
            ]
          }
        },
        "f9aa3cb6b4e841ee96655846cee41dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0440ae61af94398823042c83c17e649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4fbda6181cc467c895ae4f924594a99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a439fd5285a459a88efe98a12b86804"
          }
        },
        "2e55ab982c9b4397bab48cc7e0f8603a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b17f10af910b4a76bb2548bf6691827f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6c87b84ddd44c99aa22e64d87065b80"
          }
        },
        "af5327b93d484cc8802c756c9ce5b728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_059e33a8aa824446969e5b4b69d7d047",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 84.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d83440570601462da09abc6bcd38f659"
          }
        },
        "a4fbda6181cc467c895ae4f924594a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a439fd5285a459a88efe98a12b86804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b17f10af910b4a76bb2548bf6691827f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6c87b84ddd44c99aa22e64d87065b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "059e33a8aa824446969e5b4b69d7d047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d83440570601462da09abc6bcd38f659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46b0e49afe7a450691b7bb5dc849023d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_843c5c857b2d4838befc3f0af86363bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5684b951d464ccfbc39b79fc213c940",
              "IPY_MODEL_9d7357a9a0544906a7b7eac8c4afe82b",
              "IPY_MODEL_44101d5d93114d5f9a38873826749ce5"
            ]
          }
        },
        "843c5c857b2d4838befc3f0af86363bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5684b951d464ccfbc39b79fc213c940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_460a9894b2d34c209d8d4f2165e42d5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abf80cc9d97440a79cf9245eecd68e83"
          }
        },
        "9d7357a9a0544906a7b7eac8c4afe82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_309296b743944afaaeefc50c8eecc3e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2137f72b84443a9bdeb3bb65ed7ea30"
          }
        },
        "44101d5d93114d5f9a38873826749ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9ec09ba8c344630b2505abae80e514c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 467/467 [00:00&lt;00:00, 11.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e60435003e77472caac71400f0d70ce7"
          }
        },
        "460a9894b2d34c209d8d4f2165e42d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abf80cc9d97440a79cf9245eecd68e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "309296b743944afaaeefc50c8eecc3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2137f72b84443a9bdeb3bb65ed7ea30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9ec09ba8c344630b2505abae80e514c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e60435003e77472caac71400f0d70ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f393a248d7fc49e09b72d3334f2edc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e6ae33dae01483cbb3c924c6ccefed7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8b5bd5b04ff4bd1bb07c47cfdb0aaeb",
              "IPY_MODEL_24a3e0d4c9344ba9be4555cc769fd016",
              "IPY_MODEL_f6a9708d1cd44e4db072503061917a16"
            ]
          }
        },
        "9e6ae33dae01483cbb3c924c6ccefed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8b5bd5b04ff4bd1bb07c47cfdb0aaeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ff4295a7b5348c4889b0ae679374e5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a5bdffae9284de8b29fb62482655529"
          }
        },
        "24a3e0d4c9344ba9be4555cc769fd016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0cb17a764d794f8eaf10ef840841d537",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 451741507,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 451741507,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_685ff556259e424e8a1c6d9f0bfd9ce1"
          }
        },
        "f6a9708d1cd44e4db072503061917a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98d11d229e87458c8c5c27c3f24d3744",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 431M/431M [00:08&lt;00:00, 50.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c717f56bef64ede9aafa74b09e4a9f8"
          }
        },
        "2ff4295a7b5348c4889b0ae679374e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a5bdffae9284de8b29fb62482655529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cb17a764d794f8eaf10ef840841d537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "685ff556259e424e8a1c6d9f0bfd9ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98d11d229e87458c8c5c27c3f24d3744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c717f56bef64ede9aafa74b09e4a9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "197326e00a964c3cb933bcf746659d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4a1156c503e44089877f3890bff665c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_234d5461e00c4735b83fe615dc3c32ce",
              "IPY_MODEL_e9c96da7b6b04695a927d7b6534121e6",
              "IPY_MODEL_ebf89451a98f41a68f6df40f7289b87f"
            ]
          }
        },
        "c4a1156c503e44089877f3890bff665c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "234d5461e00c4735b83fe615dc3c32ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8249ec88c14475bb8778668b27beb77",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c98261aac364149bc60120bd05fd0dd"
          }
        },
        "e9c96da7b6b04695a927d7b6534121e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e85227bb389042858789ff330cfa8d44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 61,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 61,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_680debbed533426d99cc5d99da23d089"
          }
        },
        "ebf89451a98f41a68f6df40f7289b87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eddc0b426a85452d8db03b5edfa25235",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 61.0/61.0 [00:00&lt;00:00, 1.68kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7dda5209f9f14b79b34a167df1faaba6"
          }
        },
        "a8249ec88c14475bb8778668b27beb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c98261aac364149bc60120bd05fd0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e85227bb389042858789ff330cfa8d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "680debbed533426d99cc5d99da23d089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eddc0b426a85452d8db03b5edfa25235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7dda5209f9f14b79b34a167df1faaba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88f4f7a09b6240d7af53156b675ae127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dedaa045488c448091e3c786b07c6abf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a58e7488b31446bbe74616c593c4a6b",
              "IPY_MODEL_680c7ac691414e3cabc611de71063603",
              "IPY_MODEL_a8cf5c6750e0430fa48867684f437f5f"
            ]
          }
        },
        "dedaa045488c448091e3c786b07c6abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a58e7488b31446bbe74616c593c4a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0862243b1d349f380dee644f76fef52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13d4f38cf0b34dc18a803e432bf714b7"
          }
        },
        "680c7ac691414e3cabc611de71063603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd538b927b11426bae6a824da2eba12a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 263326,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 263326,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d52dd9526294a9fbf31bd1c5ac9cdad"
          }
        },
        "a8cf5c6750e0430fa48867684f437f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58501b9437bf46fea049b548d1bccfa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 257k/257k [00:00&lt;00:00, 620kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ba8d723825f446092b1454a4c292576"
          }
        },
        "a0862243b1d349f380dee644f76fef52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13d4f38cf0b34dc18a803e432bf714b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd538b927b11426bae6a824da2eba12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d52dd9526294a9fbf31bd1c5ac9cdad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58501b9437bf46fea049b548d1bccfa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ba8d723825f446092b1454a4c292576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7002b3cdee947e991001287a0fc3a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7d6e6e658cb486aa910c733f2866a87",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4c03c5202914d3c878be8e158249404",
              "IPY_MODEL_f2dac1155f8546669e62c3200cc61862",
              "IPY_MODEL_50b8a5b77a6342bebead39e742b3865a"
            ]
          }
        },
        "e7d6e6e658cb486aa910c733f2866a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4c03c5202914d3c878be8e158249404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78233535532044c2870c1b8c9340b184",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Tokenizing: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b054bc4845f34f74be609c8e829f1be6"
          }
        },
        "f2dac1155f8546669e62c3200cc61862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2326dae7861c4b3ea5aa7209b5090c0b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 15876,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 15876,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a42c4d0b98ec46d981c0ca0a167e4954"
          }
        },
        "50b8a5b77a6342bebead39e742b3865a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_217c05c5effd402a938ac8612b05e093",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15876/15876 [00:05&lt;00:00, 3926.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46e0c69109304c77892dfe45777771de"
          }
        },
        "78233535532044c2870c1b8c9340b184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b054bc4845f34f74be609c8e829f1be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2326dae7861c4b3ea5aa7209b5090c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a42c4d0b98ec46d981c0ca0a167e4954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "217c05c5effd402a938ac8612b05e093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46e0c69109304c77892dfe45777771de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d64b6d98fa2400eb90208b6293df3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea80119db4f24c71aed54c6bbcc837ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72cf3a8a0c774dc3b222c74209e66a34",
              "IPY_MODEL_4c1e3cd7ba68494e94580a645f899736",
              "IPY_MODEL_250a2dacca1d484d92db9a9da8ead203"
            ]
          }
        },
        "ea80119db4f24c71aed54c6bbcc837ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72cf3a8a0c774dc3b222c74209e66a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_72f89021d79847d08854625f5c82aeaf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Smart truncate chunks: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bdfd235d59b45d596d444d4334d0473"
          }
        },
        "4c1e3cd7ba68494e94580a645f899736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_361eee20975244a6a029dd4d22c7bb38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e35968c49cc4acfb4e5b4fc4947dafc"
          }
        },
        "250a2dacca1d484d92db9a9da8ead203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67d75cbcf85b433c82154f98d4c1360b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:02&lt;00:00,  1.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cb5ba619f3d4e5cb6401193c82ca75e"
          }
        },
        "72f89021d79847d08854625f5c82aeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bdfd235d59b45d596d444d4334d0473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "361eee20975244a6a029dd4d22c7bb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e35968c49cc4acfb4e5b4fc4947dafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67d75cbcf85b433c82154f98d4c1360b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cb5ba619f3d4e5cb6401193c82ca75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1c9e17b1d51448ba0acfd69cdded3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb33ba6bf2004ba78123c8dfa5f21e94",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_caa19058d0fc480dbca5a6aac64bbfa4",
              "IPY_MODEL_4d0d6e3617a348dfa03e350f3f83b996",
              "IPY_MODEL_bbb3dacdf35d46e5970dbe182740a9f5"
            ]
          }
        },
        "fb33ba6bf2004ba78123c8dfa5f21e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "caa19058d0fc480dbca5a6aac64bbfa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb6984f837c345ac9af90731b5f73acc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Smart truncate chunk-datum: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a0f995996ed4e2e8c952b4bcd95339c"
          }
        },
        "4d0d6e3617a348dfa03e350f3f83b996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3557c5ae48844d5dbbbb04b696cb4e80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bcf7ed2c55f4d35a37bc059b2a36a00"
          }
        },
        "bbb3dacdf35d46e5970dbe182740a9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d544e88d71384118a0adf27d76c596a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [00:00&lt;00:00, 33315.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5063368017e143cf877e4176ca2db829"
          }
        },
        "fb6984f837c345ac9af90731b5f73acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a0f995996ed4e2e8c952b4bcd95339c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3557c5ae48844d5dbbbb04b696cb4e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bcf7ed2c55f4d35a37bc059b2a36a00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d544e88d71384118a0adf27d76c596a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5063368017e143cf877e4176ca2db829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18889adc68994c4d8b85ac548d851cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_667f6856d5e648e1bcaa46f601974189",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4662fbec09042a4b123acb6231db72c",
              "IPY_MODEL_78698090ce1e446b972eb23354ea6ebc",
              "IPY_MODEL_7b70a8ee4903429d8aa5cde43eacf20c"
            ]
          }
        },
        "667f6856d5e648e1bcaa46f601974189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4662fbec09042a4b123acb6231db72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9d82ee0fd32484186c1fc22a00f5670",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Smart truncate chunk-datum: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ded07c34d364074a4ac8f77fb4e49f2"
          }
        },
        "78698090ce1e446b972eb23354ea6ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34ea1cb797294ac8845e3f1be0430541",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5876,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5876,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6f85b3e83a646f9998eb3411096707d"
          }
        },
        "7b70a8ee4903429d8aa5cde43eacf20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88d574eb1bd640afb879e284907bf757",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5876/5876 [00:00&lt;00:00, 39704.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_478104570762427599258c17aede6a9e"
          }
        },
        "b9d82ee0fd32484186c1fc22a00f5670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ded07c34d364074a4ac8f77fb4e49f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34ea1cb797294ac8845e3f1be0430541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6f85b3e83a646f9998eb3411096707d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88d574eb1bd640afb879e284907bf757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "478104570762427599258c17aede6a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9aa30ef67ef1497f9a4c34869ca16508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba6ec8a73a4045789f6b416b4b3808ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e961cffc7f1644049aa000164f8a1867",
              "IPY_MODEL_a6b8d0ec350b4a69922918f131729f10",
              "IPY_MODEL_a5dcda4f3c89477685488b7274d69b5c"
            ]
          }
        },
        "ba6ec8a73a4045789f6b416b4b3808ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e961cffc7f1644049aa000164f8a1867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee25c343d39340458c967bc470c5ca7f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Tokenizing: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9999990b07b4e67a9057c1a81eee667"
          }
        },
        "a6b8d0ec350b4a69922918f131729f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a7f9d3362854843ae35c7402e920dbf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2032,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2032,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91960118ad8944878817082ef9680e3b"
          }
        },
        "a5dcda4f3c89477685488b7274d69b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6dd5742b78df4054a5f150a28ea1ee4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2032/2032 [00:00&lt;00:00, 3565.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc40ad598d7543229b6a29c80baad090"
          }
        },
        "ee25c343d39340458c967bc470c5ca7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9999990b07b4e67a9057c1a81eee667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a7f9d3362854843ae35c7402e920dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91960118ad8944878817082ef9680e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dd5742b78df4054a5f150a28ea1ee4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc40ad598d7543229b6a29c80baad090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b89413b6f76f4df59c5232e9bad10703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d26771c67d549dfa56a061b5b30bc61",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc5d66625cd74bd68e6d27869b1a4f26",
              "IPY_MODEL_5231517d13c34a7aa3fd1c6df52e7c00",
              "IPY_MODEL_86b9e5c5dffa4101a884b0633e806661"
            ]
          }
        },
        "2d26771c67d549dfa56a061b5b30bc61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc5d66625cd74bd68e6d27869b1a4f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a139a29b43244b26aa3a103f0e46229e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Smart truncate chunks: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da837d51a526441d9469c8b6bdb51623"
          }
        },
        "5231517d13c34a7aa3fd1c6df52e7c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c5fb5cbdbe794711924e82def01ea714",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc7c79bb09ed4e0fba14f542a6572436"
          }
        },
        "86b9e5c5dffa4101a884b0633e806661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c71d763982b04d15b7086629b8e31265",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  1.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25f9e67735a04f30819c22ea4ee3170f"
          }
        },
        "a139a29b43244b26aa3a103f0e46229e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da837d51a526441d9469c8b6bdb51623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5fb5cbdbe794711924e82def01ea714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc7c79bb09ed4e0fba14f542a6572436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c71d763982b04d15b7086629b8e31265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25f9e67735a04f30819c22ea4ee3170f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e92966dabe3c4df4a72c9d39e1f00e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aca6df8d637942e093fd437655466046",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_184e2efefb254f8bb2e79877ff2affd9",
              "IPY_MODEL_efab0a3a937f41ad96ef5913c603a464",
              "IPY_MODEL_8d453bbb892b41c582dd902ec36a39f3"
            ]
          }
        },
        "aca6df8d637942e093fd437655466046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "184e2efefb254f8bb2e79877ff2affd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4828357ed95640e58a5b7b90229c3086",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Smart truncate chunk-datum: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd6adaecc983400d8a7ffe9c3eef2690"
          }
        },
        "efab0a3a937f41ad96ef5913c603a464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4efa133c568d40c5ad44289b7f24d7ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2032,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2032,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b93cceabf2a45679336f87c33c5a519"
          }
        },
        "8d453bbb892b41c582dd902ec36a39f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77fe0d1587e7401da97ae1cafda5a15f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2032/2032 [00:00&lt;00:00, 32140.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2deea611d78041b2b7a87f055bfaff2a"
          }
        },
        "4828357ed95640e58a5b7b90229c3086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd6adaecc983400d8a7ffe9c3eef2690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4efa133c568d40c5ad44289b7f24d7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b93cceabf2a45679336f87c33c5a519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77fe0d1587e7401da97ae1cafda5a15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2deea611d78041b2b7a87f055bfaff2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58c1ebe5168f46ac9f52925d8bf2909c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20936dbee8924e1fb10cca7191eb2df6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_599b00ce33784e9fa9dc62b13548fa58",
              "IPY_MODEL_786ec2e41b3e4fbf90843633100659be",
              "IPY_MODEL_2cbfaca82fba4f7da391749bb945ec9a"
            ]
          }
        },
        "20936dbee8924e1fb10cca7191eb2df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "599b00ce33784e9fa9dc62b13548fa58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73bca5956e3e414a969c8a626b6bdb40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Tokenizing: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff478242cc62404d8f7c5a16ede1702d"
          }
        },
        "786ec2e41b3e4fbf90843633100659be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10e2f0a6bf9347258de6e1cb8191de79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1060,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1060,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55cbdaa687c14ee58259d872cf555f61"
          }
        },
        "2cbfaca82fba4f7da391749bb945ec9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d11d95dc8e44b91a7dffb1782df06f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1060/1060 [00:00&lt;00:00, 3398.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b297498dd8a5463bb6f29201d3f160d7"
          }
        },
        "73bca5956e3e414a969c8a626b6bdb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff478242cc62404d8f7c5a16ede1702d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10e2f0a6bf9347258de6e1cb8191de79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55cbdaa687c14ee58259d872cf555f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d11d95dc8e44b91a7dffb1782df06f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b297498dd8a5463bb6f29201d3f160d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "324f3ae7be4c41f7ae9769f34ac0e8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_873ea504879e45ef849d03091b7b77b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_17fd9b6b3db242c1b3ff2623d9a4f449",
              "IPY_MODEL_6ac231c31be54d65ad60c006aa4da6aa",
              "IPY_MODEL_3de04ee2611c44e0bbdaace6bdac90cf"
            ]
          }
        },
        "873ea504879e45ef849d03091b7b77b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17fd9b6b3db242c1b3ff2623d9a4f449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cebfd04cb4e648da94ff53633a275ef4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Smart truncate chunks: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00cafa1d71274e10a4e6ccc9c57fc774"
          }
        },
        "6ac231c31be54d65ad60c006aa4da6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_93787a4159374bb7859f091dd870d97b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_517ad1d6c8884ab99fb40dc501871fa0"
          }
        },
        "3de04ee2611c44e0bbdaace6bdac90cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8970887ae6004b57bc03a707acb660f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  4.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2308595da6b470ba5a0a66762acbd52"
          }
        },
        "cebfd04cb4e648da94ff53633a275ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00cafa1d71274e10a4e6ccc9c57fc774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93787a4159374bb7859f091dd870d97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "517ad1d6c8884ab99fb40dc501871fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8970887ae6004b57bc03a707acb660f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2308595da6b470ba5a0a66762acbd52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ace0c7cf79b746f58fe8cb995cbf3385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f0696ecf049e400d90098925a172972f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ff8678f04904f28b4b5be20c787ea92",
              "IPY_MODEL_b009124420c44a1f9dc3141946b3d314",
              "IPY_MODEL_56d2ccb07dad44f79adb79a1d78a6ba5"
            ]
          }
        },
        "f0696ecf049e400d90098925a172972f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ff8678f04904f28b4b5be20c787ea92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c951ff90d254343a353102930e1e16c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Smart truncate chunk-datum: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40a779cbea9b48108b609e530b7d9d39"
          }
        },
        "b009124420c44a1f9dc3141946b3d314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_708c9c91b8334fb3a58d5fcb7293fd6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1060,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1060,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48dbdca4dc3046d281d9caf63e76e8b8"
          }
        },
        "56d2ccb07dad44f79adb79a1d78a6ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16b0106d33a84aff8581ca0273b361d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1060/1060 [00:00&lt;00:00, 18535.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8d93d51622d41d5be76f6bdc10ce6f3"
          }
        },
        "7c951ff90d254343a353102930e1e16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40a779cbea9b48108b609e530b7d9d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "708c9c91b8334fb3a58d5fcb7293fd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48dbdca4dc3046d281d9caf63e76e8b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16b0106d33a84aff8581ca0273b361d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8d93d51622d41d5be76f6bdc10ce6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5cb873b3200400e8efd023e45a4a003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38e0bec7d3864a11be181cb731c5ac40",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b929774456b843febdc2128fd846e99f",
              "IPY_MODEL_5f2d3193b394403d8a12698f3452481e",
              "IPY_MODEL_b4c3d40ab4684a7b9a5f5c01584da9a1"
            ]
          }
        },
        "38e0bec7d3864a11be181cb731c5ac40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b929774456b843febdc2128fd846e99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c572a92209d48a4a9485a118d2412c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Training: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abb975db8edb42b19e49b3b5a4249da9"
          }
        },
        "5f2d3193b394403d8a12698f3452481e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8180f7f9861411aa6701decea3a7a29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2979,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2978,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6ef62c6c6494c61a479fed01e13ed5b"
          }
        },
        "b4c3d40ab4684a7b9a5f5c01584da9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c13ebb950a2425687c6c56e58569833",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2978/2979 [04:52&lt;00:00, 10.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4676008ef0414d2f87c6776f7e72517f"
          }
        },
        "6c572a92209d48a4a9485a118d2412c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abb975db8edb42b19e49b3b5a4249da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8180f7f9861411aa6701decea3a7a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6ef62c6c6494c61a479fed01e13ed5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c13ebb950a2425687c6c56e58569833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4676008ef0414d2f87c6776f7e72517f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "052651329b984dc88c13beb3547873e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_478292a1c8814249b3f12fc5b452fe8a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_806dce365e254e1cb0265af34637a788",
              "IPY_MODEL_7386338b23f4409e95216c23e827af60",
              "IPY_MODEL_c9f1b86128b9458fa559501722ab7905"
            ]
          }
        },
        "478292a1c8814249b3f12fc5b452fe8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "806dce365e254e1cb0265af34637a788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0b785ced6cc4da2b7fe6283594b25a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Eval (cola, Val): 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97cced03e2c14e36a46f8b9f01c907e9"
          }
        },
        "7386338b23f4409e95216c23e827af60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25ef67d4851c42fea74fb6b12f1a3802",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8659b8330588400780fe975cef42989f"
          }
        },
        "c9f1b86128b9458fa559501722ab7905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e349b3e4a6b458f81b7c86646432da5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [00:00&lt;00:00, 24.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15f9808728bd434994719106bea1643b"
          }
        },
        "e0b785ced6cc4da2b7fe6283594b25a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97cced03e2c14e36a46f8b9f01c907e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25ef67d4851c42fea74fb6b12f1a3802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8659b8330588400780fe975cef42989f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e349b3e4a6b458f81b7c86646432da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15f9808728bd434994719106bea1643b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d1c8044297c4921a7dbd96ef5ab4289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a71deade8994304b85946a00149214e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_669ea8d7841e4edcaf6f1dcc9730c445",
              "IPY_MODEL_5700bc8b6fdd4626812167663035f61b",
              "IPY_MODEL_c0b9896ebc924b63ba637841e024cb1c"
            ]
          }
        },
        "6a71deade8994304b85946a00149214e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "669ea8d7841e4edcaf6f1dcc9730c445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c40491a3beb41d2a58d61a9b2fed704",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Eval (cola, Val): 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b21e7982dc349a08fdb158ecf347122"
          }
        },
        "5700bc8b6fdd4626812167663035f61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c046602b1b644dfbc7a8242176b02d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb748996fb314f1099fa5bb314c7db68"
          }
        },
        "c0b9896ebc924b63ba637841e024cb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c77dbc6ce204dc2b3f321e11167c87d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [00:00&lt;00:00, 21.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e75f63fbe9c4ffab81bf3bc353b2fcd"
          }
        },
        "9c40491a3beb41d2a58d61a9b2fed704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b21e7982dc349a08fdb158ecf347122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c046602b1b644dfbc7a8242176b02d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb748996fb314f1099fa5bb314c7db68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c77dbc6ce204dc2b3f321e11167c87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e75f63fbe9c4ffab81bf3bc353b2fcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61c1e07e545040ae861c1c4b40a6dd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02aa1fac8cf74c5c8426256b6ae887ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3134b8748f4c46a29671a40ab480e6bc",
              "IPY_MODEL_a50fb64733ce4528bb07735624d708b6",
              "IPY_MODEL_1348b00089764ebd84b45d2fa7f8807e"
            ]
          }
        },
        "02aa1fac8cf74c5c8426256b6ae887ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3134b8748f4c46a29671a40ab480e6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_695405fe5ddf4212a31f2536dbe06854",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Eval (cola, Val): 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38b43adf17774f9d9dbfba90793ba6fc"
          }
        },
        "a50fb64733ce4528bb07735624d708b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5315b02e9163427ba0d6123127ac1d6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 64,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 64,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ada011895a854ecd81183a38659b0e7e"
          }
        },
        "1348b00089764ebd84b45d2fa7f8807e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a15c965512447698ae576a104141ea4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 64/64 [00:02&lt;00:00, 28.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92b8fa1177fe4ee2b535bc9f59ef2493"
          }
        },
        "695405fe5ddf4212a31f2536dbe06854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38b43adf17774f9d9dbfba90793ba6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5315b02e9163427ba0d6123127ac1d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ada011895a854ecd81183a38659b0e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a15c965512447698ae576a104141ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92b8fa1177fe4ee2b535bc9f59ef2493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df7ba33203af4abd950c5c67bb864d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_386d839ff7754ae7b2f10b1724c67408",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0eb7e7c90f2406a8859c49e54cb1a23",
              "IPY_MODEL_27458477ea1949d7afee54b0ae55251c",
              "IPY_MODEL_5b3c90228fb64c1f801c9d5b1c0ba6e3"
            ]
          }
        },
        "386d839ff7754ae7b2f10b1724c67408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0eb7e7c90f2406a8859c49e54cb1a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6b09b5e91cdb4c27a2173f91277636a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Eval (cola, Test): 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ceec554a54b645ccba8c01ab52e85b83"
          }
        },
        "27458477ea1949d7afee54b0ae55251c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e574c5c2f1e640b6ad804ce225051a2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 34,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 34,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bc23ddd8b714be3a984ecafba08084f"
          }
        },
        "5b3c90228fb64c1f801c9d5b1c0ba6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc21584bf6f34d638579386a07a6805f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 34/34 [00:01&lt;00:00, 28.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fa3b910e81a49b38213a7263dcffa53"
          }
        },
        "6b09b5e91cdb4c27a2173f91277636a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ceec554a54b645ccba8c01ab52e85b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e574c5c2f1e640b6ad804ce225051a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bc23ddd8b714be3a984ecafba08084f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc21584bf6f34d638579386a07a6805f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fa3b910e81a49b38213a7263dcffa53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1DooSPRjKmN",
        "outputId": "533bb5c3-005b-4c26-ef79-c6db4a6f0504"
      },
      "source": [
        "# jiant toolkit\n",
        "!git clone https://github.com/rightlit/jiant-rev.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'jiant-rev'...\n",
            "remote: Enumerating objects: 1617, done.\u001b[K\n",
            "remote: Counting objects: 100% (1617/1617), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1229/1229), done.\u001b[K\n",
            "remote: Total 1617 (delta 1068), reused 781 (delta 384), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1617/1617), 2.93 MiB | 13.16 MiB/s, done.\n",
            "Resolving deltas: 100% (1068/1068), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NihL2F9XjV1N"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/jiant-rev')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYhgFbI2jZWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154c8f8a-af9e-433b-b4e4-680c33a56d72"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting attrs==19.3.0\n",
            "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements-no-torch.txt (line 2)) (0.0.1)\n",
            "Collecting jsonnet==0.15.0\n",
            "  Downloading jsonnet-0.15.0.tar.gz (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 17.0 MB/s \n",
            "\u001b[?25hCollecting lxml==4.6.3\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 35.7 MB/s \n",
            "\u001b[?25hCollecting datasets==1.15.1\n",
            "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
            "\u001b[K     |████████████████████████████████| 290 kB 43.3 MB/s \n",
            "\u001b[?25hCollecting nltk>=3.5\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 37.1 MB/s \n",
            "\u001b[?25hCollecting numexpr==2.7.1\n",
            "  Downloading numexpr-2.7.1-cp37-cp37m-manylinux1_x86_64.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 20.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements-no-torch.txt (line 10)) (1.19.5)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements-no-torch.txt (line 12)) (1.1.5)\n",
            "Collecting Levenshtein==0.16.0\n",
            "  Downloading Levenshtein-0.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 46.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.43\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[K     |████████████████████████████████| 883 kB 44.2 MB/s \n",
            "\u001b[?25hCollecting seqeval==1.2.2\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from -r requirements-no-torch.txt (line 18)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements-no-torch.txt (line 19)) (1.4.1)\n",
            "Collecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 29.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.10.1\n",
            "  Downloading tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 42.0 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.62.1\n",
            "  Downloading tqdm-4.62.1-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting transformers==4.12.3\n",
            "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.10.0+cu111)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4==0.0.1->-r requirements-no-torch.txt (line 2)) (4.6.3)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (0.70.12.2)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (3.0.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 31.7 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (2.23.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.1-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (4.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements-no-torch.txt (line 12)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements-no-torch.txt (line 12)) (2.8.2)\n",
            "Collecting rapidfuzz<1.9,>=1.8.2\n",
            "  Downloading rapidfuzz-1.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.43->-r requirements-no-torch.txt (line 15)) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.43->-r requirements-no-torch.txt (line 15)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.43->-r requirements-no-torch.txt (line 15)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.43->-r requirements-no-torch.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.3->-r requirements-no-torch.txt (line 25)) (3.3.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->-r requirements.txt (line 3)) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Collecting regex\n",
            "  Downloading regex-2021.11.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (2.10)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.0-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (2.0.7)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 53.0 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.15.1->-r requirements-no-torch.txt (line 6)) (3.6.0)\n",
            "Building wheels for collected packages: jsonnet, sacremoses, seqeval\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.15.0-cp37-cp37m-linux_x86_64.whl size=3320452 sha256=16db7897dff13539a2baf9e180a6ce1326afd7808723ce3a6fa090e23ce1cd77\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/01/e4/6fabcb0c191f51e98452f2af6cb2086f0f1cec94a2c0ce9948\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893250 sha256=30ba339d7df7468fc3a55b4afc89715db0810af2959b40e7a648e7a5cb028bf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=1ed1feab588c85edd39fbedbbc7933ad0e7bc0ab46cf57be0f501ec6ce45a7e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built jsonnet sacremoses seqeval\n",
            "Installing collected packages: multidict, frozenlist, yarl, attrs, asynctest, async-timeout, aiosignal, tqdm, regex, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, rapidfuzz, huggingface-hub, transformers, seqeval, sentencepiece, numexpr, nltk, lxml, Levenshtein, jsonnet, datasets\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: numexpr\n",
            "    Found existing installation: numexpr 2.7.3\n",
            "    Uninstalling numexpr-2.7.3:\n",
            "      Successfully uninstalled numexpr-2.7.3\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Levenshtein-0.16.0 aiohttp-3.8.0 aiosignal-1.2.0 async-timeout-4.0.0 asynctest-0.13.0 attrs-19.3.0 datasets-1.15.1 frozenlist-1.2.0 fsspec-2021.11.0 huggingface-hub-0.1.1 jsonnet-0.15.0 lxml-4.6.3 multidict-5.2.0 nltk-3.6.5 numexpr-2.7.1 pyyaml-6.0 rapidfuzz-1.8.2 regex-2021.11.2 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-1.2.2 tokenizers-0.10.1 tqdm-4.62.1 transformers-4.12.3 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1B2CgKooaXy",
        "outputId": "a1f06435-c398-4c95-f8e8-0a9141680884"
      },
      "source": [
        "!pip list | egrep \"torch|transformers|seqeval|datasets\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets                      1.15.1\n",
            "seqeval                       1.2.2\n",
            "tensorflow-datasets           4.0.1\n",
            "torch                         1.9.0+cu111\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.10.0\n",
            "torchvision                   0.10.0+cu111\n",
            "transformers                  4.12.3\n",
            "vega-datasets                 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIGyc0Bu-0A6",
        "outputId": "3762353b-4bd3-4024-b0bb-4227e7303630"
      },
      "source": [
        "!ls -l ./dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 7048\n",
            "-rw-r--r-- 1 root root  124962 Nov  7 08:14 NIKL_CoLA_dev.tsv\n",
            "-rw-r--r-- 1 root root   60057 Nov  7 08:14 NIKL_CoLA_test.tsv\n",
            "-rw-r--r-- 1 root root  928523 Nov  7 08:14 NIKL_CoLA_train.tsv\n",
            "-rw-r--r-- 1 root root  326142 Nov  7 08:14 NIKL_SKT_WiC_Dev.tsv\n",
            "-rw-r--r-- 1 root root  321235 Nov  7 08:14 NIKL_SKT_WiC_Test.tsv\n",
            "-rw-r--r-- 1 root root 2298421 Nov  7 08:14 NIKL_SKT_WiC_Train.tsv\n",
            "-rw-r--r-- 1 root root  360774 Nov  7 08:14 SKT_BoolQ_Dev.tsv\n",
            "-rw-r--r-- 1 root root  360833 Nov  7 08:14 SKT_BoolQ_Test.tsv\n",
            "-rw-r--r-- 1 root root 1930097 Nov  7 08:14 SKT_BoolQ_Train.tsv\n",
            "-rw-r--r-- 1 root root   58368 Nov  7 08:14 SKT_COPA_Dev.tsv\n",
            "-rw-r--r-- 1 root root   58044 Nov  7 08:14 SKT_COPA_Test.tsv\n",
            "-rw-r--r-- 1 root root  359824 Nov  7 08:14 SKT_COPA_Train.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RViL-0O-dW1"
      },
      "source": [
        "!rm -rf ./exp/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVSi0JwR-e6n"
      },
      "source": [
        "!rm -rf /root/.cache/huggingface/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "85e4c2efc4fd471fb75cacc63e707310",
            "d54f90f43c364807aae38c108f76616e",
            "d883de7ee9e744899797ecb57232146e",
            "a6224fdaebe9431c80710b18c14b336c",
            "661035708dd34d518e748930c6b95faf",
            "a3ad9b7cfcd84e81ab6c7ee769bebfb7",
            "11f4d2e00fef4c988b15554cc577449d",
            "08b273ad5f6e478caeff5d0a0f87a10d",
            "28a0572d6f124d03bcfbd3d24481c8bb",
            "bf4e842d74c84bd8943d784728708028",
            "5fd73341db914520b2f167d9a85ab908",
            "0ffe67d9a9284ab08d434fe05a2b23d5",
            "5dd4085b405a46818acaa9f02b960486",
            "b9db98dd5b1c4eb495cfa393596e84f6",
            "991a3104b6e24c22afa7cfe45d09aa3d",
            "ec6b06b5930047008ab09bf08fe11ff3",
            "6ec06c30f0e54df388882f9052e7cef1",
            "74af5f1d4c7644d69b139ddda586b17d",
            "4bf000d38ba946b6a093863ec07208c8",
            "f8ada40d507a46f1b1be50a5748e65f7",
            "ad1a36a29b924055b59ac4c152ebdff7",
            "9751812dd8c4400fba1b1faa64ab36e3",
            "3fe210a0f74244459d2f22e360f4fe64",
            "f9aa3cb6b4e841ee96655846cee41dbb",
            "a0440ae61af94398823042c83c17e649",
            "2e55ab982c9b4397bab48cc7e0f8603a",
            "af5327b93d484cc8802c756c9ce5b728",
            "a4fbda6181cc467c895ae4f924594a99",
            "4a439fd5285a459a88efe98a12b86804",
            "b17f10af910b4a76bb2548bf6691827f",
            "d6c87b84ddd44c99aa22e64d87065b80",
            "059e33a8aa824446969e5b4b69d7d047",
            "d83440570601462da09abc6bcd38f659",
            "46b0e49afe7a450691b7bb5dc849023d",
            "843c5c857b2d4838befc3f0af86363bb",
            "b5684b951d464ccfbc39b79fc213c940",
            "9d7357a9a0544906a7b7eac8c4afe82b",
            "44101d5d93114d5f9a38873826749ce5",
            "460a9894b2d34c209d8d4f2165e42d5b",
            "abf80cc9d97440a79cf9245eecd68e83",
            "309296b743944afaaeefc50c8eecc3e7",
            "c2137f72b84443a9bdeb3bb65ed7ea30",
            "b9ec09ba8c344630b2505abae80e514c",
            "e60435003e77472caac71400f0d70ce7",
            "f393a248d7fc49e09b72d3334f2edc6a",
            "9e6ae33dae01483cbb3c924c6ccefed7",
            "c8b5bd5b04ff4bd1bb07c47cfdb0aaeb",
            "24a3e0d4c9344ba9be4555cc769fd016",
            "f6a9708d1cd44e4db072503061917a16",
            "2ff4295a7b5348c4889b0ae679374e5e",
            "6a5bdffae9284de8b29fb62482655529",
            "0cb17a764d794f8eaf10ef840841d537",
            "685ff556259e424e8a1c6d9f0bfd9ce1",
            "98d11d229e87458c8c5c27c3f24d3744",
            "0c717f56bef64ede9aafa74b09e4a9f8",
            "197326e00a964c3cb933bcf746659d38",
            "c4a1156c503e44089877f3890bff665c",
            "234d5461e00c4735b83fe615dc3c32ce",
            "e9c96da7b6b04695a927d7b6534121e6",
            "ebf89451a98f41a68f6df40f7289b87f",
            "a8249ec88c14475bb8778668b27beb77",
            "0c98261aac364149bc60120bd05fd0dd",
            "e85227bb389042858789ff330cfa8d44",
            "680debbed533426d99cc5d99da23d089",
            "eddc0b426a85452d8db03b5edfa25235",
            "7dda5209f9f14b79b34a167df1faaba6",
            "88f4f7a09b6240d7af53156b675ae127",
            "dedaa045488c448091e3c786b07c6abf",
            "7a58e7488b31446bbe74616c593c4a6b",
            "680c7ac691414e3cabc611de71063603",
            "a8cf5c6750e0430fa48867684f437f5f",
            "a0862243b1d349f380dee644f76fef52",
            "13d4f38cf0b34dc18a803e432bf714b7",
            "cd538b927b11426bae6a824da2eba12a",
            "6d52dd9526294a9fbf31bd1c5ac9cdad",
            "58501b9437bf46fea049b548d1bccfa6",
            "0ba8d723825f446092b1454a4c292576",
            "e7002b3cdee947e991001287a0fc3a3e",
            "e7d6e6e658cb486aa910c733f2866a87",
            "b4c03c5202914d3c878be8e158249404",
            "f2dac1155f8546669e62c3200cc61862",
            "50b8a5b77a6342bebead39e742b3865a",
            "78233535532044c2870c1b8c9340b184",
            "b054bc4845f34f74be609c8e829f1be6",
            "2326dae7861c4b3ea5aa7209b5090c0b",
            "a42c4d0b98ec46d981c0ca0a167e4954",
            "217c05c5effd402a938ac8612b05e093",
            "46e0c69109304c77892dfe45777771de",
            "0d64b6d98fa2400eb90208b6293df3c7",
            "ea80119db4f24c71aed54c6bbcc837ce",
            "72cf3a8a0c774dc3b222c74209e66a34",
            "4c1e3cd7ba68494e94580a645f899736",
            "250a2dacca1d484d92db9a9da8ead203",
            "72f89021d79847d08854625f5c82aeaf",
            "4bdfd235d59b45d596d444d4334d0473",
            "361eee20975244a6a029dd4d22c7bb38",
            "7e35968c49cc4acfb4e5b4fc4947dafc",
            "67d75cbcf85b433c82154f98d4c1360b",
            "4cb5ba619f3d4e5cb6401193c82ca75e",
            "b1c9e17b1d51448ba0acfd69cdded3a7",
            "fb33ba6bf2004ba78123c8dfa5f21e94",
            "caa19058d0fc480dbca5a6aac64bbfa4",
            "4d0d6e3617a348dfa03e350f3f83b996",
            "bbb3dacdf35d46e5970dbe182740a9f5",
            "fb6984f837c345ac9af90731b5f73acc",
            "4a0f995996ed4e2e8c952b4bcd95339c",
            "3557c5ae48844d5dbbbb04b696cb4e80",
            "4bcf7ed2c55f4d35a37bc059b2a36a00",
            "d544e88d71384118a0adf27d76c596a6",
            "5063368017e143cf877e4176ca2db829",
            "18889adc68994c4d8b85ac548d851cf3",
            "667f6856d5e648e1bcaa46f601974189",
            "e4662fbec09042a4b123acb6231db72c",
            "78698090ce1e446b972eb23354ea6ebc",
            "7b70a8ee4903429d8aa5cde43eacf20c",
            "b9d82ee0fd32484186c1fc22a00f5670",
            "4ded07c34d364074a4ac8f77fb4e49f2",
            "34ea1cb797294ac8845e3f1be0430541",
            "d6f85b3e83a646f9998eb3411096707d",
            "88d574eb1bd640afb879e284907bf757",
            "478104570762427599258c17aede6a9e",
            "9aa30ef67ef1497f9a4c34869ca16508",
            "ba6ec8a73a4045789f6b416b4b3808ec",
            "e961cffc7f1644049aa000164f8a1867",
            "a6b8d0ec350b4a69922918f131729f10",
            "a5dcda4f3c89477685488b7274d69b5c",
            "ee25c343d39340458c967bc470c5ca7f",
            "c9999990b07b4e67a9057c1a81eee667",
            "4a7f9d3362854843ae35c7402e920dbf",
            "91960118ad8944878817082ef9680e3b",
            "6dd5742b78df4054a5f150a28ea1ee4f",
            "cc40ad598d7543229b6a29c80baad090",
            "b89413b6f76f4df59c5232e9bad10703",
            "2d26771c67d549dfa56a061b5b30bc61",
            "fc5d66625cd74bd68e6d27869b1a4f26",
            "5231517d13c34a7aa3fd1c6df52e7c00",
            "86b9e5c5dffa4101a884b0633e806661",
            "a139a29b43244b26aa3a103f0e46229e",
            "da837d51a526441d9469c8b6bdb51623",
            "c5fb5cbdbe794711924e82def01ea714",
            "dc7c79bb09ed4e0fba14f542a6572436",
            "c71d763982b04d15b7086629b8e31265",
            "25f9e67735a04f30819c22ea4ee3170f",
            "e92966dabe3c4df4a72c9d39e1f00e76",
            "aca6df8d637942e093fd437655466046",
            "184e2efefb254f8bb2e79877ff2affd9",
            "efab0a3a937f41ad96ef5913c603a464",
            "8d453bbb892b41c582dd902ec36a39f3",
            "4828357ed95640e58a5b7b90229c3086",
            "fd6adaecc983400d8a7ffe9c3eef2690",
            "4efa133c568d40c5ad44289b7f24d7ac",
            "2b93cceabf2a45679336f87c33c5a519",
            "77fe0d1587e7401da97ae1cafda5a15f",
            "2deea611d78041b2b7a87f055bfaff2a",
            "58c1ebe5168f46ac9f52925d8bf2909c",
            "20936dbee8924e1fb10cca7191eb2df6",
            "599b00ce33784e9fa9dc62b13548fa58",
            "786ec2e41b3e4fbf90843633100659be",
            "2cbfaca82fba4f7da391749bb945ec9a",
            "73bca5956e3e414a969c8a626b6bdb40",
            "ff478242cc62404d8f7c5a16ede1702d",
            "10e2f0a6bf9347258de6e1cb8191de79",
            "55cbdaa687c14ee58259d872cf555f61",
            "4d11d95dc8e44b91a7dffb1782df06f6",
            "b297498dd8a5463bb6f29201d3f160d7",
            "324f3ae7be4c41f7ae9769f34ac0e8e2",
            "873ea504879e45ef849d03091b7b77b7",
            "17fd9b6b3db242c1b3ff2623d9a4f449",
            "6ac231c31be54d65ad60c006aa4da6aa",
            "3de04ee2611c44e0bbdaace6bdac90cf",
            "cebfd04cb4e648da94ff53633a275ef4",
            "00cafa1d71274e10a4e6ccc9c57fc774",
            "93787a4159374bb7859f091dd870d97b",
            "517ad1d6c8884ab99fb40dc501871fa0",
            "8970887ae6004b57bc03a707acb660f6",
            "d2308595da6b470ba5a0a66762acbd52",
            "ace0c7cf79b746f58fe8cb995cbf3385",
            "f0696ecf049e400d90098925a172972f",
            "2ff8678f04904f28b4b5be20c787ea92",
            "b009124420c44a1f9dc3141946b3d314",
            "56d2ccb07dad44f79adb79a1d78a6ba5",
            "7c951ff90d254343a353102930e1e16c",
            "40a779cbea9b48108b609e530b7d9d39",
            "708c9c91b8334fb3a58d5fcb7293fd6a",
            "48dbdca4dc3046d281d9caf63e76e8b8",
            "16b0106d33a84aff8581ca0273b361d5",
            "a8d93d51622d41d5be76f6bdc10ce6f3",
            "f5cb873b3200400e8efd023e45a4a003",
            "38e0bec7d3864a11be181cb731c5ac40",
            "b929774456b843febdc2128fd846e99f",
            "5f2d3193b394403d8a12698f3452481e",
            "b4c3d40ab4684a7b9a5f5c01584da9a1",
            "6c572a92209d48a4a9485a118d2412c9",
            "abb975db8edb42b19e49b3b5a4249da9",
            "d8180f7f9861411aa6701decea3a7a29",
            "e6ef62c6c6494c61a479fed01e13ed5b",
            "1c13ebb950a2425687c6c56e58569833",
            "4676008ef0414d2f87c6776f7e72517f",
            "052651329b984dc88c13beb3547873e4",
            "478292a1c8814249b3f12fc5b452fe8a",
            "806dce365e254e1cb0265af34637a788",
            "7386338b23f4409e95216c23e827af60",
            "c9f1b86128b9458fa559501722ab7905",
            "e0b785ced6cc4da2b7fe6283594b25a9",
            "97cced03e2c14e36a46f8b9f01c907e9",
            "25ef67d4851c42fea74fb6b12f1a3802",
            "8659b8330588400780fe975cef42989f",
            "4e349b3e4a6b458f81b7c86646432da5",
            "15f9808728bd434994719106bea1643b",
            "1d1c8044297c4921a7dbd96ef5ab4289",
            "6a71deade8994304b85946a00149214e",
            "669ea8d7841e4edcaf6f1dcc9730c445",
            "5700bc8b6fdd4626812167663035f61b",
            "c0b9896ebc924b63ba637841e024cb1c",
            "9c40491a3beb41d2a58d61a9b2fed704",
            "7b21e7982dc349a08fdb158ecf347122",
            "2c046602b1b644dfbc7a8242176b02d9",
            "cb748996fb314f1099fa5bb314c7db68",
            "7c77dbc6ce204dc2b3f321e11167c87d",
            "0e75f63fbe9c4ffab81bf3bc353b2fcd",
            "61c1e07e545040ae861c1c4b40a6dd3d",
            "02aa1fac8cf74c5c8426256b6ae887ba",
            "3134b8748f4c46a29671a40ab480e6bc",
            "a50fb64733ce4528bb07735624d708b6",
            "1348b00089764ebd84b45d2fa7f8807e",
            "695405fe5ddf4212a31f2536dbe06854",
            "38b43adf17774f9d9dbfba90793ba6fc",
            "5315b02e9163427ba0d6123127ac1d6a",
            "ada011895a854ecd81183a38659b0e7e",
            "6a15c965512447698ae576a104141ea4",
            "92b8fa1177fe4ee2b535bc9f59ef2493",
            "df7ba33203af4abd950c5c67bb864d78",
            "386d839ff7754ae7b2f10b1724c67408",
            "f0eb7e7c90f2406a8859c49e54cb1a23",
            "27458477ea1949d7afee54b0ae55251c",
            "5b3c90228fb64c1f801c9d5b1c0ba6e3",
            "6b09b5e91cdb4c27a2173f91277636a2",
            "ceec554a54b645ccba8c01ab52e85b83",
            "e574c5c2f1e640b6ad804ce225051a2a",
            "1bc23ddd8b714be3a984ecafba08084f",
            "fc21584bf6f34d638579386a07a6805f",
            "7fa3b910e81a49b38213a7263dcffa53"
          ]
        },
        "id": "sXMv3iNtiDjm",
        "outputId": "b00b6dbf-12fd-48e4-dd39-23810b08eec8"
      },
      "source": [
        "# write predictions to file (cola)\n",
        "from jiant.proj.simple import runscript as run\n",
        "import jiant.scripts.download_data.runscript as downloader\n",
        "\n",
        "#EXP_DIR = \"/content/jiant-rev/exp\"\n",
        "EXP_DIR = \"./exp\"\n",
        "\n",
        "# Download the Data\n",
        "downloader.download_data([\"cola\"], f\"{EXP_DIR}/tasks\")\n",
        "\n",
        "# Set up the arguments for the Simple API\n",
        "args = run.RunConfiguration(\n",
        "   run_name=\"simple\",\n",
        "   exp_dir=EXP_DIR,\n",
        "   data_dir=f\"{EXP_DIR}/tasks\",\n",
        "   hf_pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
        "   tasks=\"cola\",\n",
        "   train_batch_size=16,\n",
        "   num_train_epochs=3,\n",
        "   write_test_preds=True\n",
        ")\n",
        "\n",
        "# Run!\n",
        "run.run_simple(args)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### hf_datasets_tasks_download, task_name:  cola , task_data_path:  /content/jiant-rev/exp/tasks/data/cola\n",
            "##### load_dataset(), path= glue , name= cola\n",
            "##### is_ko_model :  True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-118ec628641350e6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-118ec628641350e6/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85e4c2efc4fd471fb75cacc63e707310",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ffe67d9a9284ab08d434fe05a2b23d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-118ec628641350e6/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fe210a0f74244459d2f22e360f4fe64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### replace_key(), phase: train old_key: sentence new_key: text\n",
            "##### replace_key(), phase: train old_key: sentence new_key: text\n",
            "##### replace_key(), phase: train old_key: sentence new_key: text\n",
            "##### replace_key(), phase: val old_key: sentence new_key: text\n",
            "##### replace_key(), phase: val old_key: sentence new_key: text\n",
            "##### replace_key(), phase: val old_key: sentence new_key: text\n",
            "##### replace_key(), phase: test old_key: sentence new_key: text\n",
            "##### replace_key(), phase: test old_key: sentence new_key: text\n",
            "##### replace_key(), phase: test old_key: sentence new_key: text\n",
            "Downloaded and generated configs for 'cola' (1/1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46b0e49afe7a450691b7bb5dc849023d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/467 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f393a248d7fc49e09b72d3334f2edc6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/431M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "197326e00a964c3cb933bcf746659d38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88f4f7a09b6240d7af53156b675ae127",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/257k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### run_simple(): Tokenizing Task 'cola' for phases 'train,val,test'\n",
            "ColaTask\n",
            "  [train]: /content/jiant-rev/exp/tasks/data/cola/train.jsonl\n",
            "  [val]: /content/jiant-rev/exp/tasks/data/cola/val.jsonl\n",
            "  [test]: /content/jiant-rev/exp/tasks/data/cola/test.jsonl\n",
            "##### AutoTokenizer.from_pretrained() #####\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7002b3cdee947e991001287a0fc3a3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tokenizing:   0%|          | 0/15876 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d64b6d98fa2400eb90208b6293df3c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Smart truncate chunks:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1c9e17b1d51448ba0acfd69cdded3a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Smart truncate chunk-datum:   0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18889adc68994c4d8b85ac548d851cf3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Smart truncate chunk-datum:   0%|          | 0/5876 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aa30ef67ef1497f9a4c34869ca16508",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tokenizing:   0%|          | 0/2032 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b89413b6f76f4df59c5232e9bad10703",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Smart truncate chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e92966dabe3c4df4a72c9d39e1f00e76",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Smart truncate chunk-datum:   0%|          | 0/2032 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58c1ebe5168f46ac9f52925d8bf2909c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tokenizing:   0%|          | 0/1060 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "324f3ae7be4c41f7ae9769f34ac0e8e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Smart truncate chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ace0c7cf79b746f58fe8cb995cbf3385",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Smart truncate chunk-datum:   0%|          | 0/1060 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running from start\n",
            "  jiant_task_container_config_path: ./exp/run_configs/simple_config.json\n",
            "  output_dir: ./exp/runs/simple\n",
            "  hf_pretrained_model_name_or_path: monologg/koelectra-base-v3-discriminator\n",
            "  model_path: ./exp/models/electra/model/model.p\n",
            "  model_config_path: ./exp/models/electra/model/config.json\n",
            "  model_load_mode: from_transformers\n",
            "  do_train: True\n",
            "  do_val: True\n",
            "  do_save: False\n",
            "  do_save_last: False\n",
            "  do_save_best: False\n",
            "  write_val_preds: False\n",
            "  write_test_preds: True\n",
            "  eval_every_steps: 0\n",
            "  save_every_steps: 0\n",
            "  save_checkpoint_every_steps: 0\n",
            "  no_improvements_for_n_evals: 0\n",
            "  keep_checkpoint_when_done: False\n",
            "  force_overwrite: False\n",
            "  seed: -1\n",
            "  learning_rate: 1e-05\n",
            "  adam_epsilon: 1e-08\n",
            "  max_grad_norm: 1.0\n",
            "  optimizer_type: adam\n",
            "  no_cuda: False\n",
            "  fp16: False\n",
            "  fp16_opt_level: O1\n",
            "  local_rank: -1\n",
            "  server_ip: \n",
            "  server_port: \n",
            "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Using seed: 3043836997\n",
            "{\n",
            "  \"jiant_task_container_config_path\": \"./exp/run_configs/simple_config.json\",\n",
            "  \"output_dir\": \"./exp/runs/simple\",\n",
            "  \"hf_pretrained_model_name_or_path\": \"monologg/koelectra-base-v3-discriminator\",\n",
            "  \"model_path\": \"./exp/models/electra/model/model.p\",\n",
            "  \"model_config_path\": \"./exp/models/electra/model/config.json\",\n",
            "  \"model_load_mode\": \"from_transformers\",\n",
            "  \"do_train\": true,\n",
            "  \"do_val\": true,\n",
            "  \"do_save\": false,\n",
            "  \"do_save_last\": false,\n",
            "  \"do_save_best\": false,\n",
            "  \"write_val_preds\": false,\n",
            "  \"write_test_preds\": true,\n",
            "  \"eval_every_steps\": 0,\n",
            "  \"save_every_steps\": 0,\n",
            "  \"save_checkpoint_every_steps\": 0,\n",
            "  \"no_improvements_for_n_evals\": 0,\n",
            "  \"keep_checkpoint_when_done\": false,\n",
            "  \"force_overwrite\": false,\n",
            "  \"seed\": 3043836997,\n",
            "  \"learning_rate\": 1e-05,\n",
            "  \"adam_epsilon\": 1e-08,\n",
            "  \"max_grad_norm\": 1.0,\n",
            "  \"optimizer_type\": \"adam\",\n",
            "  \"no_cuda\": false,\n",
            "  \"fp16\": false,\n",
            "  \"fp16_opt_level\": \"O1\",\n",
            "  \"local_rank\": -1,\n",
            "  \"server_ip\": \"\",\n",
            "  \"server_port\": \"\"\n",
            "}\n",
            "1\n",
            "Creating Tasks:\n",
            "    cola (ColaTask): ./exp/tasks/configs/cola_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### AutoTokenizer.from_pretrained() #####\n",
            "##### encoder_prefix: electra.\n",
            "##### k :  electra.embeddings.position_ids\n",
            "##### k :  electra.embeddings.word_embeddings.weight\n",
            "##### k :  electra.embeddings.position_embeddings.weight\n",
            "##### k :  electra.embeddings.token_type_embeddings.weight\n",
            "##### k :  electra.embeddings.LayerNorm.weight\n",
            "##### k :  electra.embeddings.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.bias\n",
            "##### k :  discriminator_predictions.dense.weight\n",
            "##### k :  discriminator_predictions.dense.bias\n",
            "##### k :  discriminator_predictions.dense_prediction.weight\n",
            "##### k :  discriminator_predictions.dense_prediction.bias\n",
            "No optimizer decay for:\n",
            "  encoder.embeddings.LayerNorm.weight\n",
            "  encoder.embeddings.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.attention.self.query.bias\n",
            "  encoder.encoder.layer.0.attention.self.key.bias\n",
            "  encoder.encoder.layer.0.attention.self.value.bias\n",
            "  encoder.encoder.layer.0.attention.output.dense.bias\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.intermediate.dense.bias\n",
            "  encoder.encoder.layer.0.output.dense.bias\n",
            "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.attention.self.query.bias\n",
            "  encoder.encoder.layer.1.attention.self.key.bias\n",
            "  encoder.encoder.layer.1.attention.self.value.bias\n",
            "  encoder.encoder.layer.1.attention.output.dense.bias\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.intermediate.dense.bias\n",
            "  encoder.encoder.layer.1.output.dense.bias\n",
            "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.attention.self.query.bias\n",
            "  encoder.encoder.layer.2.attention.self.key.bias\n",
            "  encoder.encoder.layer.2.attention.self.value.bias\n",
            "  encoder.encoder.layer.2.attention.output.dense.bias\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.intermediate.dense.bias\n",
            "  encoder.encoder.layer.2.output.dense.bias\n",
            "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.attention.self.query.bias\n",
            "  encoder.encoder.layer.3.attention.self.key.bias\n",
            "  encoder.encoder.layer.3.attention.self.value.bias\n",
            "  encoder.encoder.layer.3.attention.output.dense.bias\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.intermediate.dense.bias\n",
            "  encoder.encoder.layer.3.output.dense.bias\n",
            "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.attention.self.query.bias\n",
            "  encoder.encoder.layer.4.attention.self.key.bias\n",
            "  encoder.encoder.layer.4.attention.self.value.bias\n",
            "  encoder.encoder.layer.4.attention.output.dense.bias\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.intermediate.dense.bias\n",
            "  encoder.encoder.layer.4.output.dense.bias\n",
            "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.attention.self.query.bias\n",
            "  encoder.encoder.layer.5.attention.self.key.bias\n",
            "  encoder.encoder.layer.5.attention.self.value.bias\n",
            "  encoder.encoder.layer.5.attention.output.dense.bias\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.intermediate.dense.bias\n",
            "  encoder.encoder.layer.5.output.dense.bias\n",
            "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.attention.self.query.bias\n",
            "  encoder.encoder.layer.6.attention.self.key.bias\n",
            "  encoder.encoder.layer.6.attention.self.value.bias\n",
            "  encoder.encoder.layer.6.attention.output.dense.bias\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.intermediate.dense.bias\n",
            "  encoder.encoder.layer.6.output.dense.bias\n",
            "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.attention.self.query.bias\n",
            "  encoder.encoder.layer.7.attention.self.key.bias\n",
            "  encoder.encoder.layer.7.attention.self.value.bias\n",
            "  encoder.encoder.layer.7.attention.output.dense.bias\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.intermediate.dense.bias\n",
            "  encoder.encoder.layer.7.output.dense.bias\n",
            "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.attention.self.query.bias\n",
            "  encoder.encoder.layer.8.attention.self.key.bias\n",
            "  encoder.encoder.layer.8.attention.self.value.bias\n",
            "  encoder.encoder.layer.8.attention.output.dense.bias\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.intermediate.dense.bias\n",
            "  encoder.encoder.layer.8.output.dense.bias\n",
            "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.attention.self.query.bias\n",
            "  encoder.encoder.layer.9.attention.self.key.bias\n",
            "  encoder.encoder.layer.9.attention.self.value.bias\n",
            "  encoder.encoder.layer.9.attention.output.dense.bias\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.intermediate.dense.bias\n",
            "  encoder.encoder.layer.9.output.dense.bias\n",
            "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.attention.self.query.bias\n",
            "  encoder.encoder.layer.10.attention.self.key.bias\n",
            "  encoder.encoder.layer.10.attention.self.value.bias\n",
            "  encoder.encoder.layer.10.attention.output.dense.bias\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.intermediate.dense.bias\n",
            "  encoder.encoder.layer.10.output.dense.bias\n",
            "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.attention.self.query.bias\n",
            "  encoder.encoder.layer.11.attention.self.key.bias\n",
            "  encoder.encoder.layer.11.attention.self.value.bias\n",
            "  encoder.encoder.layer.11.attention.output.dense.bias\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.intermediate.dense.bias\n",
            "  encoder.encoder.layer.11.output.dense.bias\n",
            "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
            "  taskmodels_dict.cola.head.dense.bias\n",
            "  taskmodels_dict.cola.head.out_proj.bias\n",
            "Using AdamW\n",
            "##### do_train #####\n",
            "##### run_train_context() #####\n",
            "##### get_train_dataloader_dict() :  1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5cb873b3200400e8efd023e45a4a003",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training:   0%|          | 0/2979 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "052651329b984dc88c13beb3547873e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Eval (cola, Val):   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### k, v.shape :  encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140241181066752)\n",
            "##### k, v.shape :  encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140237795753984)\n",
            "##### k, v.shape :  encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140239928999936)\n",
            "##### k, v.shape :  encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140241181070848)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181488128)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181076992)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140239923445760)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181494272)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240464003072)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181497344)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240061202432)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181500416)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240089251840)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181503488)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181506560)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181509632)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238476279808)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181512704)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140237929971712)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181524992)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181528064)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181531136)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240228630528)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181534208)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238514552832)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181537280)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238516912128)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181540352)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240326492160)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181543424)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181546496)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181549568)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140237939408896)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181552640)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140237963526144)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181564928)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181568000)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181571072)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240328851456)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181574144)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237972963328)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181577216)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237975322624)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181580288)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237977681920)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181583360)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181586432)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181589504)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140237997080576)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181592576)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238006517760)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181604864)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181607936)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181611008)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237980041216)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181614080)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238030635008)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181617152)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238032994304)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181620224)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238035353600)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181623296)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181626368)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181629440)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238037712896)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181632512)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238064189440)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181644800)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181647872)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181650944)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238047150080)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181654016)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238073626624)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181657088)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238075985920)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181660160)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238078345216)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181663232)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181666304)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181669376)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238097743872)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181672448)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238107181056)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181684736)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181687808)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181690880)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238080704512)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181693952)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238131298304)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181697024)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238133657600)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181700096)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238136016896)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181703168)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181706240)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181709312)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238138376192)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181712384)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238164852736)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181724672)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181727744)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181730816)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238147813376)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181733888)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238174289920)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181736960)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238176649216)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181740032)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238179008512)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181743104)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181746176)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181749248)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238198407168)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181752320)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238207844352)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181764608)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181767680)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181770752)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238181367808)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181773824)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238231961600)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181776896)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238234320896)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181779968)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238236680192)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181783040)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181786112)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181789184)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238239039488)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181792256)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238265516032)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181804544)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181807616)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181810688)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238248476672)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181813760)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238274953216)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181816832)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238277312512)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181819904)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238279671808)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181822976)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181826048)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181829120)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238299070464)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181832192)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238308507648)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181844480)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181847552)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181850624)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238282031104)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181853696)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238332624896)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181856768)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238334984192)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181859840)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238337343488)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181862912)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181865984)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181869056)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238339702784)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181872128)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238366179328)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181884416)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181887488)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181890560)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238349139968)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181893632)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238375616512)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181896704)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238377975808)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181899776)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238380335104)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181902848)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181905920)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181908992)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238399733760)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181912064)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238409170944)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181924352)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181927424)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181930496)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238382694400)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181933568)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237728645120)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181936640)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237731004416)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181939712)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237733363712)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181942784)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181945856)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181948928)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140237735723008)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181952000)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140237695090688)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181964288)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181967360)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181970432)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140241181066752)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140237795753984)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140239928999936)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140241181070848)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181488128)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181076992)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140239923445760)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181494272)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240464003072)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181497344)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240061202432)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181500416)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240089251840)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181503488)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181506560)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181509632)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238476279808)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181512704)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140237929971712)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181524992)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181528064)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181531136)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240228630528)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181534208)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238514552832)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181537280)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238516912128)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181540352)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240326492160)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181543424)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181546496)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181549568)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140237939408896)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181552640)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140237963526144)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181564928)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181568000)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181571072)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140240328851456)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181574144)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237972963328)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181577216)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237975322624)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181580288)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237977681920)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181583360)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181586432)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181589504)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140237997080576)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181592576)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238006517760)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181604864)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181607936)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181611008)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237980041216)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181614080)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238030635008)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181617152)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238032994304)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181620224)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238035353600)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181623296)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181626368)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181629440)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238037712896)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181632512)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238064189440)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181644800)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181647872)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181650944)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238047150080)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181654016)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238073626624)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181657088)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238075985920)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181660160)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238078345216)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181663232)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181666304)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181669376)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238097743872)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181672448)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238107181056)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181684736)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181687808)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181690880)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238080704512)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181693952)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238131298304)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181697024)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238133657600)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181700096)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238136016896)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181703168)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181706240)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181709312)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238138376192)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181712384)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238164852736)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181724672)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181727744)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181730816)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238147813376)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181733888)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238174289920)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181736960)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238176649216)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181740032)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238179008512)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181743104)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181746176)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181749248)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238198407168)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181752320)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238207844352)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181764608)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181767680)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181770752)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238181367808)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181773824)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238231961600)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181776896)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238234320896)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181779968)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238236680192)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181783040)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181786112)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181789184)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238239039488)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181792256)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238265516032)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181804544)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181807616)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181810688)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238248476672)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181813760)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238274953216)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181816832)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238277312512)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181819904)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238279671808)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181822976)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181826048)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181829120)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238299070464)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181832192)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238308507648)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181844480)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181847552)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181850624)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238282031104)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181853696)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238332624896)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181856768)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238334984192)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181859840)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238337343488)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181862912)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181865984)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181869056)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238339702784)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181872128)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238366179328)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181884416)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181887488)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181890560)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238349139968)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181893632)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238375616512)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181896704)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238377975808)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181899776)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238380335104)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181902848)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181905920)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181908992)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140238399733760)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181912064)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140238409170944)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181924352)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181927424)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181930496)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140238382694400)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181933568)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237728645120)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181936640)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237731004416)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181939712)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237733363712)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181942784)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181945856)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181948928)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140237735723008)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140241181952000)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140237695090688)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181964288)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181967360)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181970432)\n",
            "##### k, v.shape :  taskmodels_dict.cola.head.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140237745160192)\n",
            "##### k, v.shape :  taskmodels_dict.cola.head.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140241181973504)\n",
            "##### k, v.shape :  taskmodels_dict.cola.head.out_proj.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140241181976576)\n",
            "##### k, v.shape :  taskmodels_dict.cola.head.out_proj.bias torch.Size([2])\n",
            "##### unique_key :  ((2,), 140240066968064)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d1c8044297c4921a7dbd96ef5ab4289",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Eval (cola, Val):   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Best\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61c1e07e545040ae861c1c4b40a6dd3d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Eval (cola, Val):   0%|          | 0/64 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"aggregated\": 0.5136257365311373,\n",
            "  \"cola\": {\n",
            "    \"loss\": 0.6270212330855429,\n",
            "    \"metrics\": {\n",
            "      \"major\": 0.5136257365311373,\n",
            "      \"minor\": {\n",
            "        \"mcc\": 0.5136257365311373\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df7ba33203af4abd950c5c67bb864d78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Eval (cola, Test):   0%|          | 0/34 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_task_list : ['cola']\n",
            "##### write_preds(), task_name:  cola 1060\n",
            "##### write_json to :  ./exp/runs/simple/test_preds.p.cola\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXppBY04DNwf"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/jiant-rev')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8e4h-sSuPJ8"
      },
      "source": [
        "!rm -rf ./exp/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUDfoI5XdZF7",
        "outputId": "e9ae2344-d4d2-4bca-a682-2cb284c780d1"
      },
      "source": [
        "# write predictions to file (copa)\n",
        "from jiant.proj.simple import runscript as run\n",
        "import jiant.scripts.download_data.runscript as downloader\n",
        "\n",
        "#EXP_DIR = \"/content/jiant-rev/exp\"\n",
        "EXP_DIR = \"./exp\"\n",
        "\n",
        "# Download the Data\n",
        "downloader.download_data([\"copa\"], f\"{EXP_DIR}/tasks\")\n",
        "\n",
        "# Set up the arguments for the Simple API\n",
        "args = run.RunConfiguration(\n",
        "   run_name=\"simple\",\n",
        "   exp_dir=EXP_DIR,\n",
        "   data_dir=f\"{EXP_DIR}/tasks\",\n",
        "   hf_pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
        "   tasks=\"copa\",\n",
        "   train_batch_size=16,\n",
        "   num_train_epochs=3,\n",
        "   write_test_preds=True\n",
        ")\n",
        "\n",
        "# Run!\n",
        "run.run_simple(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### hf_datasets_tasks_download, task_name:  copa , task_data_path:  /content/jiant-rev/exp/tasks/data/copa\n",
            "##### load_dataset(), path= super_glue , name= copa\n",
            "##### is_ko_model :  True\n",
            "Using custom data configuration default-9bc45d1b550870d2\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-9bc45d1b550870d2/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n",
            "100% 3/3 [00:00<00:00, 13329.36it/s]\n",
            "100% 3/3 [00:00<00:00, 1514.92it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-9bc45d1b550870d2/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 958.48it/s]\n",
            "Downloaded and generated configs for 'copa' (1/1)\n",
            "##### run_simple(): Tokenizing Task 'copa' for phases 'train,val,test'\n",
            "CopaTask\n",
            "  [train]: /content/jiant-rev/exp/tasks/data/copa/train.jsonl\n",
            "  [val]: /content/jiant-rev/exp/tasks/data/copa/val.jsonl\n",
            "  [test]: /content/jiant-rev/exp/tasks/data/copa/test.jsonl\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "Tokenizing: 100% 3080/3080 [00:01<00:00, 1632.42it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 3080/3080 [00:00<00:00, 103824.41it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "Tokenizing: 100% 500/500 [00:00<00:00, 1718.82it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 500/500 [00:00<00:00, 127742.71it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00, 15.01it/s]\n",
            "Tokenizing: 100% 500/500 [00:00<00:00, 1714.46it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 500/500 [00:00<00:00, 111734.88it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00, 14.61it/s]\n",
            "Running from start\n",
            "  jiant_task_container_config_path: /content/jiant-rev/exp/run_configs/simple_config.json\n",
            "  output_dir: /content/jiant-rev/exp/runs/simple\n",
            "  hf_pretrained_model_name_or_path: monologg/koelectra-base-v3-discriminator\n",
            "  model_path: /content/jiant-rev/exp/models/electra/model/model.p\n",
            "  model_config_path: /content/jiant-rev/exp/models/electra/model/config.json\n",
            "  model_load_mode: from_transformers\n",
            "  do_train: True\n",
            "  do_val: True\n",
            "  do_save: False\n",
            "  do_save_last: False\n",
            "  do_save_best: False\n",
            "  write_val_preds: False\n",
            "  write_test_preds: True\n",
            "  eval_every_steps: 0\n",
            "  save_every_steps: 0\n",
            "  save_checkpoint_every_steps: 0\n",
            "  no_improvements_for_n_evals: 0\n",
            "  keep_checkpoint_when_done: False\n",
            "  force_overwrite: False\n",
            "  seed: -1\n",
            "  learning_rate: 1e-05\n",
            "  adam_epsilon: 1e-08\n",
            "  max_grad_norm: 1.0\n",
            "  optimizer_type: adam\n",
            "  no_cuda: False\n",
            "  fp16: False\n",
            "  fp16_opt_level: O1\n",
            "  local_rank: -1\n",
            "  server_ip: \n",
            "  server_port: \n",
            "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Using seed: 3014679038\n",
            "{\n",
            "  \"jiant_task_container_config_path\": \"/content/jiant-rev/exp/run_configs/simple_config.json\",\n",
            "  \"output_dir\": \"/content/jiant-rev/exp/runs/simple\",\n",
            "  \"hf_pretrained_model_name_or_path\": \"monologg/koelectra-base-v3-discriminator\",\n",
            "  \"model_path\": \"/content/jiant-rev/exp/models/electra/model/model.p\",\n",
            "  \"model_config_path\": \"/content/jiant-rev/exp/models/electra/model/config.json\",\n",
            "  \"model_load_mode\": \"from_transformers\",\n",
            "  \"do_train\": true,\n",
            "  \"do_val\": true,\n",
            "  \"do_save\": false,\n",
            "  \"do_save_last\": false,\n",
            "  \"do_save_best\": false,\n",
            "  \"write_val_preds\": false,\n",
            "  \"write_test_preds\": true,\n",
            "  \"eval_every_steps\": 0,\n",
            "  \"save_every_steps\": 0,\n",
            "  \"save_checkpoint_every_steps\": 0,\n",
            "  \"no_improvements_for_n_evals\": 0,\n",
            "  \"keep_checkpoint_when_done\": false,\n",
            "  \"force_overwrite\": false,\n",
            "  \"seed\": 3014679038,\n",
            "  \"learning_rate\": 1e-05,\n",
            "  \"adam_epsilon\": 1e-08,\n",
            "  \"max_grad_norm\": 1.0,\n",
            "  \"optimizer_type\": \"adam\",\n",
            "  \"no_cuda\": false,\n",
            "  \"fp16\": false,\n",
            "  \"fp16_opt_level\": \"O1\",\n",
            "  \"local_rank\": -1,\n",
            "  \"server_ip\": \"\",\n",
            "  \"server_port\": \"\"\n",
            "}\n",
            "1\n",
            "Creating Tasks:\n",
            "    copa (CopaTask): /content/jiant-rev/exp/tasks/configs/copa_config.json\n",
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "##### encoder_prefix: electra.\n",
            "##### k :  electra.embeddings.position_ids\n",
            "##### k :  electra.embeddings.word_embeddings.weight\n",
            "##### k :  electra.embeddings.position_embeddings.weight\n",
            "##### k :  electra.embeddings.token_type_embeddings.weight\n",
            "##### k :  electra.embeddings.LayerNorm.weight\n",
            "##### k :  electra.embeddings.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.bias\n",
            "##### k :  discriminator_predictions.dense.weight\n",
            "##### k :  discriminator_predictions.dense.bias\n",
            "##### k :  discriminator_predictions.dense_prediction.weight\n",
            "##### k :  discriminator_predictions.dense_prediction.bias\n",
            "No optimizer decay for:\n",
            "  encoder.embeddings.LayerNorm.weight\n",
            "  encoder.embeddings.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.attention.self.query.bias\n",
            "  encoder.encoder.layer.0.attention.self.key.bias\n",
            "  encoder.encoder.layer.0.attention.self.value.bias\n",
            "  encoder.encoder.layer.0.attention.output.dense.bias\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.intermediate.dense.bias\n",
            "  encoder.encoder.layer.0.output.dense.bias\n",
            "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.attention.self.query.bias\n",
            "  encoder.encoder.layer.1.attention.self.key.bias\n",
            "  encoder.encoder.layer.1.attention.self.value.bias\n",
            "  encoder.encoder.layer.1.attention.output.dense.bias\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.intermediate.dense.bias\n",
            "  encoder.encoder.layer.1.output.dense.bias\n",
            "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.attention.self.query.bias\n",
            "  encoder.encoder.layer.2.attention.self.key.bias\n",
            "  encoder.encoder.layer.2.attention.self.value.bias\n",
            "  encoder.encoder.layer.2.attention.output.dense.bias\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.intermediate.dense.bias\n",
            "  encoder.encoder.layer.2.output.dense.bias\n",
            "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.attention.self.query.bias\n",
            "  encoder.encoder.layer.3.attention.self.key.bias\n",
            "  encoder.encoder.layer.3.attention.self.value.bias\n",
            "  encoder.encoder.layer.3.attention.output.dense.bias\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.intermediate.dense.bias\n",
            "  encoder.encoder.layer.3.output.dense.bias\n",
            "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.attention.self.query.bias\n",
            "  encoder.encoder.layer.4.attention.self.key.bias\n",
            "  encoder.encoder.layer.4.attention.self.value.bias\n",
            "  encoder.encoder.layer.4.attention.output.dense.bias\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.intermediate.dense.bias\n",
            "  encoder.encoder.layer.4.output.dense.bias\n",
            "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.attention.self.query.bias\n",
            "  encoder.encoder.layer.5.attention.self.key.bias\n",
            "  encoder.encoder.layer.5.attention.self.value.bias\n",
            "  encoder.encoder.layer.5.attention.output.dense.bias\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.intermediate.dense.bias\n",
            "  encoder.encoder.layer.5.output.dense.bias\n",
            "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.attention.self.query.bias\n",
            "  encoder.encoder.layer.6.attention.self.key.bias\n",
            "  encoder.encoder.layer.6.attention.self.value.bias\n",
            "  encoder.encoder.layer.6.attention.output.dense.bias\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.intermediate.dense.bias\n",
            "  encoder.encoder.layer.6.output.dense.bias\n",
            "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.attention.self.query.bias\n",
            "  encoder.encoder.layer.7.attention.self.key.bias\n",
            "  encoder.encoder.layer.7.attention.self.value.bias\n",
            "  encoder.encoder.layer.7.attention.output.dense.bias\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.intermediate.dense.bias\n",
            "  encoder.encoder.layer.7.output.dense.bias\n",
            "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.attention.self.query.bias\n",
            "  encoder.encoder.layer.8.attention.self.key.bias\n",
            "  encoder.encoder.layer.8.attention.self.value.bias\n",
            "  encoder.encoder.layer.8.attention.output.dense.bias\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.intermediate.dense.bias\n",
            "  encoder.encoder.layer.8.output.dense.bias\n",
            "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.attention.self.query.bias\n",
            "  encoder.encoder.layer.9.attention.self.key.bias\n",
            "  encoder.encoder.layer.9.attention.self.value.bias\n",
            "  encoder.encoder.layer.9.attention.output.dense.bias\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.intermediate.dense.bias\n",
            "  encoder.encoder.layer.9.output.dense.bias\n",
            "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.attention.self.query.bias\n",
            "  encoder.encoder.layer.10.attention.self.key.bias\n",
            "  encoder.encoder.layer.10.attention.self.value.bias\n",
            "  encoder.encoder.layer.10.attention.output.dense.bias\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.intermediate.dense.bias\n",
            "  encoder.encoder.layer.10.output.dense.bias\n",
            "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.attention.self.query.bias\n",
            "  encoder.encoder.layer.11.attention.self.key.bias\n",
            "  encoder.encoder.layer.11.attention.self.value.bias\n",
            "  encoder.encoder.layer.11.attention.output.dense.bias\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.intermediate.dense.bias\n",
            "  encoder.encoder.layer.11.output.dense.bias\n",
            "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
            "  taskmodels_dict.copa.head.dense.bias\n",
            "  taskmodels_dict.copa.head.out_proj.bias\n",
            "Using AdamW\n",
            "##### do_train #####\n",
            "##### run_train_context() #####\n",
            "##### get_train_dataloader_dict() :  1\n",
            "Training: 100% 578/579 [01:25<00:00,  6.76it/s]\n",
            "Eval (copa, Val): 100% 16/16 [00:01<00:00, 14.07it/s]\n",
            "##### get_accumulated(), logits :  [[-2.1504474   2.4534202 ]\n",
            " [-0.31400448  2.6491735 ]\n",
            " [ 2.3787887  -2.2828372 ]\n",
            " [-2.3547294   2.3805358 ]\n",
            " [ 1.656356    2.021311  ]\n",
            " [ 2.504845    2.177699  ]\n",
            " [-0.7917392   2.6441448 ]\n",
            " [-1.8507      2.8213634 ]\n",
            " [ 0.7726247  -2.1173246 ]\n",
            " [-2.1445858   2.338613  ]\n",
            " [-1.9084153   2.221878  ]\n",
            " [ 2.7008462  -2.2023838 ]\n",
            " [ 1.1046677   1.1503321 ]\n",
            " [ 2.4834106  -2.1407824 ]\n",
            " [ 0.0980434   0.82440054]\n",
            " [-1.9721334  -0.09647377]\n",
            " [ 2.5261095   1.327853  ]\n",
            " [-0.49595577  2.012892  ]\n",
            " [-1.2534387   2.8292344 ]\n",
            " [ 0.2122598  -1.599427  ]\n",
            " [ 2.6300726  -1.6528119 ]\n",
            " [-2.0097258   1.8879483 ]\n",
            " [ 1.8323492   1.8441513 ]\n",
            " [-0.21102038  2.8275988 ]\n",
            " [-1.3486925   2.768861  ]\n",
            " [ 1.0180725  -0.9044738 ]\n",
            " [-2.185722    2.5609143 ]\n",
            " [ 0.08529936  1.9263699 ]\n",
            " [-1.7454696   2.2201583 ]\n",
            " [ 2.1367497  -2.2370942 ]\n",
            " [-1.0039271  -1.6242585 ]\n",
            " [-1.0517178   2.561564  ]\n",
            " [ 0.28368396  1.7080874 ]\n",
            " [ 2.7681048   2.7869997 ]\n",
            " [ 1.1358058   1.0058817 ]\n",
            " [ 2.7059193  -1.5833079 ]\n",
            " [-2.1885974   2.4265342 ]\n",
            " [-1.4830813   0.40009457]\n",
            " [ 2.6898687  -1.670424  ]\n",
            " [ 2.6120417   2.7556593 ]\n",
            " [-1.7008988   1.2948626 ]\n",
            " [ 1.3764393   2.4242496 ]\n",
            " [ 2.492418    2.2496006 ]\n",
            " [-1.8836321  -1.2544489 ]\n",
            " [ 2.4895034  -0.5148301 ]\n",
            " [ 1.8409883  -2.1549587 ]\n",
            " [-1.7317511  -0.84516156]\n",
            " [ 0.2634111   1.3074747 ]\n",
            " [ 0.3116999   2.8055155 ]\n",
            " [ 1.1905214  -0.77569044]\n",
            " [ 2.7959752  -0.7829282 ]\n",
            " [ 2.7287395   2.4053016 ]\n",
            " [ 1.8542593  -1.0563898 ]\n",
            " [-1.4566295   2.6775637 ]\n",
            " [ 1.7034225  -0.23490815]\n",
            " [ 1.4475359   1.1688205 ]\n",
            " [ 2.4187453  -1.4992671 ]\n",
            " [-2.148481    0.24420089]\n",
            " [ 1.9199437  -2.3411045 ]\n",
            " [ 2.5929494   1.5155647 ]\n",
            " [-2.1047654   2.6600935 ]\n",
            " [ 1.1248906  -2.0205321 ]\n",
            " [-0.6624929   2.6249466 ]\n",
            " [-1.8529112  -2.1390018 ]\n",
            " [ 0.04473776  2.8237526 ]\n",
            " [-1.8751397   2.5598452 ]\n",
            " [ 1.5552403   2.071562  ]\n",
            " [ 2.6386883  -2.2806764 ]\n",
            " [ 1.2286118   1.4211997 ]\n",
            " [ 2.5255196  -2.1865966 ]\n",
            " [ 2.863398   -1.146078  ]\n",
            " [-1.6639885  -0.03650255]\n",
            " [ 2.6861794  -1.3885306 ]\n",
            " [-1.2137506   2.8103027 ]\n",
            " [-1.2005906   2.664173  ]\n",
            " [ 1.3120422  -2.1071286 ]\n",
            " [ 2.7448506   0.70155287]\n",
            " [-2.163786    2.806927  ]\n",
            " [ 1.3504974  -2.3048913 ]\n",
            " [-0.03019945  2.7939026 ]\n",
            " [-1.3368945  -0.03361408]\n",
            " [-1.0004156   1.7316871 ]\n",
            " [-1.8065833  -1.2079008 ]\n",
            " [-0.37161562  2.472645  ]\n",
            " [-2.2916853   2.8050609 ]\n",
            " [-1.0967711   2.3782067 ]\n",
            " [-1.6020447  -2.308028  ]\n",
            " [-2.370132    2.5251503 ]\n",
            " [-1.0446719   2.6169431 ]\n",
            " [ 1.0619051   2.805765  ]\n",
            " [ 1.8265495   1.9976552 ]\n",
            " [ 2.5351183  -2.2563794 ]\n",
            " [ 0.58677685  2.742555  ]\n",
            " [ 2.551235   -2.083225  ]\n",
            " [-2.2735314   1.3566895 ]\n",
            " [ 2.7651117  -1.9309533 ]\n",
            " [ 2.4831183   2.8140697 ]\n",
            " [ 2.3407955  -2.1238365 ]\n",
            " [ 2.5944357  -0.54668844]\n",
            " [ 2.6703117  -0.7436198 ]\n",
            " [ 1.7739595  -2.1859055 ]\n",
            " [ 1.864688    2.0937655 ]\n",
            " [-2.1123383   2.0555677 ]\n",
            " [-1.9949187   1.9852138 ]\n",
            " [-0.11322264  2.454548  ]\n",
            " [ 2.881589    0.57770205]\n",
            " [ 2.4017303  -2.1870909 ]\n",
            " [-2.2760315   1.7800196 ]\n",
            " [-2.0791657   2.6210353 ]\n",
            " [-1.7350173   2.540205  ]\n",
            " [-2.125161   -0.39300177]\n",
            " [ 2.6080174  -0.54411125]\n",
            " [-1.1874607   2.6557035 ]\n",
            " [-0.83106667  2.7796137 ]\n",
            " [ 0.9486654  -1.7208948 ]\n",
            " [-1.2538512   1.1453508 ]\n",
            " [-1.4274594   2.5634854 ]\n",
            " [ 2.7576728  -2.1551235 ]\n",
            " [ 2.8606763  -2.3416007 ]\n",
            " [ 2.4934049   2.8744974 ]\n",
            " [ 2.4220893  -1.7922971 ]\n",
            " [ 1.9344692  -1.8525535 ]\n",
            " [ 2.5127797   2.4628563 ]\n",
            " [ 2.8280761   0.59217477]\n",
            " [-0.9336371   2.3595335 ]\n",
            " [-2.147406    2.6675804 ]\n",
            " [ 1.3672768  -0.6711211 ]\n",
            " [ 2.1046817  -2.27565   ]\n",
            " [ 2.6225984  -1.9318391 ]\n",
            " [ 2.5919082  -2.2133758 ]\n",
            " [-2.183046    2.5937896 ]\n",
            " [-1.2297392   0.21158254]\n",
            " [-1.856209    2.7465224 ]\n",
            " [-2.0700493   2.6430209 ]\n",
            " [-1.8892483   0.9095315 ]\n",
            " [-2.181922    2.7453547 ]\n",
            " [-1.3625976   2.6180122 ]\n",
            " [-2.253281    2.7698407 ]\n",
            " [ 2.786565    2.7534926 ]\n",
            " [ 2.0851176   1.431068  ]\n",
            " [ 2.287336   -1.9120567 ]\n",
            " [ 2.2141676  -2.1916018 ]\n",
            " [-2.1534488   2.721521  ]\n",
            " [ 1.9805932   2.7538455 ]\n",
            " [ 2.3652356  -1.5287501 ]\n",
            " [-0.11422309  2.1907218 ]\n",
            " [-2.2480164   2.4952624 ]\n",
            " [ 2.7801766  -1.9797437 ]\n",
            " [-2.0202863   2.6199863 ]\n",
            " [ 1.7189884   2.7860796 ]\n",
            " [-2.2953136   2.4586995 ]\n",
            " [ 2.829503    2.0694685 ]\n",
            " [ 0.6341237   2.6008413 ]\n",
            " [-2.0461895   2.1097896 ]\n",
            " [ 2.014272    1.0278043 ]\n",
            " [ 2.6823      1.6891004 ]\n",
            " [-2.2849615  -1.6309304 ]\n",
            " [ 2.6711478   2.7546718 ]\n",
            " [ 2.648128    2.6784542 ]\n",
            " [ 2.2122955   1.3225845 ]\n",
            " [-1.9699311   2.881978  ]\n",
            " [-0.20111744 -1.53213   ]\n",
            " [ 1.3168471  -1.4348073 ]\n",
            " [-1.4762282  -2.0318353 ]\n",
            " [ 0.4659851  -2.0105147 ]\n",
            " [-2.2797294   2.3977244 ]\n",
            " [-2.1572108   2.8317087 ]\n",
            " [-1.4107777   1.2136374 ]\n",
            " [-2.0016658  -1.330682  ]\n",
            " [ 2.7971249  -1.8306434 ]\n",
            " [ 0.08501171  2.6001248 ]\n",
            " [-2.2458708  -0.46797654]\n",
            " [ 1.8460666   2.650461  ]\n",
            " [ 0.4458086  -0.21723253]\n",
            " [ 2.5876267  -1.0764767 ]\n",
            " [ 2.6495318   0.5788762 ]\n",
            " [ 2.5557153   1.4269077 ]\n",
            " [-1.3721513  -2.29492   ]\n",
            " [ 1.0710695   1.0886183 ]\n",
            " [ 1.7744043   1.8354925 ]\n",
            " [ 1.1514527   2.433872  ]\n",
            " [ 2.1723766   1.851061  ]\n",
            " [-1.6580434   2.0536458 ]\n",
            " [ 2.5264697   2.0916226 ]\n",
            " [-1.2689555  -1.9146684 ]\n",
            " [ 1.6783754   2.828823  ]\n",
            " [ 1.3641093  -1.8761348 ]\n",
            " [ 2.4408474  -1.6116209 ]\n",
            " [ 1.0866302  -2.1413014 ]\n",
            " [ 0.19573689  2.2127566 ]\n",
            " [ 1.760284    1.0315537 ]\n",
            " [ 2.8053157  -1.5400258 ]\n",
            " [-1.9144567  -2.2204666 ]\n",
            " [ 2.5822763   2.773787  ]\n",
            " [-2.132478    2.40574   ]\n",
            " [-2.3374336   1.2511712 ]\n",
            " [-1.0449846   2.7548642 ]\n",
            " [-1.6689636   2.703223  ]\n",
            " [-1.9239326   2.3503215 ]\n",
            " [ 2.4976952   0.7989349 ]\n",
            " [-1.4232723   2.745392  ]\n",
            " [-0.8279269   2.6205413 ]\n",
            " [ 2.5654485  -0.82400644]\n",
            " [ 2.724483    2.8252168 ]\n",
            " [-1.4101758   2.092049  ]\n",
            " [ 2.643982   -1.7419875 ]\n",
            " [ 2.4144206   2.1329584 ]\n",
            " [-1.9647565   2.7671785 ]\n",
            " [-0.47228438  0.8876479 ]\n",
            " [ 2.5569167  -2.0330749 ]\n",
            " [ 1.2795113   0.7931759 ]\n",
            " [-1.705342    2.2245915 ]\n",
            " [-1.3897305   2.561885  ]\n",
            " [ 2.5363991  -1.8719859 ]\n",
            " [ 1.0054746   0.7937496 ]\n",
            " [ 2.861812    1.7891812 ]\n",
            " [-1.9327574   1.9105357 ]\n",
            " [-1.9368728  -1.0938063 ]\n",
            " [ 2.6584725  -1.7086234 ]\n",
            " [ 1.6759458   2.7122052 ]\n",
            " [-1.0295368  -2.2940955 ]\n",
            " [ 2.3342743  -1.7395066 ]\n",
            " [ 2.484432   -2.2198207 ]\n",
            " [ 1.9316114   1.6358579 ]\n",
            " [ 1.8603753   2.6184661 ]\n",
            " [ 2.7246082  -1.7878104 ]\n",
            " [-0.63352144  2.0808058 ]\n",
            " [ 2.8358471  -2.0049202 ]\n",
            " [ 2.1994982   2.3369277 ]\n",
            " [ 2.6579535  -2.2084777 ]\n",
            " [-2.1297758   2.2655241 ]\n",
            " [ 2.6106393   1.5590084 ]\n",
            " [ 2.849542   -1.5366626 ]\n",
            " [-1.7078302  -2.0093887 ]\n",
            " [-2.0795138   2.5967145 ]\n",
            " [ 2.8164697   2.5094426 ]\n",
            " [ 1.211886    0.20324749]\n",
            " [ 2.8107352   2.8624344 ]\n",
            " [ 2.7959578  -0.36069423]\n",
            " [-1.9582194   2.0925124 ]\n",
            " [ 2.7431548   1.2401718 ]\n",
            " [ 2.3376184   2.2954443 ]\n",
            " [ 1.9120882  -1.9578531 ]\n",
            " [-2.1597624   2.4243803 ]\n",
            " [ 2.5209465   2.4628398 ]\n",
            " [ 2.1220067  -1.5130119 ]\n",
            " [-1.1935298   2.3690836 ]\n",
            " [ 0.12934478  2.8028412 ]\n",
            " [-1.447331    0.01298548]\n",
            " [ 2.7748106   2.7332935 ]\n",
            " [ 2.2949111  -2.299057  ]\n",
            " [-1.9066203   2.3053312 ]\n",
            " [ 2.464407   -1.5581281 ]\n",
            " [ 2.3786519  -1.3126695 ]\n",
            " [-0.96810764  1.147285  ]\n",
            " [ 1.2943039  -1.6559131 ]\n",
            " [ 0.07775377  2.227723  ]\n",
            " [ 2.2799351  -2.3176599 ]\n",
            " [ 2.9009628   2.065329  ]\n",
            " [ 2.6150732  -0.68429774]\n",
            " [-0.20934542  2.7511795 ]\n",
            " [ 2.7989433  -1.5258992 ]\n",
            " [ 2.8151052  -1.7234397 ]\n",
            " [ 1.6932207   2.8499236 ]\n",
            " [-1.3608353   2.5639288 ]\n",
            " [ 2.8474557  -2.3650753 ]\n",
            " [ 2.7544265   1.3684742 ]\n",
            " [ 1.8024966   2.2389686 ]\n",
            " [ 2.6435907  -1.9251342 ]\n",
            " [-1.5502377  -0.95222956]\n",
            " [ 2.5720925   2.628462  ]\n",
            " [ 0.43233526 -2.1822298 ]\n",
            " [ 1.6446894  -1.8160778 ]\n",
            " [-0.4944921  -1.8894066 ]\n",
            " [ 0.72065246  2.6199667 ]\n",
            " [ 2.4064224  -2.1306758 ]\n",
            " [ 2.2770648  -0.49994734]\n",
            " [-1.4537264   2.4815478 ]\n",
            " [ 0.950881    2.824629  ]\n",
            " [ 2.4854195  -1.5637901 ]\n",
            " [ 2.784511   -2.0581348 ]\n",
            " [ 1.4919364   2.2300413 ]\n",
            " [-1.9104348   2.7653627 ]\n",
            " [ 1.5585023   2.3110754 ]\n",
            " [-0.17852862  2.3474703 ]\n",
            " [ 0.0333663  -2.1561255 ]\n",
            " [ 2.6927104  -0.52014405]\n",
            " [-2.231978   -1.0488726 ]\n",
            " [ 1.3543928  -1.883163  ]\n",
            " [-1.8429253   2.4908302 ]\n",
            " [-1.2118145   0.05088608]\n",
            " [-1.3909922   2.7421806 ]\n",
            " [-1.2095323   2.4125125 ]\n",
            " [ 2.69685     2.8153784 ]\n",
            " [ 1.8337464   2.1913962 ]\n",
            " [ 2.7902553  -1.7292066 ]\n",
            " [ 0.8543191   2.6904702 ]\n",
            " [ 0.29159608  0.40817806]\n",
            " [-1.2566801   2.1525373 ]\n",
            " [ 2.7492805   1.7740128 ]\n",
            " [ 2.050447    1.5438207 ]\n",
            " [ 2.3933504   2.7746634 ]\n",
            " [ 2.762715    2.7552383 ]\n",
            " [ 0.11561216 -1.3179238 ]\n",
            " [ 2.608551   -1.4754394 ]\n",
            " [ 2.522436   -2.3069701 ]\n",
            " [-1.6973332   2.2672226 ]\n",
            " [ 1.2372683   0.5755195 ]\n",
            " [ 2.7401233   0.9402429 ]\n",
            " [-1.624405    1.6713061 ]\n",
            " [ 1.7504722  -1.4988253 ]\n",
            " [ 1.4718908   0.07725255]\n",
            " [ 2.7481031  -2.050321  ]\n",
            " [ 0.24425858 -0.47043765]\n",
            " [ 2.5856125   2.3757265 ]\n",
            " [-1.0546073   2.507427  ]\n",
            " [-1.9485356  -1.228729  ]\n",
            " [ 1.1498599   2.410346  ]\n",
            " [ 2.1256576  -0.9252519 ]\n",
            " [ 0.67089844 -2.131072  ]\n",
            " [ 2.681002   -0.20728242]\n",
            " [ 1.7656156  -2.3261836 ]\n",
            " [-1.754266   -1.7200826 ]\n",
            " [ 2.8304713  -2.1534946 ]\n",
            " [ 1.4606344  -2.1094947 ]\n",
            " [ 2.4945722   1.095926  ]\n",
            " [ 1.8638799  -1.8300247 ]\n",
            " [ 2.593221   -2.2896411 ]\n",
            " [ 1.6081269   2.770547  ]\n",
            " [ 0.27721268  1.6439613 ]\n",
            " [ 2.7131815   2.6649895 ]\n",
            " [-0.9663895   2.8496625 ]\n",
            " [-2.2744825   2.8120382 ]\n",
            " [ 2.7646794  -0.9329873 ]\n",
            " [ 1.6459603   1.4555273 ]\n",
            " [ 1.2015244  -2.3592901 ]\n",
            " [ 2.0324147   1.1318831 ]\n",
            " [ 2.671604   -1.3310914 ]\n",
            " [-2.052582    2.6678665 ]\n",
            " [ 2.2276998  -0.2415186 ]\n",
            " [-2.2890909  -1.115474  ]\n",
            " [-2.0172272   2.691542  ]\n",
            " [ 2.710132    2.4728384 ]\n",
            " [ 2.559688    1.6999451 ]\n",
            " [ 2.007752    0.30185   ]\n",
            " [ 2.8339374  -1.4838176 ]\n",
            " [ 2.4891534   1.0727779 ]\n",
            " [ 2.495877    1.9417614 ]\n",
            " [ 2.715542   -1.2699704 ]\n",
            " [-2.1799233   2.7962027 ]\n",
            " [ 1.1657624  -1.1654001 ]\n",
            " [ 1.6954303   0.9153137 ]\n",
            " [ 2.7254255  -1.5168266 ]\n",
            " [-1.8381574   0.7971116 ]\n",
            " [-2.313991   -2.3476593 ]\n",
            " [-2.124981    2.5709524 ]\n",
            " [ 1.9996498   1.2923071 ]\n",
            " [ 2.7750664  -2.1901405 ]\n",
            " [ 2.7091107   2.0444348 ]\n",
            " [-1.9177631   2.7819219 ]\n",
            " [ 2.7203882  -1.9695591 ]\n",
            " [ 2.179116   -0.1028848 ]\n",
            " [ 2.3132641   2.6495023 ]\n",
            " [-1.9953749   2.8006837 ]\n",
            " [ 2.2862444  -1.0323337 ]\n",
            " [ 2.8397593  -2.318106  ]\n",
            " [-1.2722872   2.785776  ]\n",
            " [-1.8583593   2.6614072 ]\n",
            " [-1.5745083   1.4870595 ]\n",
            " [-2.1604497   2.630166  ]\n",
            " [-2.2839653   2.605033  ]\n",
            " [-2.0611622   2.6833825 ]\n",
            " [ 2.7664483   1.8925829 ]\n",
            " [-1.7997203  -0.21078774]\n",
            " [-1.6915394   2.7873473 ]\n",
            " [-1.3887994  -2.1483555 ]\n",
            " [ 2.8322847  -1.5162437 ]\n",
            " [ 2.761152   -2.258652  ]\n",
            " [-2.2360244  -0.52349424]\n",
            " [-1.7577384   2.5167694 ]\n",
            " [-2.2665002  -1.2933255 ]\n",
            " [ 2.7856193   2.4663155 ]\n",
            " [-2.3441327   0.377635  ]\n",
            " [ 0.63554996 -0.07557455]\n",
            " [ 2.8253603  -1.8312006 ]\n",
            " [ 2.009998    0.13113695]\n",
            " [ 2.6757424  -1.9758763 ]\n",
            " [-2.3631744  -0.8335856 ]\n",
            " [-1.0178878  -0.3933008 ]\n",
            " [-0.6533724   2.0773332 ]\n",
            " [ 2.2820342   2.090356  ]\n",
            " [-0.2826298  -0.06911895]\n",
            " [ 2.6115184  -0.5748172 ]\n",
            " [ 2.7093956  -2.0190985 ]\n",
            " [-1.9405963   1.436221  ]\n",
            " [-2.127129    1.108408  ]\n",
            " [ 2.5455267   2.4495623 ]\n",
            " [ 2.7339282   0.8497526 ]\n",
            " [ 1.7290056  -0.42936763]\n",
            " [ 1.746954    2.7487385 ]\n",
            " [ 0.05515524  2.68199   ]\n",
            " [ 2.6396904  -1.3711578 ]\n",
            " [ 2.5096564  -1.8966714 ]\n",
            " [ 2.3686883   1.5229906 ]\n",
            " [ 1.1491795   2.7295656 ]\n",
            " [ 2.6825607  -0.4789174 ]\n",
            " [-1.2992252  -2.3232248 ]\n",
            " [ 2.3940403  -1.7569404 ]\n",
            " [-1.1640817   2.6120265 ]\n",
            " [-2.2315805   2.6603904 ]\n",
            " [ 2.7875013  -2.1232986 ]\n",
            " [ 2.769821    1.0619402 ]\n",
            " [ 1.7794346  -1.8972526 ]\n",
            " [-1.6021613  -1.731295  ]\n",
            " [ 2.760505   -2.3439262 ]\n",
            " [-2.1236675   2.724581  ]\n",
            " [-0.74139863  2.4956014 ]\n",
            " [ 1.9685106  -2.0468707 ]\n",
            " [ 2.56912    -1.6255016 ]\n",
            " [ 2.250918    2.3605807 ]\n",
            " [ 2.4424958   2.7728417 ]\n",
            " [ 2.3112595   2.486933  ]\n",
            " [-1.652346   -0.8321239 ]\n",
            " [ 2.6751754  -2.337639  ]\n",
            " [-2.3540812   2.5917234 ]\n",
            " [-1.7907375   2.5037894 ]\n",
            " [ 2.753557   -2.2118275 ]\n",
            " [ 1.0614041  -1.9266735 ]\n",
            " [ 2.7139735  -2.1408002 ]\n",
            " [-1.473281    2.762387  ]\n",
            " [ 2.6878383   2.029424  ]\n",
            " [-1.9670434  -0.18286963]\n",
            " [-1.7140845   2.6727734 ]\n",
            " [ 2.2004168  -1.3559163 ]\n",
            " [-1.3310841   0.29888266]\n",
            " [ 2.6570222   2.6622903 ]\n",
            " [ 2.7495382  -0.5370745 ]\n",
            " [ 2.8690777   0.23451912]\n",
            " [ 2.230583    2.771784  ]\n",
            " [ 2.2779102  -1.424103  ]\n",
            " [ 2.1142626  -2.098485  ]\n",
            " [ 0.8688485   2.6656327 ]\n",
            " [-0.35475785 -1.9225571 ]\n",
            " [ 2.7715125   2.7335894 ]\n",
            " [ 2.1564934  -1.8904974 ]\n",
            " [ 2.594576   -1.2142209 ]\n",
            " [ 2.7885613  -0.12009999]\n",
            " [ 2.255032   -0.20421411]\n",
            " [ 2.3286126  -2.3140094 ]\n",
            " [ 2.383723    2.5956695 ]\n",
            " [-1.282976    0.76206744]\n",
            " [ 1.3318815   1.9655465 ]\n",
            " [ 2.062395   -2.2656693 ]\n",
            " [ 2.599848   -1.9092222 ]\n",
            " [ 2.8402226   2.5582256 ]\n",
            " [ 2.3282096   1.5413494 ]\n",
            " [ 1.7514756   0.01848166]\n",
            " [ 2.8083265  -2.0339274 ]\n",
            " [ 2.796908    2.4703112 ]\n",
            " [ 2.8066015  -0.32194185]\n",
            " [ 2.8181798   2.4042737 ]\n",
            " [ 2.7717655   0.8934875 ]\n",
            " [ 2.7960405   2.5292659 ]\n",
            " [-1.0074792   2.7519755 ]\n",
            " [ 0.7757833   0.6057264 ]\n",
            " [-0.02581987  2.37472   ]\n",
            " [-1.4186261   2.7455623 ]\n",
            " [-1.9692295   2.573281  ]\n",
            " [ 2.6452327  -1.5927432 ]\n",
            " [-1.8147507   2.8490112 ]\n",
            " [-2.2389956   0.17219143]\n",
            " [-2.3064663   2.8409388 ]\n",
            " [-0.91773564  2.5128756 ]\n",
            " [ 0.01855999  2.6550007 ]\n",
            " [ 2.761812    0.99223256]\n",
            " [-0.8260569   0.24484354]\n",
            " [ 2.4996064   1.8877255 ]\n",
            " [-0.06586961 -1.8975177 ]\n",
            " [-2.1107213   2.783873  ]\n",
            " [ 0.7576792  -2.2893782 ]\n",
            " [ 2.8483508   2.2061927 ]\n",
            " [ 2.1606286   1.8266462 ]\n",
            " [ 2.0451372   2.6300223 ]\n",
            " [-2.2799156   2.6924858 ]\n",
            " [-2.173927    2.4340339 ]\n",
            " [-1.1130235   2.6623204 ]\n",
            " [-1.749313   -0.98337996]\n",
            " [-1.4670795   2.7756429 ]\n",
            " [ 2.0069704  -0.40997094]\n",
            " [-2.3092763   2.8334808 ]\n",
            " [ 1.1237434   1.9433774 ]\n",
            " [ 1.0401918   2.3920784 ]\n",
            " [-1.8789464   2.2655437 ]\n",
            " [ 2.6783621   2.234581  ]\n",
            " [ 1.6644781   2.6280673 ]\n",
            " [ 2.382309    1.5671397 ]\n",
            " [ 2.0186656  -1.2805644 ]\n",
            " [ 2.7183242   2.697927  ]\n",
            " [ 2.666568    2.6967123 ]\n",
            " [ 1.9422914   2.1615283 ]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.86 [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1] [1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0\n",
            " 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 0\n",
            " 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
            " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0\n",
            " 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1]\n",
            "##### labels.shape:  (500,) preds.shape:  (500,)\n",
            "##### k, v.shape :  encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 139946166303232)\n",
            "##### k, v.shape :  encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 139941879218176)\n",
            "##### k, v.shape :  encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 139944369324032)\n",
            "##### k, v.shape :  encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 139946166307328)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139944423043072)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139944423049216)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944908554240)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166313472)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945218801664)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166316544)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944342847488)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166319616)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944644837376)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166322688)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166325760)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166328832)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139943355613184)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166331904)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139943331495936)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166344192)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166347264)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166350336)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944879718400)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166353408)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944946827264)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166356480)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945081044992)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166359552)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944848523264)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166362624)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166365696)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166368768)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942256705536)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166371840)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942266142720)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166384128)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166387200)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166390272)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945049849856)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166393344)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945452503040)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166396416)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944745500672)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166399488)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944747859968)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166402560)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166405632)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166408704)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942281871360)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166411776)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942291308544)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166424064)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166427136)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166430208)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945383034880)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166433280)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945385394176)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166436352)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942315425792)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166439424)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942317785088)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166442496)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166445568)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166448640)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942320144384)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166451712)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942348980224)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166464000)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166467072)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166470144)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942329581568)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166473216)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942331940864)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166476288)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942358417408)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166479360)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942360776704)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166482432)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166485504)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166488576)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942382534656)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166491648)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942391971840)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166503936)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166507008)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166510080)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942363136000)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166513152)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942365495296)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166516224)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942416089088)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166519296)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942418448384)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166522368)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166525440)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166528512)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942420807680)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166531584)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942449643520)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166543872)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166546944)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166550016)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942430244864)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166553088)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942432604160)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166556160)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942459080704)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166559232)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942461440000)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166562304)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166565376)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166568448)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942483197952)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166571520)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942492635136)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166583808)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166586880)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166589952)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942463799296)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166593024)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942466158592)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166596096)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942516752384)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166599168)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942519111680)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166602240)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166605312)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166608384)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942521470976)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166611456)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942550306816)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166623744)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166626816)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166629888)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942530908160)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166632960)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942533267456)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166636032)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942559744000)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166639104)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942562103296)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166642176)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166645248)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166648320)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942583861248)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166651392)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942593298432)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166663680)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166666752)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166669824)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942564462592)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166672896)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942566821888)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166675968)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942617415680)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166679040)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942619774976)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166682112)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166685184)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166688256)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942622134272)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166691328)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942650970112)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166703616)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166706688)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166709760)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942631571456)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166712832)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942633930752)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166715904)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942660407296)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166718976)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942662766592)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166722048)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166725120)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166728192)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942684524544)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166731264)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942693961728)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166743552)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166746624)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166749696)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942665125888)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166752768)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942667485184)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166755840)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942718078976)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166758912)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942720438272)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166761984)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166765056)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166768128)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942722797568)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166771200)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942751633408)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166783488)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166786560)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166789632)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 139946166303232)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 139941879218176)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 139944369324032)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 139946166307328)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139944423043072)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139944423049216)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944908554240)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166313472)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945218801664)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166316544)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944342847488)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166319616)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944644837376)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166322688)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166325760)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166328832)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139943355613184)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166331904)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139943331495936)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166344192)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166347264)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166350336)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944879718400)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166353408)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944946827264)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166356480)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945081044992)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166359552)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944848523264)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166362624)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166365696)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166368768)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942256705536)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166371840)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942266142720)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166384128)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166387200)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166390272)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945049849856)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166393344)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945452503040)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166396416)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944745500672)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166399488)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139944747859968)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166402560)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166405632)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166408704)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942281871360)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166411776)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942291308544)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166424064)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166427136)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166430208)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945383034880)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166433280)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139945385394176)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166436352)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942315425792)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166439424)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942317785088)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166442496)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166445568)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166448640)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942320144384)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166451712)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942348980224)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166464000)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166467072)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166470144)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942329581568)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166473216)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942331940864)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166476288)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942358417408)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166479360)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942360776704)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166482432)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166485504)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166488576)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942382534656)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166491648)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942391971840)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166503936)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166507008)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166510080)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942363136000)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166513152)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942365495296)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166516224)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942416089088)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166519296)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942418448384)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166522368)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166525440)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166528512)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942420807680)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166531584)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942449643520)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166543872)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166546944)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166550016)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942430244864)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166553088)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942432604160)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166556160)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942459080704)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166559232)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942461440000)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166562304)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166565376)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166568448)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942483197952)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166571520)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942492635136)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166583808)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166586880)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166589952)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942463799296)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166593024)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942466158592)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166596096)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942516752384)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166599168)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942519111680)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166602240)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166605312)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166608384)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942521470976)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166611456)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942550306816)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166623744)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166626816)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166629888)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942530908160)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166632960)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942533267456)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166636032)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942559744000)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166639104)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942562103296)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166642176)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166645248)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166648320)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942583861248)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166651392)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942593298432)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166663680)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166666752)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166669824)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942564462592)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166672896)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942566821888)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166675968)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942617415680)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166679040)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942619774976)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166682112)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166685184)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166688256)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942622134272)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166691328)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942650970112)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166703616)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166706688)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166709760)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942631571456)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166712832)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942633930752)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166715904)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942660407296)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166718976)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942662766592)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166722048)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166725120)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166728192)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942684524544)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166731264)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942693961728)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166743552)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166746624)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166749696)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942665125888)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166752768)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942667485184)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166755840)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942718078976)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166758912)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942720438272)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166761984)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166765056)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166768128)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 139942722797568)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 139946166771200)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 139942751633408)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166783488)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166786560)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166789632)\n",
            "##### k, v.shape :  taskmodels_dict.copa.head.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 139942732234752)\n",
            "##### k, v.shape :  taskmodels_dict.copa.head.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 139946166792704)\n",
            "##### k, v.shape :  taskmodels_dict.copa.head.out_proj.weight torch.Size([1, 768])\n",
            "##### unique_key :  ((1, 768), 139946166795776)\n",
            "##### k, v.shape :  taskmodels_dict.copa.head.out_proj.bias torch.Size([1])\n",
            "##### unique_key :  ((1,), 139946167893504)\n",
            "Eval (copa, Val): 100% 16/16 [00:01<00:00, 14.00it/s]\n",
            "##### get_accumulated(), logits :  [[-2.1504474   2.4534202 ]\n",
            " [-0.31400448  2.6491735 ]\n",
            " [ 2.3787887  -2.2828372 ]\n",
            " [-2.3547294   2.3805358 ]\n",
            " [ 1.656356    2.021311  ]\n",
            " [ 2.504845    2.177699  ]\n",
            " [-0.7917392   2.6441448 ]\n",
            " [-1.8507      2.8213634 ]\n",
            " [ 0.7726247  -2.1173246 ]\n",
            " [-2.1445858   2.338613  ]\n",
            " [-1.9084153   2.221878  ]\n",
            " [ 2.7008462  -2.2023838 ]\n",
            " [ 1.1046677   1.1503321 ]\n",
            " [ 2.4834106  -2.1407824 ]\n",
            " [ 0.0980434   0.82440054]\n",
            " [-1.9721334  -0.09647377]\n",
            " [ 2.5261095   1.327853  ]\n",
            " [-0.49595577  2.012892  ]\n",
            " [-1.2534387   2.8292344 ]\n",
            " [ 0.2122598  -1.599427  ]\n",
            " [ 2.6300726  -1.6528119 ]\n",
            " [-2.0097258   1.8879483 ]\n",
            " [ 1.8323492   1.8441513 ]\n",
            " [-0.21102038  2.8275988 ]\n",
            " [-1.3486925   2.768861  ]\n",
            " [ 1.0180725  -0.9044738 ]\n",
            " [-2.185722    2.5609143 ]\n",
            " [ 0.08529936  1.9263699 ]\n",
            " [-1.7454696   2.2201583 ]\n",
            " [ 2.1367497  -2.2370942 ]\n",
            " [-1.0039271  -1.6242585 ]\n",
            " [-1.0517178   2.561564  ]\n",
            " [ 0.28368396  1.7080874 ]\n",
            " [ 2.7681048   2.7869997 ]\n",
            " [ 1.1358058   1.0058817 ]\n",
            " [ 2.7059193  -1.5833079 ]\n",
            " [-2.1885974   2.4265342 ]\n",
            " [-1.4830813   0.40009457]\n",
            " [ 2.6898687  -1.670424  ]\n",
            " [ 2.6120417   2.7556593 ]\n",
            " [-1.7008988   1.2948626 ]\n",
            " [ 1.3764393   2.4242496 ]\n",
            " [ 2.492418    2.2496006 ]\n",
            " [-1.8836321  -1.2544489 ]\n",
            " [ 2.4895034  -0.5148301 ]\n",
            " [ 1.8409883  -2.1549587 ]\n",
            " [-1.7317511  -0.84516156]\n",
            " [ 0.2634111   1.3074747 ]\n",
            " [ 0.3116999   2.8055155 ]\n",
            " [ 1.1905214  -0.77569044]\n",
            " [ 2.7959752  -0.7829282 ]\n",
            " [ 2.7287395   2.4053016 ]\n",
            " [ 1.8542593  -1.0563898 ]\n",
            " [-1.4566295   2.6775637 ]\n",
            " [ 1.7034225  -0.23490815]\n",
            " [ 1.4475359   1.1688205 ]\n",
            " [ 2.4187453  -1.4992671 ]\n",
            " [-2.148481    0.24420089]\n",
            " [ 1.9199437  -2.3411045 ]\n",
            " [ 2.5929494   1.5155647 ]\n",
            " [-2.1047654   2.6600935 ]\n",
            " [ 1.1248906  -2.0205321 ]\n",
            " [-0.6624929   2.6249466 ]\n",
            " [-1.8529112  -2.1390018 ]\n",
            " [ 0.04473776  2.8237526 ]\n",
            " [-1.8751397   2.5598452 ]\n",
            " [ 1.5552403   2.071562  ]\n",
            " [ 2.6386883  -2.2806764 ]\n",
            " [ 1.2286118   1.4211997 ]\n",
            " [ 2.5255196  -2.1865966 ]\n",
            " [ 2.863398   -1.146078  ]\n",
            " [-1.6639885  -0.03650255]\n",
            " [ 2.6861794  -1.3885306 ]\n",
            " [-1.2137506   2.8103027 ]\n",
            " [-1.2005906   2.664173  ]\n",
            " [ 1.3120422  -2.1071286 ]\n",
            " [ 2.7448506   0.70155287]\n",
            " [-2.163786    2.806927  ]\n",
            " [ 1.3504974  -2.3048913 ]\n",
            " [-0.03019945  2.7939026 ]\n",
            " [-1.3368945  -0.03361408]\n",
            " [-1.0004156   1.7316871 ]\n",
            " [-1.8065833  -1.2079008 ]\n",
            " [-0.37161562  2.472645  ]\n",
            " [-2.2916853   2.8050609 ]\n",
            " [-1.0967711   2.3782067 ]\n",
            " [-1.6020447  -2.308028  ]\n",
            " [-2.370132    2.5251503 ]\n",
            " [-1.0446719   2.6169431 ]\n",
            " [ 1.0619051   2.805765  ]\n",
            " [ 1.8265495   1.9976552 ]\n",
            " [ 2.5351183  -2.2563794 ]\n",
            " [ 0.58677685  2.742555  ]\n",
            " [ 2.551235   -2.083225  ]\n",
            " [-2.2735314   1.3566895 ]\n",
            " [ 2.7651117  -1.9309533 ]\n",
            " [ 2.4831183   2.8140697 ]\n",
            " [ 2.3407955  -2.1238365 ]\n",
            " [ 2.5944357  -0.54668844]\n",
            " [ 2.6703117  -0.7436198 ]\n",
            " [ 1.7739595  -2.1859055 ]\n",
            " [ 1.864688    2.0937655 ]\n",
            " [-2.1123383   2.0555677 ]\n",
            " [-1.9949187   1.9852138 ]\n",
            " [-0.11322264  2.454548  ]\n",
            " [ 2.881589    0.57770205]\n",
            " [ 2.4017303  -2.1870909 ]\n",
            " [-2.2760315   1.7800196 ]\n",
            " [-2.0791657   2.6210353 ]\n",
            " [-1.7350173   2.540205  ]\n",
            " [-2.125161   -0.39300177]\n",
            " [ 2.6080174  -0.54411125]\n",
            " [-1.1874607   2.6557035 ]\n",
            " [-0.83106667  2.7796137 ]\n",
            " [ 0.9486654  -1.7208948 ]\n",
            " [-1.2538512   1.1453508 ]\n",
            " [-1.4274594   2.5634854 ]\n",
            " [ 2.7576728  -2.1551235 ]\n",
            " [ 2.8606763  -2.3416007 ]\n",
            " [ 2.4934049   2.8744974 ]\n",
            " [ 2.4220893  -1.7922971 ]\n",
            " [ 1.9344692  -1.8525535 ]\n",
            " [ 2.5127797   2.4628563 ]\n",
            " [ 2.8280761   0.59217477]\n",
            " [-0.9336371   2.3595335 ]\n",
            " [-2.147406    2.6675804 ]\n",
            " [ 1.3672768  -0.6711211 ]\n",
            " [ 2.1046817  -2.27565   ]\n",
            " [ 2.6225984  -1.9318391 ]\n",
            " [ 2.5919082  -2.2133758 ]\n",
            " [-2.183046    2.5937896 ]\n",
            " [-1.2297392   0.21158254]\n",
            " [-1.856209    2.7465224 ]\n",
            " [-2.0700493   2.6430209 ]\n",
            " [-1.8892483   0.9095315 ]\n",
            " [-2.181922    2.7453547 ]\n",
            " [-1.3625976   2.6180122 ]\n",
            " [-2.253281    2.7698407 ]\n",
            " [ 2.786565    2.7534926 ]\n",
            " [ 2.0851176   1.431068  ]\n",
            " [ 2.287336   -1.9120567 ]\n",
            " [ 2.2141676  -2.1916018 ]\n",
            " [-2.1534488   2.721521  ]\n",
            " [ 1.9805932   2.7538455 ]\n",
            " [ 2.3652356  -1.5287501 ]\n",
            " [-0.11422309  2.1907218 ]\n",
            " [-2.2480164   2.4952624 ]\n",
            " [ 2.7801766  -1.9797437 ]\n",
            " [-2.0202863   2.6199863 ]\n",
            " [ 1.7189884   2.7860796 ]\n",
            " [-2.2953136   2.4586995 ]\n",
            " [ 2.829503    2.0694685 ]\n",
            " [ 0.6341237   2.6008413 ]\n",
            " [-2.0461895   2.1097896 ]\n",
            " [ 2.014272    1.0278043 ]\n",
            " [ 2.6823      1.6891004 ]\n",
            " [-2.2849615  -1.6309304 ]\n",
            " [ 2.6711478   2.7546718 ]\n",
            " [ 2.648128    2.6784542 ]\n",
            " [ 2.2122955   1.3225845 ]\n",
            " [-1.9699311   2.881978  ]\n",
            " [-0.20111744 -1.53213   ]\n",
            " [ 1.3168471  -1.4348073 ]\n",
            " [-1.4762282  -2.0318353 ]\n",
            " [ 0.4659851  -2.0105147 ]\n",
            " [-2.2797294   2.3977244 ]\n",
            " [-2.1572108   2.8317087 ]\n",
            " [-1.4107777   1.2136374 ]\n",
            " [-2.0016658  -1.330682  ]\n",
            " [ 2.7971249  -1.8306434 ]\n",
            " [ 0.08501171  2.6001248 ]\n",
            " [-2.2458708  -0.46797654]\n",
            " [ 1.8460666   2.650461  ]\n",
            " [ 0.4458086  -0.21723253]\n",
            " [ 2.5876267  -1.0764767 ]\n",
            " [ 2.6495318   0.5788762 ]\n",
            " [ 2.5557153   1.4269077 ]\n",
            " [-1.3721513  -2.29492   ]\n",
            " [ 1.0710695   1.0886183 ]\n",
            " [ 1.7744043   1.8354925 ]\n",
            " [ 1.1514527   2.433872  ]\n",
            " [ 2.1723766   1.851061  ]\n",
            " [-1.6580434   2.0536458 ]\n",
            " [ 2.5264697   2.0916226 ]\n",
            " [-1.2689555  -1.9146684 ]\n",
            " [ 1.6783754   2.828823  ]\n",
            " [ 1.3641093  -1.8761348 ]\n",
            " [ 2.4408474  -1.6116209 ]\n",
            " [ 1.0866302  -2.1413014 ]\n",
            " [ 0.19573689  2.2127566 ]\n",
            " [ 1.760284    1.0315537 ]\n",
            " [ 2.8053157  -1.5400258 ]\n",
            " [-1.9144567  -2.2204666 ]\n",
            " [ 2.5822763   2.773787  ]\n",
            " [-2.132478    2.40574   ]\n",
            " [-2.3374336   1.2511712 ]\n",
            " [-1.0449846   2.7548642 ]\n",
            " [-1.6689636   2.703223  ]\n",
            " [-1.9239326   2.3503215 ]\n",
            " [ 2.4976952   0.7989349 ]\n",
            " [-1.4232723   2.745392  ]\n",
            " [-0.8279269   2.6205413 ]\n",
            " [ 2.5654485  -0.82400644]\n",
            " [ 2.724483    2.8252168 ]\n",
            " [-1.4101758   2.092049  ]\n",
            " [ 2.643982   -1.7419875 ]\n",
            " [ 2.4144206   2.1329584 ]\n",
            " [-1.9647565   2.7671785 ]\n",
            " [-0.47228438  0.8876479 ]\n",
            " [ 2.5569167  -2.0330749 ]\n",
            " [ 1.2795113   0.7931759 ]\n",
            " [-1.705342    2.2245915 ]\n",
            " [-1.3897305   2.561885  ]\n",
            " [ 2.5363991  -1.8719859 ]\n",
            " [ 1.0054746   0.7937496 ]\n",
            " [ 2.861812    1.7891812 ]\n",
            " [-1.9327574   1.9105357 ]\n",
            " [-1.9368728  -1.0938063 ]\n",
            " [ 2.6584725  -1.7086234 ]\n",
            " [ 1.6759458   2.7122052 ]\n",
            " [-1.0295368  -2.2940955 ]\n",
            " [ 2.3342743  -1.7395066 ]\n",
            " [ 2.484432   -2.2198207 ]\n",
            " [ 1.9316114   1.6358579 ]\n",
            " [ 1.8603753   2.6184661 ]\n",
            " [ 2.7246082  -1.7878104 ]\n",
            " [-0.63352144  2.0808058 ]\n",
            " [ 2.8358471  -2.0049202 ]\n",
            " [ 2.1994982   2.3369277 ]\n",
            " [ 2.6579535  -2.2084777 ]\n",
            " [-2.1297758   2.2655241 ]\n",
            " [ 2.6106393   1.5590084 ]\n",
            " [ 2.849542   -1.5366626 ]\n",
            " [-1.7078302  -2.0093887 ]\n",
            " [-2.0795138   2.5967145 ]\n",
            " [ 2.8164697   2.5094426 ]\n",
            " [ 1.211886    0.20324749]\n",
            " [ 2.8107352   2.8624344 ]\n",
            " [ 2.7959578  -0.36069423]\n",
            " [-1.9582194   2.0925124 ]\n",
            " [ 2.7431548   1.2401718 ]\n",
            " [ 2.3376184   2.2954443 ]\n",
            " [ 1.9120882  -1.9578531 ]\n",
            " [-2.1597624   2.4243803 ]\n",
            " [ 2.5209465   2.4628398 ]\n",
            " [ 2.1220067  -1.5130119 ]\n",
            " [-1.1935298   2.3690836 ]\n",
            " [ 0.12934478  2.8028412 ]\n",
            " [-1.447331    0.01298548]\n",
            " [ 2.7748106   2.7332935 ]\n",
            " [ 2.2949111  -2.299057  ]\n",
            " [-1.9066203   2.3053312 ]\n",
            " [ 2.464407   -1.5581281 ]\n",
            " [ 2.3786519  -1.3126695 ]\n",
            " [-0.96810764  1.147285  ]\n",
            " [ 1.2943039  -1.6559131 ]\n",
            " [ 0.07775377  2.227723  ]\n",
            " [ 2.2799351  -2.3176599 ]\n",
            " [ 2.9009628   2.065329  ]\n",
            " [ 2.6150732  -0.68429774]\n",
            " [-0.20934542  2.7511795 ]\n",
            " [ 2.7989433  -1.5258992 ]\n",
            " [ 2.8151052  -1.7234397 ]\n",
            " [ 1.6932207   2.8499236 ]\n",
            " [-1.3608353   2.5639288 ]\n",
            " [ 2.8474557  -2.3650753 ]\n",
            " [ 2.7544265   1.3684742 ]\n",
            " [ 1.8024966   2.2389686 ]\n",
            " [ 2.6435907  -1.9251342 ]\n",
            " [-1.5502377  -0.95222956]\n",
            " [ 2.5720925   2.628462  ]\n",
            " [ 0.43233526 -2.1822298 ]\n",
            " [ 1.6446894  -1.8160778 ]\n",
            " [-0.4944921  -1.8894066 ]\n",
            " [ 0.72065246  2.6199667 ]\n",
            " [ 2.4064224  -2.1306758 ]\n",
            " [ 2.2770648  -0.49994734]\n",
            " [-1.4537264   2.4815478 ]\n",
            " [ 0.950881    2.824629  ]\n",
            " [ 2.4854195  -1.5637901 ]\n",
            " [ 2.784511   -2.0581348 ]\n",
            " [ 1.4919364   2.2300413 ]\n",
            " [-1.9104348   2.7653627 ]\n",
            " [ 1.5585023   2.3110754 ]\n",
            " [-0.17852862  2.3474703 ]\n",
            " [ 0.0333663  -2.1561255 ]\n",
            " [ 2.6927104  -0.52014405]\n",
            " [-2.231978   -1.0488726 ]\n",
            " [ 1.3543928  -1.883163  ]\n",
            " [-1.8429253   2.4908302 ]\n",
            " [-1.2118145   0.05088608]\n",
            " [-1.3909922   2.7421806 ]\n",
            " [-1.2095323   2.4125125 ]\n",
            " [ 2.69685     2.8153784 ]\n",
            " [ 1.8337464   2.1913962 ]\n",
            " [ 2.7902553  -1.7292066 ]\n",
            " [ 0.8543191   2.6904702 ]\n",
            " [ 0.29159608  0.40817806]\n",
            " [-1.2566801   2.1525373 ]\n",
            " [ 2.7492805   1.7740128 ]\n",
            " [ 2.050447    1.5438207 ]\n",
            " [ 2.3933504   2.7746634 ]\n",
            " [ 2.762715    2.7552383 ]\n",
            " [ 0.11561216 -1.3179238 ]\n",
            " [ 2.608551   -1.4754394 ]\n",
            " [ 2.522436   -2.3069701 ]\n",
            " [-1.6973332   2.2672226 ]\n",
            " [ 1.2372683   0.5755195 ]\n",
            " [ 2.7401233   0.9402429 ]\n",
            " [-1.624405    1.6713061 ]\n",
            " [ 1.7504722  -1.4988253 ]\n",
            " [ 1.4718908   0.07725255]\n",
            " [ 2.7481031  -2.050321  ]\n",
            " [ 0.24425858 -0.47043765]\n",
            " [ 2.5856125   2.3757265 ]\n",
            " [-1.0546073   2.507427  ]\n",
            " [-1.9485356  -1.228729  ]\n",
            " [ 1.1498599   2.410346  ]\n",
            " [ 2.1256576  -0.9252519 ]\n",
            " [ 0.67089844 -2.131072  ]\n",
            " [ 2.681002   -0.20728242]\n",
            " [ 1.7656156  -2.3261836 ]\n",
            " [-1.754266   -1.7200826 ]\n",
            " [ 2.8304713  -2.1534946 ]\n",
            " [ 1.4606344  -2.1094947 ]\n",
            " [ 2.4945722   1.095926  ]\n",
            " [ 1.8638799  -1.8300247 ]\n",
            " [ 2.593221   -2.2896411 ]\n",
            " [ 1.6081269   2.770547  ]\n",
            " [ 0.27721268  1.6439613 ]\n",
            " [ 2.7131815   2.6649895 ]\n",
            " [-0.9663895   2.8496625 ]\n",
            " [-2.2744825   2.8120382 ]\n",
            " [ 2.7646794  -0.9329873 ]\n",
            " [ 1.6459603   1.4555273 ]\n",
            " [ 1.2015244  -2.3592901 ]\n",
            " [ 2.0324147   1.1318831 ]\n",
            " [ 2.671604   -1.3310914 ]\n",
            " [-2.052582    2.6678665 ]\n",
            " [ 2.2276998  -0.2415186 ]\n",
            " [-2.2890909  -1.115474  ]\n",
            " [-2.0172272   2.691542  ]\n",
            " [ 2.710132    2.4728384 ]\n",
            " [ 2.559688    1.6999451 ]\n",
            " [ 2.007752    0.30185   ]\n",
            " [ 2.8339374  -1.4838176 ]\n",
            " [ 2.4891534   1.0727779 ]\n",
            " [ 2.495877    1.9417614 ]\n",
            " [ 2.715542   -1.2699704 ]\n",
            " [-2.1799233   2.7962027 ]\n",
            " [ 1.1657624  -1.1654001 ]\n",
            " [ 1.6954303   0.9153137 ]\n",
            " [ 2.7254255  -1.5168266 ]\n",
            " [-1.8381574   0.7971116 ]\n",
            " [-2.313991   -2.3476593 ]\n",
            " [-2.124981    2.5709524 ]\n",
            " [ 1.9996498   1.2923071 ]\n",
            " [ 2.7750664  -2.1901405 ]\n",
            " [ 2.7091107   2.0444348 ]\n",
            " [-1.9177631   2.7819219 ]\n",
            " [ 2.7203882  -1.9695591 ]\n",
            " [ 2.179116   -0.1028848 ]\n",
            " [ 2.3132641   2.6495023 ]\n",
            " [-1.9953749   2.8006837 ]\n",
            " [ 2.2862444  -1.0323337 ]\n",
            " [ 2.8397593  -2.318106  ]\n",
            " [-1.2722872   2.785776  ]\n",
            " [-1.8583593   2.6614072 ]\n",
            " [-1.5745083   1.4870595 ]\n",
            " [-2.1604497   2.630166  ]\n",
            " [-2.2839653   2.605033  ]\n",
            " [-2.0611622   2.6833825 ]\n",
            " [ 2.7664483   1.8925829 ]\n",
            " [-1.7997203  -0.21078774]\n",
            " [-1.6915394   2.7873473 ]\n",
            " [-1.3887994  -2.1483555 ]\n",
            " [ 2.8322847  -1.5162437 ]\n",
            " [ 2.761152   -2.258652  ]\n",
            " [-2.2360244  -0.52349424]\n",
            " [-1.7577384   2.5167694 ]\n",
            " [-2.2665002  -1.2933255 ]\n",
            " [ 2.7856193   2.4663155 ]\n",
            " [-2.3441327   0.377635  ]\n",
            " [ 0.63554996 -0.07557455]\n",
            " [ 2.8253603  -1.8312006 ]\n",
            " [ 2.009998    0.13113695]\n",
            " [ 2.6757424  -1.9758763 ]\n",
            " [-2.3631744  -0.8335856 ]\n",
            " [-1.0178878  -0.3933008 ]\n",
            " [-0.6533724   2.0773332 ]\n",
            " [ 2.2820342   2.090356  ]\n",
            " [-0.2826298  -0.06911895]\n",
            " [ 2.6115184  -0.5748172 ]\n",
            " [ 2.7093956  -2.0190985 ]\n",
            " [-1.9405963   1.436221  ]\n",
            " [-2.127129    1.108408  ]\n",
            " [ 2.5455267   2.4495623 ]\n",
            " [ 2.7339282   0.8497526 ]\n",
            " [ 1.7290056  -0.42936763]\n",
            " [ 1.746954    2.7487385 ]\n",
            " [ 0.05515524  2.68199   ]\n",
            " [ 2.6396904  -1.3711578 ]\n",
            " [ 2.5096564  -1.8966714 ]\n",
            " [ 2.3686883   1.5229906 ]\n",
            " [ 1.1491795   2.7295656 ]\n",
            " [ 2.6825607  -0.4789174 ]\n",
            " [-1.2992252  -2.3232248 ]\n",
            " [ 2.3940403  -1.7569404 ]\n",
            " [-1.1640817   2.6120265 ]\n",
            " [-2.2315805   2.6603904 ]\n",
            " [ 2.7875013  -2.1232986 ]\n",
            " [ 2.769821    1.0619402 ]\n",
            " [ 1.7794346  -1.8972526 ]\n",
            " [-1.6021613  -1.731295  ]\n",
            " [ 2.760505   -2.3439262 ]\n",
            " [-2.1236675   2.724581  ]\n",
            " [-0.74139863  2.4956014 ]\n",
            " [ 1.9685106  -2.0468707 ]\n",
            " [ 2.56912    -1.6255016 ]\n",
            " [ 2.250918    2.3605807 ]\n",
            " [ 2.4424958   2.7728417 ]\n",
            " [ 2.3112595   2.486933  ]\n",
            " [-1.652346   -0.8321239 ]\n",
            " [ 2.6751754  -2.337639  ]\n",
            " [-2.3540812   2.5917234 ]\n",
            " [-1.7907375   2.5037894 ]\n",
            " [ 2.753557   -2.2118275 ]\n",
            " [ 1.0614041  -1.9266735 ]\n",
            " [ 2.7139735  -2.1408002 ]\n",
            " [-1.473281    2.762387  ]\n",
            " [ 2.6878383   2.029424  ]\n",
            " [-1.9670434  -0.18286963]\n",
            " [-1.7140845   2.6727734 ]\n",
            " [ 2.2004168  -1.3559163 ]\n",
            " [-1.3310841   0.29888266]\n",
            " [ 2.6570222   2.6622903 ]\n",
            " [ 2.7495382  -0.5370745 ]\n",
            " [ 2.8690777   0.23451912]\n",
            " [ 2.230583    2.771784  ]\n",
            " [ 2.2779102  -1.424103  ]\n",
            " [ 2.1142626  -2.098485  ]\n",
            " [ 0.8688485   2.6656327 ]\n",
            " [-0.35475785 -1.9225571 ]\n",
            " [ 2.7715125   2.7335894 ]\n",
            " [ 2.1564934  -1.8904974 ]\n",
            " [ 2.594576   -1.2142209 ]\n",
            " [ 2.7885613  -0.12009999]\n",
            " [ 2.255032   -0.20421411]\n",
            " [ 2.3286126  -2.3140094 ]\n",
            " [ 2.383723    2.5956695 ]\n",
            " [-1.282976    0.76206744]\n",
            " [ 1.3318815   1.9655465 ]\n",
            " [ 2.062395   -2.2656693 ]\n",
            " [ 2.599848   -1.9092222 ]\n",
            " [ 2.8402226   2.5582256 ]\n",
            " [ 2.3282096   1.5413494 ]\n",
            " [ 1.7514756   0.01848166]\n",
            " [ 2.8083265  -2.0339274 ]\n",
            " [ 2.796908    2.4703112 ]\n",
            " [ 2.8066015  -0.32194185]\n",
            " [ 2.8181798   2.4042737 ]\n",
            " [ 2.7717655   0.8934875 ]\n",
            " [ 2.7960405   2.5292659 ]\n",
            " [-1.0074792   2.7519755 ]\n",
            " [ 0.7757833   0.6057264 ]\n",
            " [-0.02581987  2.37472   ]\n",
            " [-1.4186261   2.7455623 ]\n",
            " [-1.9692295   2.573281  ]\n",
            " [ 2.6452327  -1.5927432 ]\n",
            " [-1.8147507   2.8490112 ]\n",
            " [-2.2389956   0.17219143]\n",
            " [-2.3064663   2.8409388 ]\n",
            " [-0.91773564  2.5128756 ]\n",
            " [ 0.01855999  2.6550007 ]\n",
            " [ 2.761812    0.99223256]\n",
            " [-0.8260569   0.24484354]\n",
            " [ 2.4996064   1.8877255 ]\n",
            " [-0.06586961 -1.8975177 ]\n",
            " [-2.1107213   2.783873  ]\n",
            " [ 0.7576792  -2.2893782 ]\n",
            " [ 2.8483508   2.2061927 ]\n",
            " [ 2.1606286   1.8266462 ]\n",
            " [ 2.0451372   2.6300223 ]\n",
            " [-2.2799156   2.6924858 ]\n",
            " [-2.173927    2.4340339 ]\n",
            " [-1.1130235   2.6623204 ]\n",
            " [-1.749313   -0.98337996]\n",
            " [-1.4670795   2.7756429 ]\n",
            " [ 2.0069704  -0.40997094]\n",
            " [-2.3092763   2.8334808 ]\n",
            " [ 1.1237434   1.9433774 ]\n",
            " [ 1.0401918   2.3920784 ]\n",
            " [-1.8789464   2.2655437 ]\n",
            " [ 2.6783621   2.234581  ]\n",
            " [ 1.6644781   2.6280673 ]\n",
            " [ 2.382309    1.5671397 ]\n",
            " [ 2.0186656  -1.2805644 ]\n",
            " [ 2.7183242   2.697927  ]\n",
            " [ 2.666568    2.6967123 ]\n",
            " [ 1.9422914   2.1615283 ]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.86 [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1] [1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0\n",
            " 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 0\n",
            " 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
            " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0\n",
            " 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1]\n",
            "##### labels.shape:  (500,) preds.shape:  (500,)\n",
            "Loading Best\n",
            "Eval (copa, Val): 100% 16/16 [00:01<00:00, 14.05it/s]\n",
            "##### get_accumulated(), logits :  [[-2.1504474   2.4534202 ]\n",
            " [-0.31400448  2.6491735 ]\n",
            " [ 2.3787887  -2.2828372 ]\n",
            " [-2.3547294   2.3805358 ]\n",
            " [ 1.656356    2.021311  ]\n",
            " [ 2.504845    2.177699  ]\n",
            " [-0.7917392   2.6441448 ]\n",
            " [-1.8507      2.8213634 ]\n",
            " [ 0.7726247  -2.1173246 ]\n",
            " [-2.1445858   2.338613  ]\n",
            " [-1.9084153   2.221878  ]\n",
            " [ 2.7008462  -2.2023838 ]\n",
            " [ 1.1046677   1.1503321 ]\n",
            " [ 2.4834106  -2.1407824 ]\n",
            " [ 0.0980434   0.82440054]\n",
            " [-1.9721334  -0.09647377]\n",
            " [ 2.5261095   1.327853  ]\n",
            " [-0.49595577  2.012892  ]\n",
            " [-1.2534387   2.8292344 ]\n",
            " [ 0.2122598  -1.599427  ]\n",
            " [ 2.6300726  -1.6528119 ]\n",
            " [-2.0097258   1.8879483 ]\n",
            " [ 1.8323492   1.8441513 ]\n",
            " [-0.21102038  2.8275988 ]\n",
            " [-1.3486925   2.768861  ]\n",
            " [ 1.0180725  -0.9044738 ]\n",
            " [-2.185722    2.5609143 ]\n",
            " [ 0.08529936  1.9263699 ]\n",
            " [-1.7454696   2.2201583 ]\n",
            " [ 2.1367497  -2.2370942 ]\n",
            " [-1.0039271  -1.6242585 ]\n",
            " [-1.0517178   2.561564  ]\n",
            " [ 0.28368396  1.7080874 ]\n",
            " [ 2.7681048   2.7869997 ]\n",
            " [ 1.1358058   1.0058817 ]\n",
            " [ 2.7059193  -1.5833079 ]\n",
            " [-2.1885974   2.4265342 ]\n",
            " [-1.4830813   0.40009457]\n",
            " [ 2.6898687  -1.670424  ]\n",
            " [ 2.6120417   2.7556593 ]\n",
            " [-1.7008988   1.2948626 ]\n",
            " [ 1.3764393   2.4242496 ]\n",
            " [ 2.492418    2.2496006 ]\n",
            " [-1.8836321  -1.2544489 ]\n",
            " [ 2.4895034  -0.5148301 ]\n",
            " [ 1.8409883  -2.1549587 ]\n",
            " [-1.7317511  -0.84516156]\n",
            " [ 0.2634111   1.3074747 ]\n",
            " [ 0.3116999   2.8055155 ]\n",
            " [ 1.1905214  -0.77569044]\n",
            " [ 2.7959752  -0.7829282 ]\n",
            " [ 2.7287395   2.4053016 ]\n",
            " [ 1.8542593  -1.0563898 ]\n",
            " [-1.4566295   2.6775637 ]\n",
            " [ 1.7034225  -0.23490815]\n",
            " [ 1.4475359   1.1688205 ]\n",
            " [ 2.4187453  -1.4992671 ]\n",
            " [-2.148481    0.24420089]\n",
            " [ 1.9199437  -2.3411045 ]\n",
            " [ 2.5929494   1.5155647 ]\n",
            " [-2.1047654   2.6600935 ]\n",
            " [ 1.1248906  -2.0205321 ]\n",
            " [-0.6624929   2.6249466 ]\n",
            " [-1.8529112  -2.1390018 ]\n",
            " [ 0.04473776  2.8237526 ]\n",
            " [-1.8751397   2.5598452 ]\n",
            " [ 1.5552403   2.071562  ]\n",
            " [ 2.6386883  -2.2806764 ]\n",
            " [ 1.2286118   1.4211997 ]\n",
            " [ 2.5255196  -2.1865966 ]\n",
            " [ 2.863398   -1.146078  ]\n",
            " [-1.6639885  -0.03650255]\n",
            " [ 2.6861794  -1.3885306 ]\n",
            " [-1.2137506   2.8103027 ]\n",
            " [-1.2005906   2.664173  ]\n",
            " [ 1.3120422  -2.1071286 ]\n",
            " [ 2.7448506   0.70155287]\n",
            " [-2.163786    2.806927  ]\n",
            " [ 1.3504974  -2.3048913 ]\n",
            " [-0.03019945  2.7939026 ]\n",
            " [-1.3368945  -0.03361408]\n",
            " [-1.0004156   1.7316871 ]\n",
            " [-1.8065833  -1.2079008 ]\n",
            " [-0.37161562  2.472645  ]\n",
            " [-2.2916853   2.8050609 ]\n",
            " [-1.0967711   2.3782067 ]\n",
            " [-1.6020447  -2.308028  ]\n",
            " [-2.370132    2.5251503 ]\n",
            " [-1.0446719   2.6169431 ]\n",
            " [ 1.0619051   2.805765  ]\n",
            " [ 1.8265495   1.9976552 ]\n",
            " [ 2.5351183  -2.2563794 ]\n",
            " [ 0.58677685  2.742555  ]\n",
            " [ 2.551235   -2.083225  ]\n",
            " [-2.2735314   1.3566895 ]\n",
            " [ 2.7651117  -1.9309533 ]\n",
            " [ 2.4831183   2.8140697 ]\n",
            " [ 2.3407955  -2.1238365 ]\n",
            " [ 2.5944357  -0.54668844]\n",
            " [ 2.6703117  -0.7436198 ]\n",
            " [ 1.7739595  -2.1859055 ]\n",
            " [ 1.864688    2.0937655 ]\n",
            " [-2.1123383   2.0555677 ]\n",
            " [-1.9949187   1.9852138 ]\n",
            " [-0.11322264  2.454548  ]\n",
            " [ 2.881589    0.57770205]\n",
            " [ 2.4017303  -2.1870909 ]\n",
            " [-2.2760315   1.7800196 ]\n",
            " [-2.0791657   2.6210353 ]\n",
            " [-1.7350173   2.540205  ]\n",
            " [-2.125161   -0.39300177]\n",
            " [ 2.6080174  -0.54411125]\n",
            " [-1.1874607   2.6557035 ]\n",
            " [-0.83106667  2.7796137 ]\n",
            " [ 0.9486654  -1.7208948 ]\n",
            " [-1.2538512   1.1453508 ]\n",
            " [-1.4274594   2.5634854 ]\n",
            " [ 2.7576728  -2.1551235 ]\n",
            " [ 2.8606763  -2.3416007 ]\n",
            " [ 2.4934049   2.8744974 ]\n",
            " [ 2.4220893  -1.7922971 ]\n",
            " [ 1.9344692  -1.8525535 ]\n",
            " [ 2.5127797   2.4628563 ]\n",
            " [ 2.8280761   0.59217477]\n",
            " [-0.9336371   2.3595335 ]\n",
            " [-2.147406    2.6675804 ]\n",
            " [ 1.3672768  -0.6711211 ]\n",
            " [ 2.1046817  -2.27565   ]\n",
            " [ 2.6225984  -1.9318391 ]\n",
            " [ 2.5919082  -2.2133758 ]\n",
            " [-2.183046    2.5937896 ]\n",
            " [-1.2297392   0.21158254]\n",
            " [-1.856209    2.7465224 ]\n",
            " [-2.0700493   2.6430209 ]\n",
            " [-1.8892483   0.9095315 ]\n",
            " [-2.181922    2.7453547 ]\n",
            " [-1.3625976   2.6180122 ]\n",
            " [-2.253281    2.7698407 ]\n",
            " [ 2.786565    2.7534926 ]\n",
            " [ 2.0851176   1.431068  ]\n",
            " [ 2.287336   -1.9120567 ]\n",
            " [ 2.2141676  -2.1916018 ]\n",
            " [-2.1534488   2.721521  ]\n",
            " [ 1.9805932   2.7538455 ]\n",
            " [ 2.3652356  -1.5287501 ]\n",
            " [-0.11422309  2.1907218 ]\n",
            " [-2.2480164   2.4952624 ]\n",
            " [ 2.7801766  -1.9797437 ]\n",
            " [-2.0202863   2.6199863 ]\n",
            " [ 1.7189884   2.7860796 ]\n",
            " [-2.2953136   2.4586995 ]\n",
            " [ 2.829503    2.0694685 ]\n",
            " [ 0.6341237   2.6008413 ]\n",
            " [-2.0461895   2.1097896 ]\n",
            " [ 2.014272    1.0278043 ]\n",
            " [ 2.6823      1.6891004 ]\n",
            " [-2.2849615  -1.6309304 ]\n",
            " [ 2.6711478   2.7546718 ]\n",
            " [ 2.648128    2.6784542 ]\n",
            " [ 2.2122955   1.3225845 ]\n",
            " [-1.9699311   2.881978  ]\n",
            " [-0.20111744 -1.53213   ]\n",
            " [ 1.3168471  -1.4348073 ]\n",
            " [-1.4762282  -2.0318353 ]\n",
            " [ 0.4659851  -2.0105147 ]\n",
            " [-2.2797294   2.3977244 ]\n",
            " [-2.1572108   2.8317087 ]\n",
            " [-1.4107777   1.2136374 ]\n",
            " [-2.0016658  -1.330682  ]\n",
            " [ 2.7971249  -1.8306434 ]\n",
            " [ 0.08501171  2.6001248 ]\n",
            " [-2.2458708  -0.46797654]\n",
            " [ 1.8460666   2.650461  ]\n",
            " [ 0.4458086  -0.21723253]\n",
            " [ 2.5876267  -1.0764767 ]\n",
            " [ 2.6495318   0.5788762 ]\n",
            " [ 2.5557153   1.4269077 ]\n",
            " [-1.3721513  -2.29492   ]\n",
            " [ 1.0710695   1.0886183 ]\n",
            " [ 1.7744043   1.8354925 ]\n",
            " [ 1.1514527   2.433872  ]\n",
            " [ 2.1723766   1.851061  ]\n",
            " [-1.6580434   2.0536458 ]\n",
            " [ 2.5264697   2.0916226 ]\n",
            " [-1.2689555  -1.9146684 ]\n",
            " [ 1.6783754   2.828823  ]\n",
            " [ 1.3641093  -1.8761348 ]\n",
            " [ 2.4408474  -1.6116209 ]\n",
            " [ 1.0866302  -2.1413014 ]\n",
            " [ 0.19573689  2.2127566 ]\n",
            " [ 1.760284    1.0315537 ]\n",
            " [ 2.8053157  -1.5400258 ]\n",
            " [-1.9144567  -2.2204666 ]\n",
            " [ 2.5822763   2.773787  ]\n",
            " [-2.132478    2.40574   ]\n",
            " [-2.3374336   1.2511712 ]\n",
            " [-1.0449846   2.7548642 ]\n",
            " [-1.6689636   2.703223  ]\n",
            " [-1.9239326   2.3503215 ]\n",
            " [ 2.4976952   0.7989349 ]\n",
            " [-1.4232723   2.745392  ]\n",
            " [-0.8279269   2.6205413 ]\n",
            " [ 2.5654485  -0.82400644]\n",
            " [ 2.724483    2.8252168 ]\n",
            " [-1.4101758   2.092049  ]\n",
            " [ 2.643982   -1.7419875 ]\n",
            " [ 2.4144206   2.1329584 ]\n",
            " [-1.9647565   2.7671785 ]\n",
            " [-0.47228438  0.8876479 ]\n",
            " [ 2.5569167  -2.0330749 ]\n",
            " [ 1.2795113   0.7931759 ]\n",
            " [-1.705342    2.2245915 ]\n",
            " [-1.3897305   2.561885  ]\n",
            " [ 2.5363991  -1.8719859 ]\n",
            " [ 1.0054746   0.7937496 ]\n",
            " [ 2.861812    1.7891812 ]\n",
            " [-1.9327574   1.9105357 ]\n",
            " [-1.9368728  -1.0938063 ]\n",
            " [ 2.6584725  -1.7086234 ]\n",
            " [ 1.6759458   2.7122052 ]\n",
            " [-1.0295368  -2.2940955 ]\n",
            " [ 2.3342743  -1.7395066 ]\n",
            " [ 2.484432   -2.2198207 ]\n",
            " [ 1.9316114   1.6358579 ]\n",
            " [ 1.8603753   2.6184661 ]\n",
            " [ 2.7246082  -1.7878104 ]\n",
            " [-0.63352144  2.0808058 ]\n",
            " [ 2.8358471  -2.0049202 ]\n",
            " [ 2.1994982   2.3369277 ]\n",
            " [ 2.6579535  -2.2084777 ]\n",
            " [-2.1297758   2.2655241 ]\n",
            " [ 2.6106393   1.5590084 ]\n",
            " [ 2.849542   -1.5366626 ]\n",
            " [-1.7078302  -2.0093887 ]\n",
            " [-2.0795138   2.5967145 ]\n",
            " [ 2.8164697   2.5094426 ]\n",
            " [ 1.211886    0.20324749]\n",
            " [ 2.8107352   2.8624344 ]\n",
            " [ 2.7959578  -0.36069423]\n",
            " [-1.9582194   2.0925124 ]\n",
            " [ 2.7431548   1.2401718 ]\n",
            " [ 2.3376184   2.2954443 ]\n",
            " [ 1.9120882  -1.9578531 ]\n",
            " [-2.1597624   2.4243803 ]\n",
            " [ 2.5209465   2.4628398 ]\n",
            " [ 2.1220067  -1.5130119 ]\n",
            " [-1.1935298   2.3690836 ]\n",
            " [ 0.12934478  2.8028412 ]\n",
            " [-1.447331    0.01298548]\n",
            " [ 2.7748106   2.7332935 ]\n",
            " [ 2.2949111  -2.299057  ]\n",
            " [-1.9066203   2.3053312 ]\n",
            " [ 2.464407   -1.5581281 ]\n",
            " [ 2.3786519  -1.3126695 ]\n",
            " [-0.96810764  1.147285  ]\n",
            " [ 1.2943039  -1.6559131 ]\n",
            " [ 0.07775377  2.227723  ]\n",
            " [ 2.2799351  -2.3176599 ]\n",
            " [ 2.9009628   2.065329  ]\n",
            " [ 2.6150732  -0.68429774]\n",
            " [-0.20934542  2.7511795 ]\n",
            " [ 2.7989433  -1.5258992 ]\n",
            " [ 2.8151052  -1.7234397 ]\n",
            " [ 1.6932207   2.8499236 ]\n",
            " [-1.3608353   2.5639288 ]\n",
            " [ 2.8474557  -2.3650753 ]\n",
            " [ 2.7544265   1.3684742 ]\n",
            " [ 1.8024966   2.2389686 ]\n",
            " [ 2.6435907  -1.9251342 ]\n",
            " [-1.5502377  -0.95222956]\n",
            " [ 2.5720925   2.628462  ]\n",
            " [ 0.43233526 -2.1822298 ]\n",
            " [ 1.6446894  -1.8160778 ]\n",
            " [-0.4944921  -1.8894066 ]\n",
            " [ 0.72065246  2.6199667 ]\n",
            " [ 2.4064224  -2.1306758 ]\n",
            " [ 2.2770648  -0.49994734]\n",
            " [-1.4537264   2.4815478 ]\n",
            " [ 0.950881    2.824629  ]\n",
            " [ 2.4854195  -1.5637901 ]\n",
            " [ 2.784511   -2.0581348 ]\n",
            " [ 1.4919364   2.2300413 ]\n",
            " [-1.9104348   2.7653627 ]\n",
            " [ 1.5585023   2.3110754 ]\n",
            " [-0.17852862  2.3474703 ]\n",
            " [ 0.0333663  -2.1561255 ]\n",
            " [ 2.6927104  -0.52014405]\n",
            " [-2.231978   -1.0488726 ]\n",
            " [ 1.3543928  -1.883163  ]\n",
            " [-1.8429253   2.4908302 ]\n",
            " [-1.2118145   0.05088608]\n",
            " [-1.3909922   2.7421806 ]\n",
            " [-1.2095323   2.4125125 ]\n",
            " [ 2.69685     2.8153784 ]\n",
            " [ 1.8337464   2.1913962 ]\n",
            " [ 2.7902553  -1.7292066 ]\n",
            " [ 0.8543191   2.6904702 ]\n",
            " [ 0.29159608  0.40817806]\n",
            " [-1.2566801   2.1525373 ]\n",
            " [ 2.7492805   1.7740128 ]\n",
            " [ 2.050447    1.5438207 ]\n",
            " [ 2.3933504   2.7746634 ]\n",
            " [ 2.762715    2.7552383 ]\n",
            " [ 0.11561216 -1.3179238 ]\n",
            " [ 2.608551   -1.4754394 ]\n",
            " [ 2.522436   -2.3069701 ]\n",
            " [-1.6973332   2.2672226 ]\n",
            " [ 1.2372683   0.5755195 ]\n",
            " [ 2.7401233   0.9402429 ]\n",
            " [-1.624405    1.6713061 ]\n",
            " [ 1.7504722  -1.4988253 ]\n",
            " [ 1.4718908   0.07725255]\n",
            " [ 2.7481031  -2.050321  ]\n",
            " [ 0.24425858 -0.47043765]\n",
            " [ 2.5856125   2.3757265 ]\n",
            " [-1.0546073   2.507427  ]\n",
            " [-1.9485356  -1.228729  ]\n",
            " [ 1.1498599   2.410346  ]\n",
            " [ 2.1256576  -0.9252519 ]\n",
            " [ 0.67089844 -2.131072  ]\n",
            " [ 2.681002   -0.20728242]\n",
            " [ 1.7656156  -2.3261836 ]\n",
            " [-1.754266   -1.7200826 ]\n",
            " [ 2.8304713  -2.1534946 ]\n",
            " [ 1.4606344  -2.1094947 ]\n",
            " [ 2.4945722   1.095926  ]\n",
            " [ 1.8638799  -1.8300247 ]\n",
            " [ 2.593221   -2.2896411 ]\n",
            " [ 1.6081269   2.770547  ]\n",
            " [ 0.27721268  1.6439613 ]\n",
            " [ 2.7131815   2.6649895 ]\n",
            " [-0.9663895   2.8496625 ]\n",
            " [-2.2744825   2.8120382 ]\n",
            " [ 2.7646794  -0.9329873 ]\n",
            " [ 1.6459603   1.4555273 ]\n",
            " [ 1.2015244  -2.3592901 ]\n",
            " [ 2.0324147   1.1318831 ]\n",
            " [ 2.671604   -1.3310914 ]\n",
            " [-2.052582    2.6678665 ]\n",
            " [ 2.2276998  -0.2415186 ]\n",
            " [-2.2890909  -1.115474  ]\n",
            " [-2.0172272   2.691542  ]\n",
            " [ 2.710132    2.4728384 ]\n",
            " [ 2.559688    1.6999451 ]\n",
            " [ 2.007752    0.30185   ]\n",
            " [ 2.8339374  -1.4838176 ]\n",
            " [ 2.4891534   1.0727779 ]\n",
            " [ 2.495877    1.9417614 ]\n",
            " [ 2.715542   -1.2699704 ]\n",
            " [-2.1799233   2.7962027 ]\n",
            " [ 1.1657624  -1.1654001 ]\n",
            " [ 1.6954303   0.9153137 ]\n",
            " [ 2.7254255  -1.5168266 ]\n",
            " [-1.8381574   0.7971116 ]\n",
            " [-2.313991   -2.3476593 ]\n",
            " [-2.124981    2.5709524 ]\n",
            " [ 1.9996498   1.2923071 ]\n",
            " [ 2.7750664  -2.1901405 ]\n",
            " [ 2.7091107   2.0444348 ]\n",
            " [-1.9177631   2.7819219 ]\n",
            " [ 2.7203882  -1.9695591 ]\n",
            " [ 2.179116   -0.1028848 ]\n",
            " [ 2.3132641   2.6495023 ]\n",
            " [-1.9953749   2.8006837 ]\n",
            " [ 2.2862444  -1.0323337 ]\n",
            " [ 2.8397593  -2.318106  ]\n",
            " [-1.2722872   2.785776  ]\n",
            " [-1.8583593   2.6614072 ]\n",
            " [-1.5745083   1.4870595 ]\n",
            " [-2.1604497   2.630166  ]\n",
            " [-2.2839653   2.605033  ]\n",
            " [-2.0611622   2.6833825 ]\n",
            " [ 2.7664483   1.8925829 ]\n",
            " [-1.7997203  -0.21078774]\n",
            " [-1.6915394   2.7873473 ]\n",
            " [-1.3887994  -2.1483555 ]\n",
            " [ 2.8322847  -1.5162437 ]\n",
            " [ 2.761152   -2.258652  ]\n",
            " [-2.2360244  -0.52349424]\n",
            " [-1.7577384   2.5167694 ]\n",
            " [-2.2665002  -1.2933255 ]\n",
            " [ 2.7856193   2.4663155 ]\n",
            " [-2.3441327   0.377635  ]\n",
            " [ 0.63554996 -0.07557455]\n",
            " [ 2.8253603  -1.8312006 ]\n",
            " [ 2.009998    0.13113695]\n",
            " [ 2.6757424  -1.9758763 ]\n",
            " [-2.3631744  -0.8335856 ]\n",
            " [-1.0178878  -0.3933008 ]\n",
            " [-0.6533724   2.0773332 ]\n",
            " [ 2.2820342   2.090356  ]\n",
            " [-0.2826298  -0.06911895]\n",
            " [ 2.6115184  -0.5748172 ]\n",
            " [ 2.7093956  -2.0190985 ]\n",
            " [-1.9405963   1.436221  ]\n",
            " [-2.127129    1.108408  ]\n",
            " [ 2.5455267   2.4495623 ]\n",
            " [ 2.7339282   0.8497526 ]\n",
            " [ 1.7290056  -0.42936763]\n",
            " [ 1.746954    2.7487385 ]\n",
            " [ 0.05515524  2.68199   ]\n",
            " [ 2.6396904  -1.3711578 ]\n",
            " [ 2.5096564  -1.8966714 ]\n",
            " [ 2.3686883   1.5229906 ]\n",
            " [ 1.1491795   2.7295656 ]\n",
            " [ 2.6825607  -0.4789174 ]\n",
            " [-1.2992252  -2.3232248 ]\n",
            " [ 2.3940403  -1.7569404 ]\n",
            " [-1.1640817   2.6120265 ]\n",
            " [-2.2315805   2.6603904 ]\n",
            " [ 2.7875013  -2.1232986 ]\n",
            " [ 2.769821    1.0619402 ]\n",
            " [ 1.7794346  -1.8972526 ]\n",
            " [-1.6021613  -1.731295  ]\n",
            " [ 2.760505   -2.3439262 ]\n",
            " [-2.1236675   2.724581  ]\n",
            " [-0.74139863  2.4956014 ]\n",
            " [ 1.9685106  -2.0468707 ]\n",
            " [ 2.56912    -1.6255016 ]\n",
            " [ 2.250918    2.3605807 ]\n",
            " [ 2.4424958   2.7728417 ]\n",
            " [ 2.3112595   2.486933  ]\n",
            " [-1.652346   -0.8321239 ]\n",
            " [ 2.6751754  -2.337639  ]\n",
            " [-2.3540812   2.5917234 ]\n",
            " [-1.7907375   2.5037894 ]\n",
            " [ 2.753557   -2.2118275 ]\n",
            " [ 1.0614041  -1.9266735 ]\n",
            " [ 2.7139735  -2.1408002 ]\n",
            " [-1.473281    2.762387  ]\n",
            " [ 2.6878383   2.029424  ]\n",
            " [-1.9670434  -0.18286963]\n",
            " [-1.7140845   2.6727734 ]\n",
            " [ 2.2004168  -1.3559163 ]\n",
            " [-1.3310841   0.29888266]\n",
            " [ 2.6570222   2.6622903 ]\n",
            " [ 2.7495382  -0.5370745 ]\n",
            " [ 2.8690777   0.23451912]\n",
            " [ 2.230583    2.771784  ]\n",
            " [ 2.2779102  -1.424103  ]\n",
            " [ 2.1142626  -2.098485  ]\n",
            " [ 0.8688485   2.6656327 ]\n",
            " [-0.35475785 -1.9225571 ]\n",
            " [ 2.7715125   2.7335894 ]\n",
            " [ 2.1564934  -1.8904974 ]\n",
            " [ 2.594576   -1.2142209 ]\n",
            " [ 2.7885613  -0.12009999]\n",
            " [ 2.255032   -0.20421411]\n",
            " [ 2.3286126  -2.3140094 ]\n",
            " [ 2.383723    2.5956695 ]\n",
            " [-1.282976    0.76206744]\n",
            " [ 1.3318815   1.9655465 ]\n",
            " [ 2.062395   -2.2656693 ]\n",
            " [ 2.599848   -1.9092222 ]\n",
            " [ 2.8402226   2.5582256 ]\n",
            " [ 2.3282096   1.5413494 ]\n",
            " [ 1.7514756   0.01848166]\n",
            " [ 2.8083265  -2.0339274 ]\n",
            " [ 2.796908    2.4703112 ]\n",
            " [ 2.8066015  -0.32194185]\n",
            " [ 2.8181798   2.4042737 ]\n",
            " [ 2.7717655   0.8934875 ]\n",
            " [ 2.7960405   2.5292659 ]\n",
            " [-1.0074792   2.7519755 ]\n",
            " [ 0.7757833   0.6057264 ]\n",
            " [-0.02581987  2.37472   ]\n",
            " [-1.4186261   2.7455623 ]\n",
            " [-1.9692295   2.573281  ]\n",
            " [ 2.6452327  -1.5927432 ]\n",
            " [-1.8147507   2.8490112 ]\n",
            " [-2.2389956   0.17219143]\n",
            " [-2.3064663   2.8409388 ]\n",
            " [-0.91773564  2.5128756 ]\n",
            " [ 0.01855999  2.6550007 ]\n",
            " [ 2.761812    0.99223256]\n",
            " [-0.8260569   0.24484354]\n",
            " [ 2.4996064   1.8877255 ]\n",
            " [-0.06586961 -1.8975177 ]\n",
            " [-2.1107213   2.783873  ]\n",
            " [ 0.7576792  -2.2893782 ]\n",
            " [ 2.8483508   2.2061927 ]\n",
            " [ 2.1606286   1.8266462 ]\n",
            " [ 2.0451372   2.6300223 ]\n",
            " [-2.2799156   2.6924858 ]\n",
            " [-2.173927    2.4340339 ]\n",
            " [-1.1130235   2.6623204 ]\n",
            " [-1.749313   -0.98337996]\n",
            " [-1.4670795   2.7756429 ]\n",
            " [ 2.0069704  -0.40997094]\n",
            " [-2.3092763   2.8334808 ]\n",
            " [ 1.1237434   1.9433774 ]\n",
            " [ 1.0401918   2.3920784 ]\n",
            " [-1.8789464   2.2655437 ]\n",
            " [ 2.6783621   2.234581  ]\n",
            " [ 1.6644781   2.6280673 ]\n",
            " [ 2.382309    1.5671397 ]\n",
            " [ 2.0186656  -1.2805644 ]\n",
            " [ 2.7183242   2.697927  ]\n",
            " [ 2.666568    2.6967123 ]\n",
            " [ 1.9422914   2.1615283 ]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.86 [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1] [1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0\n",
            " 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 0\n",
            " 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
            " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0\n",
            " 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1]\n",
            "##### labels.shape:  (500,) preds.shape:  (500,)\n",
            "{\n",
            "  \"aggregated\": 0.86,\n",
            "  \"copa\": {\n",
            "    \"loss\": 0.3700321838259697,\n",
            "    \"metrics\": {\n",
            "      \"major\": 0.86,\n",
            "      \"minor\": {\n",
            "        \"acc\": 0.86\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "Eval (copa, Test): 100% 16/16 [00:01<00:00, 10.98it/s]\n",
            "##### get_accumulated(), logits :  [[ 0.55188584  2.2914839 ]\n",
            " [-0.5243904   2.826377  ]\n",
            " [ 1.1846786   1.0432515 ]\n",
            " [ 1.0942429   0.5985366 ]\n",
            " [ 2.1853004   2.4486988 ]\n",
            " [ 2.6446972  -2.2205684 ]\n",
            " [ 2.7122061  -1.4128729 ]\n",
            " [ 2.4738622  -0.7813109 ]\n",
            " [ 1.9118767   1.9900095 ]\n",
            " [-0.91986924  2.6975806 ]\n",
            " [ 2.3456037   2.084676  ]\n",
            " [ 2.7584708   2.6902893 ]\n",
            " [ 2.8415575  -1.6448687 ]\n",
            " [-1.637729    2.781909  ]\n",
            " [ 1.8293707   2.094491  ]\n",
            " [ 2.7456877  -0.12700644]\n",
            " [ 0.9114822   2.565055  ]\n",
            " [ 2.3843384   1.8797505 ]\n",
            " [ 2.3924377  -2.0871656 ]\n",
            " [ 1.7028829   2.526378  ]\n",
            " [ 2.7336004  -2.3521326 ]\n",
            " [ 2.6989758   2.179832  ]\n",
            " [-2.0306675  -0.6002804 ]\n",
            " [ 1.5306324   2.0623162 ]\n",
            " [ 2.2471447   2.1094356 ]\n",
            " [-0.88806796  2.236374  ]\n",
            " [ 2.0603874   2.2502763 ]\n",
            " [ 2.4464152  -2.1869278 ]\n",
            " [ 2.5156415   1.4716574 ]\n",
            " [ 1.3731475  -0.49313855]\n",
            " [ 2.5813031   2.1799145 ]\n",
            " [-2.2923205   2.0949817 ]\n",
            " [-0.81361854  2.872808  ]\n",
            " [ 0.9689287  -0.21777089]\n",
            " [ 2.1717725  -1.0559174 ]\n",
            " [ 2.7697816   2.2960715 ]\n",
            " [ 0.8788468   2.405295  ]\n",
            " [ 0.2119248   2.0940647 ]\n",
            " [ 0.6903995  -1.682963  ]\n",
            " [ 2.6844282  -1.760695  ]\n",
            " [ 2.2623258  -1.5541795 ]\n",
            " [ 2.7786965   2.1552157 ]\n",
            " [-1.924944    0.4116459 ]\n",
            " [-2.15693     2.7817016 ]\n",
            " [ 0.2636147  -1.3782767 ]\n",
            " [ 2.7262275  -0.14931521]\n",
            " [ 1.5169512  -1.6387606 ]\n",
            " [ 1.9364588  -1.4914273 ]\n",
            " [-1.8670441  -1.1178224 ]\n",
            " [-0.1221716   1.7556498 ]\n",
            " [-2.253667   -1.725214  ]\n",
            " [-1.6363549   2.8697708 ]\n",
            " [ 2.8329508   1.2750324 ]\n",
            " [ 2.7870326  -1.5300211 ]\n",
            " [ 2.5927503   2.6321433 ]\n",
            " [ 2.3434474   1.5641721 ]\n",
            " [-1.4515247   2.718099  ]\n",
            " [ 2.1177835   1.3016186 ]\n",
            " [-1.9367516  -2.230223  ]\n",
            " [-2.076424   -0.34602532]\n",
            " [ 1.2249405   1.2915778 ]\n",
            " [-1.3748074   1.4069076 ]\n",
            " [ 1.0093001  -1.4198232 ]\n",
            " [ 2.649851   -2.2259507 ]\n",
            " [ 1.1438262  -0.66300094]\n",
            " [ 2.715033    1.215046  ]\n",
            " [ 2.751884    0.9644448 ]\n",
            " [-1.6882463   2.4035113 ]\n",
            " [-2.257346   -2.1261451 ]\n",
            " [ 0.45167357 -2.356375  ]\n",
            " [ 0.94407594 -1.8896772 ]\n",
            " [ 2.4458406   2.5592365 ]\n",
            " [ 2.3515735  -2.1431222 ]\n",
            " [-0.23214713 -1.9350662 ]\n",
            " [ 2.8043146   2.3694246 ]\n",
            " [ 2.8473232  -2.1064653 ]\n",
            " [ 2.7822063  -2.3512928 ]\n",
            " [ 1.3814727  -1.0294667 ]\n",
            " [ 1.4558619   1.7872207 ]\n",
            " [-1.8285959  -2.2665706 ]\n",
            " [-2.0899525  -1.3773298 ]\n",
            " [ 0.27443773 -1.3260999 ]\n",
            " [-2.1830003   0.4608547 ]\n",
            " [ 2.8103402   2.7115097 ]\n",
            " [ 2.277715    2.5548277 ]\n",
            " [ 2.8535554   2.127138  ]\n",
            " [ 2.810729   -1.8620408 ]\n",
            " [ 2.7341726   2.7728572 ]\n",
            " [ 2.5958483   1.008504  ]\n",
            " [ 2.6657262  -2.2386444 ]\n",
            " [-1.4794523   0.9115164 ]\n",
            " [-0.7700626   2.605599  ]\n",
            " [ 2.3064854  -0.29324794]\n",
            " [-0.83736     2.8147175 ]\n",
            " [ 2.8111575   2.743795  ]\n",
            " [ 1.9797485   2.6481237 ]\n",
            " [-1.7461238  -1.2106851 ]\n",
            " [ 0.46217558 -1.8925405 ]\n",
            " [-2.2731802   2.7674837 ]\n",
            " [-1.3379326   2.1897404 ]\n",
            " [ 2.4108777  -0.5138423 ]\n",
            " [-2.3302166   2.7467496 ]\n",
            " [ 2.3119588  -0.02847704]\n",
            " [-1.9910144   2.8322294 ]\n",
            " [ 0.00328076  1.7908882 ]\n",
            " [ 2.3799965  -2.04203   ]\n",
            " [-0.6503953  -1.6196927 ]\n",
            " [-2.050999   -1.9935548 ]\n",
            " [ 2.529733    0.1449695 ]\n",
            " [-1.1665986   2.6719306 ]\n",
            " [ 2.8719063   2.4096437 ]\n",
            " [-2.2045164   2.836903  ]\n",
            " [ 2.7852094   2.1297572 ]\n",
            " [ 1.6376872   2.1057549 ]\n",
            " [-2.1641493   2.3302016 ]\n",
            " [ 2.4663274   0.23682824]\n",
            " [ 2.7108247   2.5947113 ]\n",
            " [ 1.4860475   1.9099823 ]\n",
            " [-2.3272262   2.6282623 ]\n",
            " [ 2.5294206   1.7445943 ]\n",
            " [ 2.7910976   2.4956183 ]\n",
            " [ 0.23786816  2.6390438 ]\n",
            " [-2.2115865  -0.98697734]\n",
            " [-1.3324926   2.5831983 ]\n",
            " [ 2.4463415  -2.3506827 ]\n",
            " [-0.03973055 -2.063963  ]\n",
            " [ 1.2159039   2.8222334 ]\n",
            " [ 1.3129022  -1.3378334 ]\n",
            " [-2.1003296  -2.23372   ]\n",
            " [ 2.409408    1.7128952 ]\n",
            " [-2.2009184   2.3752043 ]\n",
            " [ 0.2770486   1.542209  ]\n",
            " [-0.6672981   1.3626126 ]\n",
            " [-2.082913    2.6370027 ]\n",
            " [-2.211247    2.5074308 ]\n",
            " [ 1.8844695   1.7097301 ]\n",
            " [ 2.002248    1.8531016 ]\n",
            " [ 0.60412323  2.6806    ]\n",
            " [ 2.2634223   0.39982677]\n",
            " [-2.2593267   2.7076943 ]\n",
            " [-1.3629063   2.7415872 ]\n",
            " [-2.000387    2.7881548 ]\n",
            " [-1.5919671   2.2907767 ]\n",
            " [ 2.7337642  -1.9649847 ]\n",
            " [ 2.6814535  -1.9505881 ]\n",
            " [-1.6678133   1.3893646 ]\n",
            " [ 2.2218854  -2.0920277 ]\n",
            " [ 2.743462   -2.0972326 ]\n",
            " [-1.2748142   2.861534  ]\n",
            " [ 2.8034644  -1.67717   ]\n",
            " [ 1.986831   -0.47258797]\n",
            " [ 0.7945785   2.2059817 ]\n",
            " [ 2.825137    0.13309035]\n",
            " [-0.47070265  0.42364272]\n",
            " [ 2.8353198  -1.9786458 ]\n",
            " [ 2.8076956  -2.307127  ]\n",
            " [ 2.4616742   1.3762276 ]\n",
            " [-2.3376927   1.1690013 ]\n",
            " [ 1.9186238   1.8388543 ]\n",
            " [ 2.7607543  -2.1801348 ]\n",
            " [-1.9357017  -1.8658197 ]\n",
            " [ 0.5239856  -1.6291498 ]\n",
            " [-2.3370671   2.7848682 ]\n",
            " [ 2.095569    2.234898  ]\n",
            " [-0.47385418  2.1767983 ]\n",
            " [ 2.3509347  -0.9198081 ]\n",
            " [-2.2267854   2.1294308 ]\n",
            " [ 2.7038975   2.1387131 ]\n",
            " [-2.2142391   2.8171632 ]\n",
            " [ 2.2683065   2.2977753 ]\n",
            " [ 1.9120319   2.8271842 ]\n",
            " [ 2.3099494   1.4353055 ]\n",
            " [ 1.816353    2.1574779 ]\n",
            " [-1.3470353   2.6144958 ]\n",
            " [ 1.8146031   2.055883  ]\n",
            " [ 2.780873   -1.9739289 ]\n",
            " [ 0.63043994  2.2883074 ]\n",
            " [-2.267964    2.7011049 ]\n",
            " [ 2.4600987  -2.0228844 ]\n",
            " [ 2.1199641  -2.197558  ]\n",
            " [-2.273399   -2.1500702 ]\n",
            " [ 2.5686634  -2.1237118 ]\n",
            " [ 1.6033497   1.573322  ]\n",
            " [-1.7514846  -0.31758964]\n",
            " [ 2.3143435   2.405442  ]\n",
            " [ 2.5862923  -2.1221943 ]\n",
            " [-1.7822506   2.5846803 ]\n",
            " [ 2.8149655  -2.3228805 ]\n",
            " [ 2.6436324   0.5853512 ]\n",
            " [-0.463778   -2.2331092 ]\n",
            " [-2.1758769   2.822232  ]\n",
            " [ 1.670784    2.7914093 ]\n",
            " [ 1.1726761  -1.9931523 ]\n",
            " [ 2.7210493  -1.9969345 ]\n",
            " [ 2.6427538  -0.63146114]\n",
            " [ 2.1866946   0.22975835]\n",
            " [ 2.6746688  -2.1392019 ]\n",
            " [ 2.8660545   2.8296027 ]\n",
            " [-0.06608126 -0.43370253]\n",
            " [ 2.1598387   0.91114205]\n",
            " [-1.7878759   2.851391  ]\n",
            " [ 2.8037522  -2.3148246 ]\n",
            " [-1.2881355   2.7196558 ]\n",
            " [ 2.2477977  -2.0385606 ]\n",
            " [ 1.2724016   2.26498   ]\n",
            " [ 2.4470053  -2.229684  ]\n",
            " [ 2.8149111   2.3920178 ]\n",
            " [-1.9979839   2.5879533 ]\n",
            " [-2.0477164   1.6547463 ]\n",
            " [ 1.948188    2.6542366 ]\n",
            " [ 2.3104215   2.3942392 ]\n",
            " [-1.7924212   2.4053566 ]\n",
            " [-0.17448707  2.4990263 ]\n",
            " [ 2.5011182   2.4421163 ]\n",
            " [ 2.8218129  -0.86232114]\n",
            " [ 2.7722497  -1.9867697 ]\n",
            " [-1.9287359   2.4060557 ]\n",
            " [ 2.2239046   1.6892577 ]\n",
            " [ 1.6825926   2.8155313 ]\n",
            " [ 2.629306    1.8233975 ]\n",
            " [ 2.7882009   1.727979  ]\n",
            " [-2.115483   -1.9601647 ]\n",
            " [-1.1611131   1.620124  ]\n",
            " [-0.9898847  -2.2741685 ]\n",
            " [-1.0254053  -0.28095806]\n",
            " [-2.1877117   2.7892036 ]\n",
            " [ 2.287915   -2.3107233 ]\n",
            " [ 2.3221033  -2.0133653 ]\n",
            " [-2.153697   -1.9856566 ]\n",
            " [ 2.620975   -1.1422054 ]\n",
            " [-2.0199718   1.7377708 ]\n",
            " [-2.204352   -2.0485377 ]\n",
            " [ 2.5218217  -0.8216869 ]\n",
            " [ 2.7489486  -2.1956565 ]\n",
            " [ 2.775003    2.0655427 ]\n",
            " [ 1.1969409   2.7273905 ]\n",
            " [-1.8139018  -1.751626  ]\n",
            " [ 0.08832711 -1.6713606 ]\n",
            " [-0.9376673   2.1197617 ]\n",
            " [ 1.7792611   2.352021  ]\n",
            " [-0.6616683   2.8695443 ]\n",
            " [-2.2841883   2.0526052 ]\n",
            " [-2.0055914   2.7487876 ]\n",
            " [-1.9824542   2.5470572 ]\n",
            " [-2.0333197   0.8806671 ]\n",
            " [-2.2196608   2.883888  ]\n",
            " [-2.1202297   2.4838889 ]\n",
            " [ 0.03464544  2.2326927 ]\n",
            " [ 1.1510412   2.5422766 ]\n",
            " [ 1.4182657  -1.928408  ]\n",
            " [-1.2004647  -1.7081347 ]\n",
            " [-2.1499133   2.1524527 ]\n",
            " [ 2.6816504   0.6274827 ]\n",
            " [ 2.6738985   2.2738335 ]\n",
            " [-0.43398777  2.773189  ]\n",
            " [-0.5921016   2.8442316 ]\n",
            " [-0.1771152   2.4351223 ]\n",
            " [ 0.5989528   2.7084696 ]\n",
            " [-2.0101511   1.3148013 ]\n",
            " [-1.9445611  -1.6567721 ]\n",
            " [ 2.5589755   1.1197121 ]\n",
            " [-0.76484656  2.9129236 ]\n",
            " [-1.2755541   1.7576047 ]\n",
            " [ 0.67224276  0.36367452]\n",
            " [ 2.8193672  -2.2626123 ]\n",
            " [-0.7193416   1.1983235 ]\n",
            " [-2.187507   -2.022474  ]\n",
            " [-1.8134869  -2.103854  ]\n",
            " [-1.9900303  -2.1434917 ]\n",
            " [ 0.06813273  2.6816049 ]\n",
            " [-2.2450168   2.7876081 ]\n",
            " [ 1.0759875   2.5560985 ]\n",
            " [-1.7839904   2.4008653 ]\n",
            " [ 2.3272352   2.4735768 ]\n",
            " [ 2.813197    1.6749358 ]\n",
            " [ 0.40345478  2.4828525 ]\n",
            " [ 2.4287617  -1.93372   ]\n",
            " [ 1.9950447   2.7959566 ]\n",
            " [ 0.30515125  2.741866  ]\n",
            " [ 0.18115996  2.5310194 ]\n",
            " [ 2.724504   -2.0529072 ]\n",
            " [ 2.8486474   0.10470386]\n",
            " [ 1.8896049   2.775963  ]\n",
            " [ 1.9344096   2.550483  ]\n",
            " [-2.2594044   2.8146489 ]\n",
            " [-1.98663     2.7019145 ]\n",
            " [-2.3135874   2.719218  ]\n",
            " [-1.8040949   2.6063585 ]\n",
            " [ 2.732485    1.7967888 ]\n",
            " [-2.1483316   2.603741  ]\n",
            " [ 1.533898    0.5888277 ]\n",
            " [ 2.6184964  -2.2272034 ]\n",
            " [-1.6288688   2.2918727 ]\n",
            " [-2.093747    1.3485066 ]\n",
            " [-0.3797214  -2.2294538 ]\n",
            " [-1.9110702   2.4280553 ]\n",
            " [-1.6135702   2.298024  ]\n",
            " [ 0.7326812   1.8807449 ]\n",
            " [-2.2256386  -2.2518356 ]\n",
            " [ 2.7433393  -2.0698295 ]\n",
            " [ 2.1305478   1.2668006 ]\n",
            " [ 2.6380577   0.11628707]\n",
            " [ 2.0311508  -0.30302542]\n",
            " [-2.1579282  -2.2648842 ]\n",
            " [ 2.584834   -1.0526615 ]\n",
            " [ 2.6409938   2.4669714 ]\n",
            " [ 1.7710971   0.6583346 ]\n",
            " [-2.067643   -2.1461291 ]\n",
            " [ 2.4245102   2.865428  ]\n",
            " [ 2.363309   -1.9373193 ]\n",
            " [-1.7187274  -1.3423206 ]\n",
            " [ 0.16229695  2.0254562 ]\n",
            " [-2.3280618   2.7432284 ]\n",
            " [-2.2849574  -0.05557305]\n",
            " [ 2.7587504   2.7640042 ]\n",
            " [ 1.8123881   2.3033943 ]\n",
            " [ 2.616804    0.9325661 ]\n",
            " [-2.0435445   1.8636289 ]\n",
            " [ 0.6935078  -1.8276997 ]\n",
            " [ 0.33269158  1.1701827 ]\n",
            " [-0.28131855  2.676356  ]\n",
            " [ 2.8242464  -2.3293426 ]\n",
            " [ 2.7030432  -1.3960388 ]\n",
            " [ 2.660637    2.242681  ]\n",
            " [-1.7467678   2.6559763 ]\n",
            " [ 2.191496   -1.8963499 ]\n",
            " [ 2.747651   -2.03033   ]\n",
            " [-2.1629417   1.482956  ]\n",
            " [ 2.4472344  -1.3780503 ]\n",
            " [-2.120874    2.1167254 ]\n",
            " [ 2.2062166   2.3929667 ]\n",
            " [ 2.0257664   0.05768928]\n",
            " [ 2.0048428  -2.2115383 ]\n",
            " [ 2.8424988  -1.6400851 ]\n",
            " [-2.1672225   2.5813608 ]\n",
            " [-2.2232294  -1.3436854 ]\n",
            " [-2.2954416   1.3555143 ]\n",
            " [-1.9781342   2.7173936 ]\n",
            " [ 2.6276855  -1.6744175 ]\n",
            " [ 1.7411152  -1.2726324 ]\n",
            " [-2.1440616   2.6739633 ]\n",
            " [ 2.4831603  -2.2223022 ]\n",
            " [ 0.5622897  -0.30441427]\n",
            " [-2.285709    2.7794743 ]\n",
            " [ 2.8021758  -2.2501056 ]\n",
            " [ 2.7545974   2.8005445 ]\n",
            " [ 2.165985    0.5005539 ]\n",
            " [-1.2628798   1.9479334 ]\n",
            " [ 2.0959852   0.07706845]\n",
            " [ 1.5635539   0.7847602 ]\n",
            " [-0.53513724  0.6861797 ]\n",
            " [ 0.845011    0.74498975]\n",
            " [ 2.562949    2.4719634 ]\n",
            " [-1.9369193   2.7856026 ]\n",
            " [ 2.6428564  -0.2664422 ]\n",
            " [ 1.12032     1.8697442 ]\n",
            " [ 1.2376995   2.768626  ]\n",
            " [-2.2681463   2.6407962 ]\n",
            " [-2.2798233   2.800558  ]\n",
            " [-2.1939993  -1.535444  ]\n",
            " [ 1.2547143   2.4735444 ]\n",
            " [ 1.8974475   1.4395429 ]\n",
            " [ 2.6933448  -1.370723  ]\n",
            " [ 2.163564   -0.3191996 ]\n",
            " [ 2.5211794   2.7234848 ]\n",
            " [-2.0584805   2.0009134 ]\n",
            " [ 2.0869737   2.124746  ]\n",
            " [-2.3044355   1.5721866 ]\n",
            " [ 2.8916044  -2.3442726 ]\n",
            " [ 0.21664768 -2.2416308 ]\n",
            " [ 2.4783926   0.63279563]\n",
            " [ 2.186864    0.8820558 ]\n",
            " [-2.2929773   2.7213907 ]\n",
            " [ 2.8154626   2.6963596 ]\n",
            " [ 2.115462   -2.0226648 ]\n",
            " [-1.7399065  -0.68648267]\n",
            " [-2.2068682   2.6376228 ]\n",
            " [ 0.46089625  1.4253858 ]\n",
            " [ 2.616474    2.1253226 ]\n",
            " [ 0.27527094  2.2142267 ]\n",
            " [ 2.7888548  -2.3591557 ]\n",
            " [-2.028321   -2.0154653 ]\n",
            " [ 2.8298852  -0.8226803 ]\n",
            " [-1.5244982   2.7452989 ]\n",
            " [ 2.2493823   0.73573667]\n",
            " [-0.95676804 -1.7276846 ]\n",
            " [ 2.7910495   1.9604104 ]\n",
            " [-2.0299022   2.8211582 ]\n",
            " [ 2.792211   -1.10135   ]\n",
            " [ 0.78726655 -1.9157085 ]\n",
            " [-0.12146963  1.0085872 ]\n",
            " [-1.6044599  -1.5953777 ]\n",
            " [-0.5846374  -0.65924585]\n",
            " [ 2.6012864   2.4971054 ]\n",
            " [ 1.7955925   2.4301207 ]\n",
            " [-1.7578497  -1.3776691 ]\n",
            " [ 2.746169    1.3702157 ]\n",
            " [ 2.7048566   1.1196421 ]\n",
            " [-1.4706054  -1.1546706 ]\n",
            " [ 2.5960119   1.1155301 ]\n",
            " [ 2.6158888  -0.45963755]\n",
            " [ 2.7366385  -1.8686146 ]\n",
            " [ 2.5811927   2.7944973 ]\n",
            " [ 2.74576     2.127514  ]\n",
            " [-2.01121     0.8526138 ]\n",
            " [-0.73980284 -1.8130726 ]\n",
            " [ 0.22412494  0.35562634]\n",
            " [ 2.5642555  -2.2670867 ]\n",
            " [-2.3059208   2.0871458 ]\n",
            " [ 2.1483998  -1.9649558 ]\n",
            " [-2.170226    2.6164222 ]\n",
            " [ 1.6568476  -2.267404  ]\n",
            " [ 2.681717   -0.7901372 ]\n",
            " [-1.6016291  -0.6589678 ]\n",
            " [ 2.759324   -0.11212046]\n",
            " [ 2.6862648   0.7301504 ]\n",
            " [ 2.59187     1.7505744 ]\n",
            " [ 1.5586362   2.7625577 ]\n",
            " [ 2.8247268   0.51505333]\n",
            " [ 2.6901934  -1.1430595 ]\n",
            " [-1.1063935  -0.3647187 ]\n",
            " [ 2.4705396   2.696854  ]\n",
            " [-1.2356145   2.4908082 ]\n",
            " [ 1.3749852  -1.8854775 ]\n",
            " [ 2.8582313   0.17643453]\n",
            " [-0.2926596   2.748075  ]\n",
            " [ 2.527623   -0.94953114]\n",
            " [ 2.7727716   2.5954056 ]\n",
            " [-2.032619   -2.0937748 ]\n",
            " [-1.9080122   2.672293  ]\n",
            " [-0.38031638  2.3112519 ]\n",
            " [-2.1727488   2.466208  ]\n",
            " [ 2.4447982  -2.1399775 ]\n",
            " [-1.9013274   2.8495486 ]\n",
            " [-0.6329179   2.0659363 ]\n",
            " [ 2.5570703  -2.0190287 ]\n",
            " [-2.308338    2.5258234 ]\n",
            " [ 0.31622452  1.9998198 ]\n",
            " [-0.61544675 -0.635895  ]\n",
            " [-1.7479384  -1.3962471 ]\n",
            " [ 2.7036486   0.48001075]\n",
            " [ 0.9465479   2.4059267 ]\n",
            " [ 1.8019572  -1.9427576 ]\n",
            " [ 2.3428419   2.8094513 ]\n",
            " [ 0.05711289 -2.1467516 ]\n",
            " [-2.01936     2.548868  ]\n",
            " [-2.3177516   2.82193   ]\n",
            " [ 2.7281911  -1.0049874 ]\n",
            " [-0.5198894   2.237427  ]\n",
            " [ 0.31914237  2.2627182 ]\n",
            " [ 2.8440845   0.8185598 ]\n",
            " [ 2.6909184   1.2814347 ]\n",
            " [ 1.9722096  -1.3120561 ]\n",
            " [-2.0983553  -1.4174263 ]\n",
            " [ 2.711385   -2.297407  ]\n",
            " [ 0.76811075  1.7994183 ]\n",
            " [ 2.5436769  -1.8102204 ]\n",
            " [ 2.2786143  -1.4610696 ]\n",
            " [-0.02782269  2.7859857 ]\n",
            " [ 2.563575   -1.8708155 ]\n",
            " [ 0.7016279   0.68395275]\n",
            " [-0.34480584  2.843024  ]\n",
            " [ 2.5968003  -0.5594207 ]\n",
            " [ 1.7285044  -1.7926946 ]\n",
            " [ 2.150483   -2.0868928 ]\n",
            " [ 2.4770515   1.9999158 ]\n",
            " [ 2.3367097  -2.1329336 ]\n",
            " [ 2.7906      2.149515  ]\n",
            " [-1.6557976   1.4289918 ]\n",
            " [ 2.8265166  -1.3968549 ]\n",
            " [ 0.44445726  0.63350123]\n",
            " [-0.90311927  0.692742  ]\n",
            " [-2.318542    2.785695  ]\n",
            " [-1.4034854   2.7506049 ]\n",
            " [ 2.2645946   2.2935476 ]\n",
            " [ 1.6651325   2.6497753 ]\n",
            " [-2.1836324   1.0115466 ]\n",
            " [-0.7125788   2.6188684 ]\n",
            " [ 2.608213    0.00757143]\n",
            " [-1.8048093   0.01054754]\n",
            " [ 2.7630959   0.6583169 ]\n",
            " [-1.7147968   2.6584074 ]\n",
            " [ 2.51539     0.7522219 ]\n",
            " [ 2.4294314  -0.17649876]\n",
            " [-2.061999   -0.3672322 ]\n",
            " [-1.1524339  -1.2716434 ]\n",
            " [-1.9951185   1.8238392 ]\n",
            " [ 2.361766    1.2581025 ]\n",
            " [-2.038103    2.5926049 ]\n",
            " [ 0.9902015   0.3112981 ]\n",
            " [ 2.6167467   1.8688474 ]\n",
            " [ 0.25350356  2.7154868 ]\n",
            " [ 0.61031425  2.5951045 ]\n",
            " [-1.6585194  -1.1785771 ]\n",
            " [ 2.3718264  -1.2833111 ]\n",
            " [-1.6361961  -0.35851   ]\n",
            " [ 1.2891917   2.6269217 ]\n",
            " [ 2.08751     2.6569796 ]\n",
            " [ 2.7276924  -1.5885477 ]\n",
            " [-1.944644    2.714415  ]]\n",
            "test_task_list : ['copa']\n",
            "##### write_preds(), task_name:  copa 500\n",
            "[1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1\n",
            " 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0\n",
            " 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1\n",
            " 1 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0\n",
            " 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0\n",
            " 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1\n",
            " 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1\n",
            " 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 1 0 1 0 0 1 1 1 0 1 1 1 0 1]\n",
            "['test-1' 'test-2' 'test-3' 'test-4' 'test-5' 'test-6' 'test-7' 'test-8'\n",
            " 'test-9' 'test-10' 'test-11' 'test-12' 'test-13' 'test-14' 'test-15'\n",
            " 'test-16' 'test-17' 'test-18' 'test-19' 'test-20' 'test-21' 'test-22'\n",
            " 'test-23' 'test-24' 'test-25' 'test-26' 'test-27' 'test-28' 'test-29'\n",
            " 'test-30' 'test-31' 'test-32' 'test-33' 'test-34' 'test-35' 'test-36'\n",
            " 'test-37' 'test-38' 'test-39' 'test-40' 'test-41' 'test-42' 'test-43'\n",
            " 'test-44' 'test-45' 'test-46' 'test-47' 'test-48' 'test-49' 'test-50'\n",
            " 'test-51' 'test-52' 'test-53' 'test-54' 'test-55' 'test-56' 'test-57'\n",
            " 'test-58' 'test-59' 'test-60' 'test-61' 'test-62' 'test-63' 'test-64'\n",
            " 'test-65' 'test-66' 'test-67' 'test-68' 'test-69' 'test-70' 'test-71'\n",
            " 'test-72' 'test-73' 'test-74' 'test-75' 'test-76' 'test-77' 'test-78'\n",
            " 'test-79' 'test-80' 'test-81' 'test-82' 'test-83' 'test-84' 'test-85'\n",
            " 'test-86' 'test-87' 'test-88' 'test-89' 'test-90' 'test-91' 'test-92'\n",
            " 'test-93' 'test-94' 'test-95' 'test-96' 'test-97' 'test-98' 'test-99'\n",
            " 'test-100' 'test-101' 'test-102' 'test-103' 'test-104' 'test-105'\n",
            " 'test-106' 'test-107' 'test-108' 'test-109' 'test-110' 'test-111'\n",
            " 'test-112' 'test-113' 'test-114' 'test-115' 'test-116' 'test-117'\n",
            " 'test-118' 'test-119' 'test-120' 'test-121' 'test-122' 'test-123'\n",
            " 'test-124' 'test-125' 'test-126' 'test-127' 'test-128' 'test-129'\n",
            " 'test-130' 'test-131' 'test-132' 'test-133' 'test-134' 'test-135'\n",
            " 'test-136' 'test-137' 'test-138' 'test-139' 'test-140' 'test-141'\n",
            " 'test-142' 'test-143' 'test-144' 'test-145' 'test-146' 'test-147'\n",
            " 'test-148' 'test-149' 'test-150' 'test-151' 'test-152' 'test-153'\n",
            " 'test-154' 'test-155' 'test-156' 'test-157' 'test-158' 'test-159'\n",
            " 'test-160' 'test-161' 'test-162' 'test-163' 'test-164' 'test-165'\n",
            " 'test-166' 'test-167' 'test-168' 'test-169' 'test-170' 'test-171'\n",
            " 'test-172' 'test-173' 'test-174' 'test-175' 'test-176' 'test-177'\n",
            " 'test-178' 'test-179' 'test-180' 'test-181' 'test-182' 'test-183'\n",
            " 'test-184' 'test-185' 'test-186' 'test-187' 'test-188' 'test-189'\n",
            " 'test-190' 'test-191' 'test-192' 'test-193' 'test-194' 'test-195'\n",
            " 'test-196' 'test-197' 'test-198' 'test-199' 'test-200' 'test-201'\n",
            " 'test-202' 'test-203' 'test-204' 'test-205' 'test-206' 'test-207'\n",
            " 'test-208' 'test-209' 'test-210' 'test-211' 'test-212' 'test-213'\n",
            " 'test-214' 'test-215' 'test-216' 'test-217' 'test-218' 'test-219'\n",
            " 'test-220' 'test-221' 'test-222' 'test-223' 'test-224' 'test-225'\n",
            " 'test-226' 'test-227' 'test-228' 'test-229' 'test-230' 'test-231'\n",
            " 'test-232' 'test-233' 'test-234' 'test-235' 'test-236' 'test-237'\n",
            " 'test-238' 'test-239' 'test-240' 'test-241' 'test-242' 'test-243'\n",
            " 'test-244' 'test-245' 'test-246' 'test-247' 'test-248' 'test-249'\n",
            " 'test-250' 'test-251' 'test-252' 'test-253' 'test-254' 'test-255'\n",
            " 'test-256' 'test-257' 'test-258' 'test-259' 'test-260' 'test-261'\n",
            " 'test-262' 'test-263' 'test-264' 'test-265' 'test-266' 'test-267'\n",
            " 'test-268' 'test-269' 'test-270' 'test-271' 'test-272' 'test-273'\n",
            " 'test-274' 'test-275' 'test-276' 'test-277' 'test-278' 'test-279'\n",
            " 'test-280' 'test-281' 'test-282' 'test-283' 'test-284' 'test-285'\n",
            " 'test-286' 'test-287' 'test-288' 'test-289' 'test-290' 'test-291'\n",
            " 'test-292' 'test-293' 'test-294' 'test-295' 'test-296' 'test-297'\n",
            " 'test-298' 'test-299' 'test-300' 'test-301' 'test-302' 'test-303'\n",
            " 'test-304' 'test-305' 'test-306' 'test-307' 'test-308' 'test-309'\n",
            " 'test-310' 'test-311' 'test-312' 'test-313' 'test-314' 'test-315'\n",
            " 'test-316' 'test-317' 'test-318' 'test-319' 'test-320' 'test-321'\n",
            " 'test-322' 'test-323' 'test-324' 'test-325' 'test-326' 'test-327'\n",
            " 'test-328' 'test-329' 'test-330' 'test-331' 'test-332' 'test-333'\n",
            " 'test-334' 'test-335' 'test-336' 'test-337' 'test-338' 'test-339'\n",
            " 'test-340' 'test-341' 'test-342' 'test-343' 'test-344' 'test-345'\n",
            " 'test-346' 'test-347' 'test-348' 'test-349' 'test-350' 'test-351'\n",
            " 'test-352' 'test-353' 'test-354' 'test-355' 'test-356' 'test-357'\n",
            " 'test-358' 'test-359' 'test-360' 'test-361' 'test-362' 'test-363'\n",
            " 'test-364' 'test-365' 'test-366' 'test-367' 'test-368' 'test-369'\n",
            " 'test-370' 'test-371' 'test-372' 'test-373' 'test-374' 'test-375'\n",
            " 'test-376' 'test-377' 'test-378' 'test-379' 'test-380' 'test-381'\n",
            " 'test-382' 'test-383' 'test-384' 'test-385' 'test-386' 'test-387'\n",
            " 'test-388' 'test-389' 'test-390' 'test-391' 'test-392' 'test-393'\n",
            " 'test-394' 'test-395' 'test-396' 'test-397' 'test-398' 'test-399'\n",
            " 'test-400' 'test-401' 'test-402' 'test-403' 'test-404' 'test-405'\n",
            " 'test-406' 'test-407' 'test-408' 'test-409' 'test-410' 'test-411'\n",
            " 'test-412' 'test-413' 'test-414' 'test-415' 'test-416' 'test-417'\n",
            " 'test-418' 'test-419' 'test-420' 'test-421' 'test-422' 'test-423'\n",
            " 'test-424' 'test-425' 'test-426' 'test-427' 'test-428' 'test-429'\n",
            " 'test-430' 'test-431' 'test-432' 'test-433' 'test-434' 'test-435'\n",
            " 'test-436' 'test-437' 'test-438' 'test-439' 'test-440' 'test-441'\n",
            " 'test-442' 'test-443' 'test-444' 'test-445' 'test-446' 'test-447'\n",
            " 'test-448' 'test-449' 'test-450' 'test-451' 'test-452' 'test-453'\n",
            " 'test-454' 'test-455' 'test-456' 'test-457' 'test-458' 'test-459'\n",
            " 'test-460' 'test-461' 'test-462' 'test-463' 'test-464' 'test-465'\n",
            " 'test-466' 'test-467' 'test-468' 'test-469' 'test-470' 'test-471'\n",
            " 'test-472' 'test-473' 'test-474' 'test-475' 'test-476' 'test-477'\n",
            " 'test-478' 'test-479' 'test-480' 'test-481' 'test-482' 'test-483'\n",
            " 'test-484' 'test-485' 'test-486' 'test-487' 'test-488' 'test-489'\n",
            " 'test-490' 'test-491' 'test-492' 'test-493' 'test-494' 'test-495'\n",
            " 'test-496' 'test-497' 'test-498' 'test-499' 'test-500']\n",
            "##### preds_dic_list:  [{'idx': 1, 'label': 2}, {'idx': 2, 'label': 2}, {'idx': 3, 'label': 1}, {'idx': 4, 'label': 1}, {'idx': 5, 'label': 2}, {'idx': 6, 'label': 1}, {'idx': 7, 'label': 1}, {'idx': 8, 'label': 1}, {'idx': 9, 'label': 2}, {'idx': 10, 'label': 2}, {'idx': 11, 'label': 1}, {'idx': 12, 'label': 1}, {'idx': 13, 'label': 1}, {'idx': 14, 'label': 2}, {'idx': 15, 'label': 2}, {'idx': 16, 'label': 1}, {'idx': 17, 'label': 2}, {'idx': 18, 'label': 1}, {'idx': 19, 'label': 1}, {'idx': 20, 'label': 2}, {'idx': 21, 'label': 1}, {'idx': 22, 'label': 1}, {'idx': 23, 'label': 2}, {'idx': 24, 'label': 2}, {'idx': 25, 'label': 1}, {'idx': 26, 'label': 2}, {'idx': 27, 'label': 2}, {'idx': 28, 'label': 1}, {'idx': 29, 'label': 1}, {'idx': 30, 'label': 1}, {'idx': 31, 'label': 1}, {'idx': 32, 'label': 2}, {'idx': 33, 'label': 2}, {'idx': 34, 'label': 1}, {'idx': 35, 'label': 1}, {'idx': 36, 'label': 1}, {'idx': 37, 'label': 2}, {'idx': 38, 'label': 2}, {'idx': 39, 'label': 1}, {'idx': 40, 'label': 1}, {'idx': 41, 'label': 1}, {'idx': 42, 'label': 1}, {'idx': 43, 'label': 2}, {'idx': 44, 'label': 2}, {'idx': 45, 'label': 1}, {'idx': 46, 'label': 1}, {'idx': 47, 'label': 1}, {'idx': 48, 'label': 1}, {'idx': 49, 'label': 2}, {'idx': 50, 'label': 2}, {'idx': 51, 'label': 2}, {'idx': 52, 'label': 2}, {'idx': 53, 'label': 1}, {'idx': 54, 'label': 1}, {'idx': 55, 'label': 2}, {'idx': 56, 'label': 1}, {'idx': 57, 'label': 2}, {'idx': 58, 'label': 1}, {'idx': 59, 'label': 1}, {'idx': 60, 'label': 2}, {'idx': 61, 'label': 2}, {'idx': 62, 'label': 2}, {'idx': 63, 'label': 1}, {'idx': 64, 'label': 1}, {'idx': 65, 'label': 1}, {'idx': 66, 'label': 1}, {'idx': 67, 'label': 1}, {'idx': 68, 'label': 2}, {'idx': 69, 'label': 2}, {'idx': 70, 'label': 1}, {'idx': 71, 'label': 1}, {'idx': 72, 'label': 2}, {'idx': 73, 'label': 1}, {'idx': 74, 'label': 1}, {'idx': 75, 'label': 1}, {'idx': 76, 'label': 1}, {'idx': 77, 'label': 1}, {'idx': 78, 'label': 1}, {'idx': 79, 'label': 2}, {'idx': 80, 'label': 1}, {'idx': 81, 'label': 2}, {'idx': 82, 'label': 1}, {'idx': 83, 'label': 2}, {'idx': 84, 'label': 1}, {'idx': 85, 'label': 2}, {'idx': 86, 'label': 1}, {'idx': 87, 'label': 1}, {'idx': 88, 'label': 2}, {'idx': 89, 'label': 1}, {'idx': 90, 'label': 1}, {'idx': 91, 'label': 2}, {'idx': 92, 'label': 2}, {'idx': 93, 'label': 1}, {'idx': 94, 'label': 2}, {'idx': 95, 'label': 1}, {'idx': 96, 'label': 2}, {'idx': 97, 'label': 2}, {'idx': 98, 'label': 1}, {'idx': 99, 'label': 2}, {'idx': 100, 'label': 2}, {'idx': 101, 'label': 1}, {'idx': 102, 'label': 2}, {'idx': 103, 'label': 1}, {'idx': 104, 'label': 2}, {'idx': 105, 'label': 2}, {'idx': 106, 'label': 1}, {'idx': 107, 'label': 1}, {'idx': 108, 'label': 2}, {'idx': 109, 'label': 1}, {'idx': 110, 'label': 2}, {'idx': 111, 'label': 1}, {'idx': 112, 'label': 2}, {'idx': 113, 'label': 1}, {'idx': 114, 'label': 2}, {'idx': 115, 'label': 2}, {'idx': 116, 'label': 1}, {'idx': 117, 'label': 1}, {'idx': 118, 'label': 2}, {'idx': 119, 'label': 2}, {'idx': 120, 'label': 1}, {'idx': 121, 'label': 1}, {'idx': 122, 'label': 2}, {'idx': 123, 'label': 2}, {'idx': 124, 'label': 2}, {'idx': 125, 'label': 1}, {'idx': 126, 'label': 1}, {'idx': 127, 'label': 2}, {'idx': 128, 'label': 1}, {'idx': 129, 'label': 1}, {'idx': 130, 'label': 1}, {'idx': 131, 'label': 2}, {'idx': 132, 'label': 2}, {'idx': 133, 'label': 2}, {'idx': 134, 'label': 2}, {'idx': 135, 'label': 2}, {'idx': 136, 'label': 1}, {'idx': 137, 'label': 1}, {'idx': 138, 'label': 2}, {'idx': 139, 'label': 1}, {'idx': 140, 'label': 2}, {'idx': 141, 'label': 2}, {'idx': 142, 'label': 2}, {'idx': 143, 'label': 2}, {'idx': 144, 'label': 1}, {'idx': 145, 'label': 1}, {'idx': 146, 'label': 2}, {'idx': 147, 'label': 1}, {'idx': 148, 'label': 1}, {'idx': 149, 'label': 2}, {'idx': 150, 'label': 1}, {'idx': 151, 'label': 1}, {'idx': 152, 'label': 2}, {'idx': 153, 'label': 1}, {'idx': 154, 'label': 2}, {'idx': 155, 'label': 1}, {'idx': 156, 'label': 1}, {'idx': 157, 'label': 1}, {'idx': 158, 'label': 2}, {'idx': 159, 'label': 1}, {'idx': 160, 'label': 1}, {'idx': 161, 'label': 2}, {'idx': 162, 'label': 1}, {'idx': 163, 'label': 2}, {'idx': 164, 'label': 2}, {'idx': 165, 'label': 2}, {'idx': 166, 'label': 1}, {'idx': 167, 'label': 2}, {'idx': 168, 'label': 1}, {'idx': 169, 'label': 2}, {'idx': 170, 'label': 2}, {'idx': 171, 'label': 2}, {'idx': 172, 'label': 1}, {'idx': 173, 'label': 2}, {'idx': 174, 'label': 2}, {'idx': 175, 'label': 2}, {'idx': 176, 'label': 1}, {'idx': 177, 'label': 2}, {'idx': 178, 'label': 2}, {'idx': 179, 'label': 1}, {'idx': 180, 'label': 1}, {'idx': 181, 'label': 2}, {'idx': 182, 'label': 1}, {'idx': 183, 'label': 1}, {'idx': 184, 'label': 2}, {'idx': 185, 'label': 2}, {'idx': 186, 'label': 1}, {'idx': 187, 'label': 2}, {'idx': 188, 'label': 1}, {'idx': 189, 'label': 1}, {'idx': 190, 'label': 1}, {'idx': 191, 'label': 2}, {'idx': 192, 'label': 2}, {'idx': 193, 'label': 1}, {'idx': 194, 'label': 1}, {'idx': 195, 'label': 1}, {'idx': 196, 'label': 1}, {'idx': 197, 'label': 1}, {'idx': 198, 'label': 1}, {'idx': 199, 'label': 1}, {'idx': 200, 'label': 1}, {'idx': 201, 'label': 2}, {'idx': 202, 'label': 1}, {'idx': 203, 'label': 2}, {'idx': 204, 'label': 1}, {'idx': 205, 'label': 2}, {'idx': 206, 'label': 1}, {'idx': 207, 'label': 1}, {'idx': 208, 'label': 2}, {'idx': 209, 'label': 2}, {'idx': 210, 'label': 2}, {'idx': 211, 'label': 2}, {'idx': 212, 'label': 2}, {'idx': 213, 'label': 2}, {'idx': 214, 'label': 1}, {'idx': 215, 'label': 1}, {'idx': 216, 'label': 1}, {'idx': 217, 'label': 2}, {'idx': 218, 'label': 1}, {'idx': 219, 'label': 2}, {'idx': 220, 'label': 1}, {'idx': 221, 'label': 1}, {'idx': 222, 'label': 2}, {'idx': 223, 'label': 2}, {'idx': 224, 'label': 1}, {'idx': 225, 'label': 2}, {'idx': 226, 'label': 2}, {'idx': 227, 'label': 1}, {'idx': 228, 'label': 1}, {'idx': 229, 'label': 2}, {'idx': 230, 'label': 1}, {'idx': 231, 'label': 2}, {'idx': 232, 'label': 2}, {'idx': 233, 'label': 1}, {'idx': 234, 'label': 1}, {'idx': 235, 'label': 1}, {'idx': 236, 'label': 2}, {'idx': 237, 'label': 2}, {'idx': 238, 'label': 1}, {'idx': 239, 'label': 2}, {'idx': 240, 'label': 2}, {'idx': 241, 'label': 2}, {'idx': 242, 'label': 2}, {'idx': 243, 'label': 2}, {'idx': 244, 'label': 2}, {'idx': 245, 'label': 2}, {'idx': 246, 'label': 2}, {'idx': 247, 'label': 2}, {'idx': 248, 'label': 2}, {'idx': 249, 'label': 2}, {'idx': 250, 'label': 1}, {'idx': 251, 'label': 1}, {'idx': 252, 'label': 2}, {'idx': 253, 'label': 1}, {'idx': 254, 'label': 1}, {'idx': 255, 'label': 2}, {'idx': 256, 'label': 2}, {'idx': 257, 'label': 2}, {'idx': 258, 'label': 2}, {'idx': 259, 'label': 2}, {'idx': 260, 'label': 2}, {'idx': 261, 'label': 1}, {'idx': 262, 'label': 2}, {'idx': 263, 'label': 2}, {'idx': 264, 'label': 1}, {'idx': 265, 'label': 1}, {'idx': 266, 'label': 2}, {'idx': 267, 'label': 2}, {'idx': 268, 'label': 1}, {'idx': 269, 'label': 1}, {'idx': 270, 'label': 2}, {'idx': 271, 'label': 2}, {'idx': 272, 'label': 2}, {'idx': 273, 'label': 2}, {'idx': 274, 'label': 2}, {'idx': 275, 'label': 1}, {'idx': 276, 'label': 2}, {'idx': 277, 'label': 1}, {'idx': 278, 'label': 2}, {'idx': 279, 'label': 2}, {'idx': 280, 'label': 2}, {'idx': 281, 'label': 1}, {'idx': 282, 'label': 1}, {'idx': 283, 'label': 2}, {'idx': 284, 'label': 2}, {'idx': 285, 'label': 2}, {'idx': 286, 'label': 2}, {'idx': 287, 'label': 2}, {'idx': 288, 'label': 2}, {'idx': 289, 'label': 1}, {'idx': 290, 'label': 2}, {'idx': 291, 'label': 1}, {'idx': 292, 'label': 1}, {'idx': 293, 'label': 2}, {'idx': 294, 'label': 2}, {'idx': 295, 'label': 1}, {'idx': 296, 'label': 2}, {'idx': 297, 'label': 2}, {'idx': 298, 'label': 2}, {'idx': 299, 'label': 1}, {'idx': 300, 'label': 1}, {'idx': 301, 'label': 1}, {'idx': 302, 'label': 1}, {'idx': 303, 'label': 1}, {'idx': 304, 'label': 1}, {'idx': 305, 'label': 1}, {'idx': 306, 'label': 1}, {'idx': 307, 'label': 1}, {'idx': 308, 'label': 1}, {'idx': 309, 'label': 2}, {'idx': 310, 'label': 1}, {'idx': 311, 'label': 2}, {'idx': 312, 'label': 2}, {'idx': 313, 'label': 2}, {'idx': 314, 'label': 2}, {'idx': 315, 'label': 2}, {'idx': 316, 'label': 2}, {'idx': 317, 'label': 1}, {'idx': 318, 'label': 2}, {'idx': 319, 'label': 1}, {'idx': 320, 'label': 2}, {'idx': 321, 'label': 2}, {'idx': 322, 'label': 1}, {'idx': 323, 'label': 1}, {'idx': 324, 'label': 1}, {'idx': 325, 'label': 2}, {'idx': 326, 'label': 1}, {'idx': 327, 'label': 1}, {'idx': 328, 'label': 2}, {'idx': 329, 'label': 1}, {'idx': 330, 'label': 2}, {'idx': 331, 'label': 2}, {'idx': 332, 'label': 1}, {'idx': 333, 'label': 1}, {'idx': 334, 'label': 1}, {'idx': 335, 'label': 2}, {'idx': 336, 'label': 2}, {'idx': 337, 'label': 2}, {'idx': 338, 'label': 2}, {'idx': 339, 'label': 1}, {'idx': 340, 'label': 1}, {'idx': 341, 'label': 2}, {'idx': 342, 'label': 1}, {'idx': 343, 'label': 1}, {'idx': 344, 'label': 2}, {'idx': 345, 'label': 1}, {'idx': 346, 'label': 2}, {'idx': 347, 'label': 1}, {'idx': 348, 'label': 2}, {'idx': 349, 'label': 1}, {'idx': 350, 'label': 1}, {'idx': 351, 'label': 2}, {'idx': 352, 'label': 1}, {'idx': 353, 'label': 1}, {'idx': 354, 'label': 2}, {'idx': 355, 'label': 1}, {'idx': 356, 'label': 2}, {'idx': 357, 'label': 2}, {'idx': 358, 'label': 2}, {'idx': 359, 'label': 2}, {'idx': 360, 'label': 2}, {'idx': 361, 'label': 2}, {'idx': 362, 'label': 1}, {'idx': 363, 'label': 1}, {'idx': 364, 'label': 1}, {'idx': 365, 'label': 2}, {'idx': 366, 'label': 2}, {'idx': 367, 'label': 2}, {'idx': 368, 'label': 2}, {'idx': 369, 'label': 1}, {'idx': 370, 'label': 1}, {'idx': 371, 'label': 1}, {'idx': 372, 'label': 1}, {'idx': 373, 'label': 2}, {'idx': 374, 'label': 1}, {'idx': 375, 'label': 1}, {'idx': 376, 'label': 2}, {'idx': 377, 'label': 2}, {'idx': 378, 'label': 2}, {'idx': 379, 'label': 1}, {'idx': 380, 'label': 2}, {'idx': 381, 'label': 1}, {'idx': 382, 'label': 2}, {'idx': 383, 'label': 1}, {'idx': 384, 'label': 2}, {'idx': 385, 'label': 1}, {'idx': 386, 'label': 1}, {'idx': 387, 'label': 1}, {'idx': 388, 'label': 2}, {'idx': 389, 'label': 1}, {'idx': 390, 'label': 1}, {'idx': 391, 'label': 2}, {'idx': 392, 'label': 2}, {'idx': 393, 'label': 1}, {'idx': 394, 'label': 1}, {'idx': 395, 'label': 2}, {'idx': 396, 'label': 2}, {'idx': 397, 'label': 1}, {'idx': 398, 'label': 1}, {'idx': 399, 'label': 2}, {'idx': 400, 'label': 1}, {'idx': 401, 'label': 1}, {'idx': 402, 'label': 1}, {'idx': 403, 'label': 2}, {'idx': 404, 'label': 1}, {'idx': 405, 'label': 2}, {'idx': 406, 'label': 1}, {'idx': 407, 'label': 2}, {'idx': 408, 'label': 1}, {'idx': 409, 'label': 2}, {'idx': 410, 'label': 1}, {'idx': 411, 'label': 2}, {'idx': 412, 'label': 1}, {'idx': 413, 'label': 1}, {'idx': 414, 'label': 2}, {'idx': 415, 'label': 1}, {'idx': 416, 'label': 1}, {'idx': 417, 'label': 1}, {'idx': 418, 'label': 2}, {'idx': 419, 'label': 1}, {'idx': 420, 'label': 1}, {'idx': 421, 'label': 2}, {'idx': 422, 'label': 2}, {'idx': 423, 'label': 2}, {'idx': 424, 'label': 1}, {'idx': 425, 'label': 1}, {'idx': 426, 'label': 2}, {'idx': 427, 'label': 1}, {'idx': 428, 'label': 1}, {'idx': 429, 'label': 1}, {'idx': 430, 'label': 2}, {'idx': 431, 'label': 2}, {'idx': 432, 'label': 2}, {'idx': 433, 'label': 1}, {'idx': 434, 'label': 2}, {'idx': 435, 'label': 2}, {'idx': 436, 'label': 1}, {'idx': 437, 'label': 2}, {'idx': 438, 'label': 2}, {'idx': 439, 'label': 1}, {'idx': 440, 'label': 2}, {'idx': 441, 'label': 1}, {'idx': 442, 'label': 2}, {'idx': 443, 'label': 1}, {'idx': 444, 'label': 2}, {'idx': 445, 'label': 1}, {'idx': 446, 'label': 2}, {'idx': 447, 'label': 2}, {'idx': 448, 'label': 1}, {'idx': 449, 'label': 2}, {'idx': 450, 'label': 2}, {'idx': 451, 'label': 1}, {'idx': 452, 'label': 1}, {'idx': 453, 'label': 1}, {'idx': 454, 'label': 2}, {'idx': 455, 'label': 1}, {'idx': 456, 'label': 2}, {'idx': 457, 'label': 1}, {'idx': 458, 'label': 1}, {'idx': 459, 'label': 2}, {'idx': 460, 'label': 1}, {'idx': 461, 'label': 1}, {'idx': 462, 'label': 2}, {'idx': 463, 'label': 1}, {'idx': 464, 'label': 1}, {'idx': 465, 'label': 1}, {'idx': 466, 'label': 1}, {'idx': 467, 'label': 1}, {'idx': 468, 'label': 1}, {'idx': 469, 'label': 2}, {'idx': 470, 'label': 1}, {'idx': 471, 'label': 2}, {'idx': 472, 'label': 2}, {'idx': 473, 'label': 2}, {'idx': 474, 'label': 2}, {'idx': 475, 'label': 2}, {'idx': 476, 'label': 2}, {'idx': 477, 'label': 2}, {'idx': 478, 'label': 2}, {'idx': 479, 'label': 1}, {'idx': 480, 'label': 2}, {'idx': 481, 'label': 1}, {'idx': 482, 'label': 2}, {'idx': 483, 'label': 1}, {'idx': 484, 'label': 1}, {'idx': 485, 'label': 2}, {'idx': 486, 'label': 1}, {'idx': 487, 'label': 2}, {'idx': 488, 'label': 1}, {'idx': 489, 'label': 2}, {'idx': 490, 'label': 1}, {'idx': 491, 'label': 1}, {'idx': 492, 'label': 2}, {'idx': 493, 'label': 2}, {'idx': 494, 'label': 2}, {'idx': 495, 'label': 1}, {'idx': 496, 'label': 2}, {'idx': 497, 'label': 2}, {'idx': 498, 'label': 2}, {'idx': 499, 'label': 1}, {'idx': 500, 'label': 2}]\n",
            "##### write_json to :  /content/jiant-rev/exp/runs/simple/test_preds.p.copa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2QlfkqiDj4H"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/jiant-rev')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B80mbhzqnCrl"
      },
      "source": [
        "!rm -rf ./exp/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pav6-Z8PtBhR"
      },
      "source": [
        "!rm -rf ./exp/tasks/data/wic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjN067cBstSj"
      },
      "source": [
        "!rm -rf /root/.cache/huggingface/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ5qEFdxmfps",
        "outputId": "94979d3e-0c11-43b3-a1c1-2c577e6f8354"
      },
      "source": [
        "# write predictions to file (wic)\n",
        "from jiant.proj.simple import runscript as run\n",
        "import jiant.scripts.download_data.runscript as downloader\n",
        "\n",
        "#EXP_DIR = \"/content/jiant-rev/exp\"\n",
        "EXP_DIR = \"./exp\"\n",
        "\n",
        "# Download the Data\n",
        "downloader.download_data([\"wic\"], f\"{EXP_DIR}/tasks\")\n",
        "\n",
        "# Set up the arguments for the Simple API\n",
        "args = run.RunConfiguration(\n",
        "   run_name=\"simple\",\n",
        "   exp_dir=EXP_DIR,\n",
        "   data_dir=f\"{EXP_DIR}/tasks\",\n",
        "   hf_pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
        "   tasks=\"wic\",\n",
        "   train_batch_size=16,\n",
        "   num_train_epochs=3,\n",
        "   write_test_preds=True\n",
        ")\n",
        "\n",
        "# Run!\n",
        "run.run_simple(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### hf_datasets_tasks_download, task_name:  wic , task_data_path:  /content/jiant-rev/exp/tasks/data/wic\n",
            "##### load_dataset(), path= super_glue , name= wic\n",
            "##### is_ko_model :  True\n",
            "Using custom data configuration default-6746b2c6f0597a4c\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-6746b2c6f0597a4c/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n",
            "100% 3/3 [00:00<00:00, 13245.17it/s]\n",
            "100% 3/3 [00:00<00:00, 1424.05it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-6746b2c6f0597a4c/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 855.81it/s]\n",
            "Downloaded and generated configs for 'wic' (1/1)\n",
            "##### run_simple(): Tokenizing Task 'wic' for phases 'train,val,test'\n",
            "WiCTask\n",
            "  [train]: /content/jiant-rev/exp/tasks/data/wic/train.jsonl\n",
            "  [val]: /content/jiant-rev/exp/tasks/data/wic/val.jsonl\n",
            "  [test]: /content/jiant-rev/exp/tasks/data/wic/test.jsonl\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "Tokenizing:   0% 0/7748 [00:00<?, ?it/s]Project (20, 23) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   1% 81/7748 [00:00<00:09, 801.46it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (18, 20) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Tokenizing:   2% 163/7748 [00:00<00:09, 810.70it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   3% 248/7748 [00:00<00:09, 827.23it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 6) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (24, 27) into empty span in target sequence\n",
            "Project (17, 20) into empty span in target sequence\n",
            "Tokenizing:   4% 336/7748 [00:00<00:08, 845.23it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Project (6, 8) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   5% 421/7748 [00:00<00:08, 822.42it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   7% 504/7748 [00:00<00:08, 822.57it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (18, 19) into empty span in target sequence\n",
            "Project (34, 36) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   8% 595/7748 [00:00<00:08, 848.02it/s]Project (13, 15) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (6, 9) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   9% 680/7748 [00:00<00:08, 842.63it/s]Project (2, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  10% 766/7748 [00:00<00:08, 847.18it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (13, 14) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  11% 851/7748 [00:01<00:08, 847.34it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  12% 936/7748 [00:01<00:08, 837.19it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (19, 21) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  13% 1020/7748 [00:01<00:08, 819.70it/s]Project (20, 22) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  14% 1105/7748 [00:01<00:08, 828.60it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (7, 10) into empty span in target sequence\n",
            "Project (21, 23) into empty span in target sequence\n",
            "Project (21, 23) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  15% 1189/7748 [00:01<00:07, 829.83it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (18, 20) into empty span in target sequence\n",
            "Tokenizing:  17% 1279/7748 [00:01<00:07, 848.59it/s]Project (11, 13) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (38, 39) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  18% 1373/7748 [00:01<00:07, 875.21it/s]Project (45, 47) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (12, 13) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  19% 1464/7748 [00:01<00:07, 878.95it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (26, 28) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (44, 46) into empty span in target sequence\n",
            "Project (16, 17) into empty span in target sequence\n",
            "Tokenizing:  20% 1552/7748 [00:01<00:07, 873.68it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (41, 42) into empty span in target sequence\n",
            "Tokenizing:  21% 1640/7748 [00:01<00:06, 872.86it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Tokenizing:  22% 1728/7748 [00:02<00:06, 874.72it/s]Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (6, 8) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  23% 1816/7748 [00:02<00:06, 855.05it/s]Project (5, 7) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (31, 33) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (27, 30) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (18, 19) into empty span in target sequence\n",
            "Tokenizing:  25% 1902/7748 [00:02<00:06, 842.99it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (31, 33) into empty span in target sequence\n",
            "Tokenizing:  26% 1992/7748 [00:02<00:06, 857.04it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (16, 19) into empty span in target sequence\n",
            "Project (10, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (19, 20) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  27% 2085/7748 [00:02<00:06, 876.82it/s]Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (31, 33) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (32, 33) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  28% 2173/7748 [00:02<00:06, 870.45it/s]Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (16, 18) into empty span in target sequence\n",
            "Project (19, 21) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  29% 2261/7748 [00:02<00:06, 868.42it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  30% 2351/7748 [00:02<00:06, 876.83it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  31% 2440/7748 [00:02<00:06, 878.25it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (32, 35) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  33% 2528/7748 [00:02<00:06, 853.52it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (23, 26) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  34% 2619/7748 [00:03<00:05, 869.94it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (7, 9) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (32, 33) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Tokenizing:  35% 2707/7748 [00:03<00:05, 862.83it/s]Project (34, 36) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (10, 12) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (10, 12) into empty span in target sequence\n",
            "Tokenizing:  36% 2800/7748 [00:03<00:05, 881.13it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (7, 8) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (24, 26) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  37% 2890/7748 [00:03<00:05, 884.49it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Tokenizing:  38% 2979/7748 [00:03<00:05, 883.01it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (26, 27) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (32, 34) into empty span in target sequence\n",
            "Project (11, 12) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  40% 3072/7748 [00:03<00:05, 896.54it/s]Project (11, 13) into empty span in target sequence\n",
            "Project (7, 10) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (20, 22) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (27, 29) into empty span in target sequence\n",
            "Tokenizing:  41% 3166/7748 [00:03<00:05, 908.85it/s]Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  42% 3257/7748 [00:03<00:04, 900.57it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  43% 3348/7748 [00:03<00:05, 863.11it/s]Project (98, 99) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (7, 9) into empty span in target sequence\n",
            "Tokenizing:  44% 3435/7748 [00:04<00:09, 443.82it/s]Project (139, 141) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (56, 57) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  45% 3502/7748 [00:04<00:12, 337.71it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (76, 77) into empty span in target sequence\n",
            "Tokenizing:  46% 3555/7748 [00:04<00:14, 281.71it/s]Project (56, 57) into empty span in target sequence\n",
            "Tokenizing:  46% 3598/7748 [00:05<00:15, 269.80it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (78, 79) into empty span in target sequence\n",
            "Tokenizing:  47% 3635/7748 [00:05<00:15, 258.63it/s]Project (65, 68) into empty span in target sequence\n",
            "Project (27, 30) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  47% 3668/7748 [00:05<00:16, 246.31it/s]Project (67, 68) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  48% 3697/7748 [00:05<00:17, 233.84it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  49% 3771/7748 [00:06<00:18, 214.34it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  49% 3816/7748 [00:06<00:19, 202.13it/s]Project (204, 205) into empty span in target sequence\n",
            "Project (42, 43) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  50% 3837/7748 [00:06<00:19, 203.41it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  50% 3861/7748 [00:06<00:18, 211.81it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  50% 3909/7748 [00:06<00:17, 213.38it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  51% 3983/7748 [00:07<00:18, 208.50it/s]Project (39, 40) into empty span in target sequence\n",
            "Project (21, 22) into empty span in target sequence\n",
            "Project (135, 136) into empty span in target sequence\n",
            "Tokenizing:  52% 4026/7748 [00:07<00:19, 195.07it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  52% 4046/7748 [00:07<00:19, 189.12it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  52% 4067/7748 [00:07<00:19, 193.73it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  54% 4147/7748 [00:07<00:19, 181.70it/s]Project (144, 145) into empty span in target sequence\n",
            "Tokenizing:  54% 4166/7748 [00:08<00:20, 178.25it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  55% 4225/7748 [00:08<00:19, 179.75it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  55% 4244/7748 [00:08<00:20, 169.27it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  55% 4287/7748 [00:08<00:19, 181.50it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  56% 4315/7748 [00:08<00:16, 207.66it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  56% 4337/7748 [00:08<00:16, 203.42it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  56% 4361/7748 [00:09<00:15, 212.72it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  57% 4383/7748 [00:09<00:16, 203.08it/s]Project (196, 198) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  57% 4424/7748 [00:09<00:19, 170.52it/s]Project (75, 76) into empty span in target sequence\n",
            "Tokenizing:  57% 4446/7748 [00:09<00:18, 182.86it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  58% 4467/7748 [00:09<00:17, 187.30it/s]Project (82, 83) into empty span in target sequence\n",
            "Tokenizing:  58% 4507/7748 [00:09<00:17, 183.58it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  58% 4527/7748 [00:09<00:17, 186.95it/s]Project (67, 68) into empty span in target sequence\n",
            "Tokenizing:  59% 4548/7748 [00:10<00:16, 192.23it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  60% 4637/7748 [00:10<00:17, 182.77it/s]Project (91, 92) into empty span in target sequence\n",
            "Tokenizing:  61% 4700/7748 [00:10<00:15, 190.68it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  61% 4745/7748 [00:11<00:16, 186.20it/s]Project (88, 89) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  62% 4768/7748 [00:11<00:15, 197.25it/s]Project (57, 59) into empty span in target sequence\n",
            "Tokenizing:  62% 4836/7748 [00:11<00:14, 194.97it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  63% 4884/7748 [00:11<00:13, 214.43it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  64% 4928/7748 [00:12<00:13, 202.21it/s]Project (60, 61) into empty span in target sequence\n",
            "Project (100, 101) into empty span in target sequence\n",
            "Tokenizing:  64% 4949/7748 [00:12<00:14, 196.40it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  64% 4970/7748 [00:12<00:13, 199.58it/s]Project (36, 37) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  64% 4996/7748 [00:12<00:12, 215.57it/s]Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  65% 5023/7748 [00:12<00:12, 224.35it/s]Project (64, 65) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  65% 5047/7748 [00:12<00:12, 220.92it/s]Project (84, 85) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  66% 5131/7748 [00:13<00:13, 190.80it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  66% 5151/7748 [00:13<00:14, 175.96it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  67% 5174/7748 [00:13<00:13, 189.55it/s]Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  67% 5196/7748 [00:13<00:13, 193.24it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  67% 5216/7748 [00:13<00:14, 177.29it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  68% 5238/7748 [00:13<00:14, 167.76it/s]Project (55, 56) into empty span in target sequence\n",
            "Tokenizing:  69% 5326/7748 [00:14<00:12, 197.71it/s]Project (15, 16) into empty span in target sequence\n",
            "Project (70, 71) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  69% 5347/7748 [00:14<00:12, 190.24it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  69% 5367/7748 [00:14<00:13, 180.09it/s]Project (22, 23) into empty span in target sequence\n",
            "Tokenizing:  70% 5392/7748 [00:14<00:11, 197.84it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  70% 5413/7748 [00:14<00:11, 195.41it/s]Project (1, 2) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  70% 5433/7748 [00:14<00:12, 191.15it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  71% 5519/7748 [00:15<00:11, 193.90it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (82, 83) into empty span in target sequence\n",
            "Project (11, 12) into empty span in target sequence\n",
            "Project (165, 166) into empty span in target sequence\n",
            "Tokenizing:  71% 5539/7748 [00:15<00:11, 185.48it/s]Project (91, 92) into empty span in target sequence\n",
            "Tokenizing:  72% 5559/7748 [00:15<00:11, 189.28it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  72% 5579/7748 [00:15<00:12, 173.53it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  72% 5597/7748 [00:15<00:12, 169.12it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  73% 5637/7748 [00:15<00:12, 174.45it/s]Project (34, 36) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  73% 5656/7748 [00:15<00:11, 177.81it/s]Project (1, 2) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (52, 53) into empty span in target sequence\n",
            "Project (157, 160) into empty span in target sequence\n",
            "Tokenizing:  73% 5680/7748 [00:16<00:10, 193.23it/s]Project (132, 133) into empty span in target sequence\n",
            "Tokenizing:  74% 5707/7748 [00:16<00:09, 211.97it/s]Project (51, 52) into empty span in target sequence\n",
            "Project (204, 205) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  74% 5730/7748 [00:16<00:09, 214.85it/s]Project (6, 7) into empty span in target sequence\n",
            "Project (77, 80) into empty span in target sequence\n",
            "Tokenizing:  75% 5777/7748 [00:16<00:10, 192.42it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  75% 5817/7748 [00:16<00:10, 186.08it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  75% 5837/7748 [00:16<00:10, 188.78it/s]Project (67, 68) into empty span in target sequence\n",
            "Tokenizing:  76% 5857/7748 [00:16<00:10, 177.37it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  76% 5876/7748 [00:17<00:11, 166.20it/s]Project (47, 49) into empty span in target sequence\n",
            "Tokenizing:  77% 5945/7748 [00:17<00:09, 182.92it/s]Project (51, 54) into empty span in target sequence\n",
            "Project (31, 32) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  77% 5968/7748 [00:17<00:09, 193.81it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  77% 5988/7748 [00:17<00:10, 171.45it/s]Project (51, 52) into empty span in target sequence\n",
            "Tokenizing:  78% 6013/7748 [00:17<00:09, 190.70it/s]Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  78% 6033/7748 [00:17<00:08, 191.28it/s]Project (29, 30) into empty span in target sequence\n",
            "Project (85, 86) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (39, 40) into empty span in target sequence\n",
            "Project (12, 15) into empty span in target sequence\n",
            "Tokenizing:  79% 6136/7748 [00:18<00:09, 165.03it/s]Project (103, 106) into empty span in target sequence\n",
            "Tokenizing:  79% 6154/7748 [00:18<00:09, 165.56it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  80% 6181/7748 [00:18<00:08, 191.93it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  80% 6201/7748 [00:18<00:08, 186.24it/s]Project (18, 19) into empty span in target sequence\n",
            "Tokenizing:  81% 6249/7748 [00:19<00:08, 180.34it/s]Project (27, 28) into empty span in target sequence\n",
            "Tokenizing:  81% 6268/7748 [00:19<00:08, 178.32it/s]Project (78, 79) into empty span in target sequence\n",
            "Tokenizing:  82% 6368/7748 [00:19<00:07, 183.76it/s]Project (179, 180) into empty span in target sequence\n",
            "Tokenizing:  82% 6387/7748 [00:19<00:09, 143.95it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  83% 6450/7748 [00:20<00:07, 178.68it/s]Project (71, 72) into empty span in target sequence\n",
            "Project (13, 14) into empty span in target sequence\n",
            "Tokenizing:  84% 6473/7748 [00:20<00:06, 190.79it/s]Project (24, 27) into empty span in target sequence\n",
            "Tokenizing:  84% 6513/7748 [00:20<00:06, 179.61it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (78, 79) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (99, 102) into empty span in target sequence\n",
            "Tokenizing:  85% 6577/7748 [00:20<00:06, 185.24it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  85% 6600/7748 [00:21<00:05, 195.38it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  85% 6620/7748 [00:21<00:05, 191.01it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  86% 6643/7748 [00:21<00:05, 200.92it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  86% 6668/7748 [00:21<00:05, 213.75it/s]Project (109, 111) into empty span in target sequence\n",
            "Tokenizing:  86% 6690/7748 [00:21<00:05, 200.60it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  87% 6711/7748 [00:21<00:05, 188.05it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  87% 6739/7748 [00:21<00:04, 211.51it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (179, 180) into empty span in target sequence\n",
            "Tokenizing:  87% 6761/7748 [00:21<00:04, 198.04it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  88% 6782/7748 [00:21<00:05, 182.23it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (39, 40) into empty span in target sequence\n",
            "Project (109, 111) into empty span in target sequence\n",
            "Tokenizing:  88% 6838/7748 [00:22<00:05, 164.71it/s]Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  89% 6863/7748 [00:22<00:04, 185.40it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  90% 6935/7748 [00:22<00:03, 205.12it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (19, 20) into empty span in target sequence\n",
            "Tokenizing:  90% 6976/7748 [00:22<00:04, 189.87it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  91% 7015/7748 [00:23<00:03, 184.38it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  91% 7034/7748 [00:23<00:04, 174.57it/s]Project (52, 53) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  91% 7076/7748 [00:23<00:03, 188.83it/s]Project (20, 21) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  92% 7096/7748 [00:23<00:03, 180.53it/s]Project (1, 2) into empty span in target sequence\n",
            "Project (26, 28) into empty span in target sequence\n",
            "Tokenizing:  92% 7120/7748 [00:23<00:03, 196.74it/s]Project (31, 32) into empty span in target sequence\n",
            "Project (49, 50) into empty span in target sequence\n",
            "Project (54, 55) into empty span in target sequence\n",
            "Tokenizing:  92% 7142/7748 [00:23<00:03, 200.65it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  92% 7163/7748 [00:24<00:03, 164.13it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  93% 7189/7748 [00:24<00:02, 186.98it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  93% 7209/7748 [00:24<00:02, 185.68it/s]Project (16, 17) into empty span in target sequence\n",
            "Project (107, 108) into empty span in target sequence\n",
            "Tokenizing:  93% 7230/7748 [00:24<00:02, 187.95it/s]Project (12, 13) into empty span in target sequence\n",
            "Tokenizing:  94% 7255/7748 [00:24<00:02, 203.83it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (125, 126) into empty span in target sequence\n",
            "Project (42, 43) into empty span in target sequence\n",
            "Tokenizing:  94% 7297/7748 [00:24<00:02, 192.63it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  95% 7322/7748 [00:24<00:02, 206.81it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  95% 7366/7748 [00:24<00:01, 208.65it/s]Project (30, 31) into empty span in target sequence\n",
            "Tokenizing:  96% 7409/7748 [00:25<00:01, 196.15it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Project (84, 85) into empty span in target sequence\n",
            "Tokenizing:  96% 7429/7748 [00:25<00:01, 191.11it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  96% 7449/7748 [00:25<00:01, 172.64it/s]Project (139, 141) into empty span in target sequence\n",
            "Tokenizing:  96% 7470/7748 [00:25<00:01, 181.13it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  97% 7493/7748 [00:25<00:01, 172.93it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  97% 7533/7748 [00:25<00:01, 181.28it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  98% 7589/7748 [00:26<00:00, 171.23it/s]Project (126, 127) into empty span in target sequence\n",
            "Tokenizing:  98% 7607/7748 [00:26<00:00, 171.85it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (195, 196) into empty span in target sequence\n",
            "Project (55, 56) into empty span in target sequence\n",
            "Tokenizing:  98% 7626/7748 [00:26<00:00, 176.13it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  99% 7646/7748 [00:26<00:00, 181.63it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (39, 40) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (165, 166) into empty span in target sequence\n",
            "Tokenizing:  99% 7688/7748 [00:26<00:00, 184.74it/s]Project (97, 98) into empty span in target sequence\n",
            "Tokenizing: 100% 7748/7748 [00:27<00:00, 286.18it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 7748/7748 [00:00<00:00, 110033.34it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:01<00:00,  1.76s/it]\n",
            "Tokenizing:   0% 0/1166 [00:00<?, ?it/s]Project (5, 7) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   7% 83/1166 [00:00<00:01, 828.16it/s]Project (16, 19) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  14% 166/1166 [00:00<00:01, 812.29it/s]Project (12, 14) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  22% 255/1166 [00:00<00:01, 846.16it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Project (17, 19) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (11, 12) into empty span in target sequence\n",
            "Tokenizing:  30% 345/1166 [00:00<00:00, 862.13it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (19, 21) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (21, 22) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  37% 432/1166 [00:00<00:00, 839.46it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  45% 523/1166 [00:00<00:00, 861.28it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (21, 23) into empty span in target sequence\n",
            "Tokenizing:  53% 617/1166 [00:00<00:00, 868.22it/s]Project (51, 52) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (51, 52) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (65, 68) into empty span in target sequence\n",
            "Project (79, 80) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  60% 704/1166 [00:01<00:01, 379.61it/s]Project (47, 48) into empty span in target sequence\n",
            "Project (51, 52) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  66% 769/1166 [00:01<00:01, 268.08it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (41, 42) into empty span in target sequence\n",
            "Tokenizing:  70% 818/1166 [00:02<00:01, 228.25it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (94, 95) into empty span in target sequence\n",
            "Tokenizing:  76% 889/1166 [00:02<00:01, 204.28it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  79% 917/1166 [00:02<00:01, 206.26it/s]Project (51, 52) into empty span in target sequence\n",
            "Tokenizing:  83% 967/1166 [00:02<00:01, 186.99it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  85% 988/1166 [00:03<00:00, 179.89it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  87% 1010/1166 [00:03<00:00, 187.15it/s]Project (26, 27) into empty span in target sequence\n",
            "Tokenizing:  90% 1050/1166 [00:03<00:00, 176.72it/s]Project (26, 27) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  92% 1070/1166 [00:03<00:00, 181.24it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  95% 1106/1166 [00:03<00:00, 159.30it/s]Project (39, 40) into empty span in target sequence\n",
            "Tokenizing:  97% 1127/1166 [00:03<00:00, 171.34it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (46, 47) into empty span in target sequence\n",
            "Tokenizing:  98% 1146/1166 [00:03<00:00, 170.81it/s]Project (1, 2) into empty span in target sequence\n",
            "Tokenizing: 100% 1166/1166 [00:04<00:00, 289.09it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 1166/1166 [00:00<00:00, 121311.67it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  4.38it/s]\n",
            "Tokenizing:   0% 0/1246 [00:00<?, ?it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (29, 31) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (26, 27) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (17, 18) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (25, 27) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:   8% 98/1246 [00:00<00:01, 979.23it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (25, 26) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  16% 196/1246 [00:00<00:01, 973.86it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  24% 294/1246 [00:00<00:01, 882.85it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  31% 388/1246 [00:00<00:00, 902.05it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (23, 24) into empty span in target sequence\n",
            "Tokenizing:  39% 489/1246 [00:00<00:00, 935.60it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 12) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  47% 584/1246 [00:00<00:00, 936.61it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  54% 679/1246 [00:00<00:00, 934.35it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (147, 150) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (26, 27) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  62% 773/1246 [00:01<00:00, 486.42it/s]Project (55, 56) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (31, 32) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  68% 845/1246 [00:01<00:01, 333.84it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (17, 18) into empty span in target sequence\n",
            "Project (77, 78) into empty span in target sequence\n",
            "Project (36, 37) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  72% 900/1246 [00:01<00:01, 289.07it/s]Project (102, 103) into empty span in target sequence\n",
            "Tokenizing:  79% 980/1246 [00:02<00:01, 235.55it/s]Project (88, 89) into empty span in target sequence\n",
            "Tokenizing:  81% 1011/1246 [00:02<00:01, 234.40it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (12, 13) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  83% 1040/1246 [00:02<00:01, 201.20it/s]Project (139, 141) into empty span in target sequence\n",
            "Project (39, 40) into empty span in target sequence\n",
            "Project (34, 36) into empty span in target sequence\n",
            "Tokenizing:  85% 1064/1246 [00:02<00:00, 196.18it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  87% 1086/1246 [00:02<00:00, 185.49it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  89% 1108/1246 [00:03<00:00, 191.49it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  91% 1129/1246 [00:03<00:00, 174.15it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  92% 1148/1246 [00:03<00:00, 147.64it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  98% 1217/1246 [00:03<00:00, 145.49it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing: 100% 1246/1246 [00:04<00:00, 307.93it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 1246/1246 [00:00<00:00, 117585.84it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  4.34it/s]\n",
            "Running from start\n",
            "  jiant_task_container_config_path: /content/jiant-rev/exp/run_configs/simple_config.json\n",
            "  output_dir: /content/jiant-rev/exp/runs/simple\n",
            "  hf_pretrained_model_name_or_path: monologg/koelectra-base-v3-discriminator\n",
            "  model_path: /content/jiant-rev/exp/models/electra/model/model.p\n",
            "  model_config_path: /content/jiant-rev/exp/models/electra/model/config.json\n",
            "  model_load_mode: from_transformers\n",
            "  do_train: True\n",
            "  do_val: True\n",
            "  do_save: False\n",
            "  do_save_last: False\n",
            "  do_save_best: False\n",
            "  write_val_preds: False\n",
            "  write_test_preds: True\n",
            "  eval_every_steps: 0\n",
            "  save_every_steps: 0\n",
            "  save_checkpoint_every_steps: 0\n",
            "  no_improvements_for_n_evals: 0\n",
            "  keep_checkpoint_when_done: False\n",
            "  force_overwrite: False\n",
            "  seed: -1\n",
            "  learning_rate: 1e-05\n",
            "  adam_epsilon: 1e-08\n",
            "  max_grad_norm: 1.0\n",
            "  optimizer_type: adam\n",
            "  no_cuda: False\n",
            "  fp16: False\n",
            "  fp16_opt_level: O1\n",
            "  local_rank: -1\n",
            "  server_ip: \n",
            "  server_port: \n",
            "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Using seed: 3270024546\n",
            "{\n",
            "  \"jiant_task_container_config_path\": \"/content/jiant-rev/exp/run_configs/simple_config.json\",\n",
            "  \"output_dir\": \"/content/jiant-rev/exp/runs/simple\",\n",
            "  \"hf_pretrained_model_name_or_path\": \"monologg/koelectra-base-v3-discriminator\",\n",
            "  \"model_path\": \"/content/jiant-rev/exp/models/electra/model/model.p\",\n",
            "  \"model_config_path\": \"/content/jiant-rev/exp/models/electra/model/config.json\",\n",
            "  \"model_load_mode\": \"from_transformers\",\n",
            "  \"do_train\": true,\n",
            "  \"do_val\": true,\n",
            "  \"do_save\": false,\n",
            "  \"do_save_last\": false,\n",
            "  \"do_save_best\": false,\n",
            "  \"write_val_preds\": false,\n",
            "  \"write_test_preds\": true,\n",
            "  \"eval_every_steps\": 0,\n",
            "  \"save_every_steps\": 0,\n",
            "  \"save_checkpoint_every_steps\": 0,\n",
            "  \"no_improvements_for_n_evals\": 0,\n",
            "  \"keep_checkpoint_when_done\": false,\n",
            "  \"force_overwrite\": false,\n",
            "  \"seed\": 3270024546,\n",
            "  \"learning_rate\": 1e-05,\n",
            "  \"adam_epsilon\": 1e-08,\n",
            "  \"max_grad_norm\": 1.0,\n",
            "  \"optimizer_type\": \"adam\",\n",
            "  \"no_cuda\": false,\n",
            "  \"fp16\": false,\n",
            "  \"fp16_opt_level\": \"O1\",\n",
            "  \"local_rank\": -1,\n",
            "  \"server_ip\": \"\",\n",
            "  \"server_port\": \"\"\n",
            "}\n",
            "1\n",
            "Creating Tasks:\n",
            "    wic (WiCTask): /content/jiant-rev/exp/tasks/configs/wic_config.json\n",
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "##### encoder_prefix: electra.\n",
            "##### k :  electra.embeddings.position_ids\n",
            "##### k :  electra.embeddings.word_embeddings.weight\n",
            "##### k :  electra.embeddings.position_embeddings.weight\n",
            "##### k :  electra.embeddings.token_type_embeddings.weight\n",
            "##### k :  electra.embeddings.LayerNorm.weight\n",
            "##### k :  electra.embeddings.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.bias\n",
            "##### k :  discriminator_predictions.dense.weight\n",
            "##### k :  discriminator_predictions.dense.bias\n",
            "##### k :  discriminator_predictions.dense_prediction.weight\n",
            "##### k :  discriminator_predictions.dense_prediction.bias\n",
            "No optimizer decay for:\n",
            "  encoder.embeddings.LayerNorm.weight\n",
            "  encoder.embeddings.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.attention.self.query.bias\n",
            "  encoder.encoder.layer.0.attention.self.key.bias\n",
            "  encoder.encoder.layer.0.attention.self.value.bias\n",
            "  encoder.encoder.layer.0.attention.output.dense.bias\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.intermediate.dense.bias\n",
            "  encoder.encoder.layer.0.output.dense.bias\n",
            "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.attention.self.query.bias\n",
            "  encoder.encoder.layer.1.attention.self.key.bias\n",
            "  encoder.encoder.layer.1.attention.self.value.bias\n",
            "  encoder.encoder.layer.1.attention.output.dense.bias\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.intermediate.dense.bias\n",
            "  encoder.encoder.layer.1.output.dense.bias\n",
            "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.attention.self.query.bias\n",
            "  encoder.encoder.layer.2.attention.self.key.bias\n",
            "  encoder.encoder.layer.2.attention.self.value.bias\n",
            "  encoder.encoder.layer.2.attention.output.dense.bias\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.intermediate.dense.bias\n",
            "  encoder.encoder.layer.2.output.dense.bias\n",
            "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.attention.self.query.bias\n",
            "  encoder.encoder.layer.3.attention.self.key.bias\n",
            "  encoder.encoder.layer.3.attention.self.value.bias\n",
            "  encoder.encoder.layer.3.attention.output.dense.bias\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.intermediate.dense.bias\n",
            "  encoder.encoder.layer.3.output.dense.bias\n",
            "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.attention.self.query.bias\n",
            "  encoder.encoder.layer.4.attention.self.key.bias\n",
            "  encoder.encoder.layer.4.attention.self.value.bias\n",
            "  encoder.encoder.layer.4.attention.output.dense.bias\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.intermediate.dense.bias\n",
            "  encoder.encoder.layer.4.output.dense.bias\n",
            "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.attention.self.query.bias\n",
            "  encoder.encoder.layer.5.attention.self.key.bias\n",
            "  encoder.encoder.layer.5.attention.self.value.bias\n",
            "  encoder.encoder.layer.5.attention.output.dense.bias\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.intermediate.dense.bias\n",
            "  encoder.encoder.layer.5.output.dense.bias\n",
            "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.attention.self.query.bias\n",
            "  encoder.encoder.layer.6.attention.self.key.bias\n",
            "  encoder.encoder.layer.6.attention.self.value.bias\n",
            "  encoder.encoder.layer.6.attention.output.dense.bias\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.intermediate.dense.bias\n",
            "  encoder.encoder.layer.6.output.dense.bias\n",
            "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.attention.self.query.bias\n",
            "  encoder.encoder.layer.7.attention.self.key.bias\n",
            "  encoder.encoder.layer.7.attention.self.value.bias\n",
            "  encoder.encoder.layer.7.attention.output.dense.bias\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.intermediate.dense.bias\n",
            "  encoder.encoder.layer.7.output.dense.bias\n",
            "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.attention.self.query.bias\n",
            "  encoder.encoder.layer.8.attention.self.key.bias\n",
            "  encoder.encoder.layer.8.attention.self.value.bias\n",
            "  encoder.encoder.layer.8.attention.output.dense.bias\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.intermediate.dense.bias\n",
            "  encoder.encoder.layer.8.output.dense.bias\n",
            "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.attention.self.query.bias\n",
            "  encoder.encoder.layer.9.attention.self.key.bias\n",
            "  encoder.encoder.layer.9.attention.self.value.bias\n",
            "  encoder.encoder.layer.9.attention.output.dense.bias\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.intermediate.dense.bias\n",
            "  encoder.encoder.layer.9.output.dense.bias\n",
            "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.attention.self.query.bias\n",
            "  encoder.encoder.layer.10.attention.self.key.bias\n",
            "  encoder.encoder.layer.10.attention.self.value.bias\n",
            "  encoder.encoder.layer.10.attention.output.dense.bias\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.intermediate.dense.bias\n",
            "  encoder.encoder.layer.10.output.dense.bias\n",
            "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.attention.self.query.bias\n",
            "  encoder.encoder.layer.11.attention.self.key.bias\n",
            "  encoder.encoder.layer.11.attention.self.value.bias\n",
            "  encoder.encoder.layer.11.attention.output.dense.bias\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.intermediate.dense.bias\n",
            "  encoder.encoder.layer.11.output.dense.bias\n",
            "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
            "  taskmodels_dict.wic.head.span_attention_extractor._global_attention._module.bias\n",
            "  taskmodels_dict.wic.head.classifier.bias\n",
            "Using AdamW\n",
            "##### do_train #####\n",
            "##### run_train_context() #####\n",
            "##### get_train_dataloader_dict() :  1\n",
            "Training: 100% 1454/1455 [08:32<00:00,  2.84it/s]\n",
            "Eval (wic, Val): 100% 16/16 [00:03<00:00,  5.20it/s]\n",
            "##### get_accumulated(), logits :  [[-9.9027389e-01 -2.9570609e-01]\n",
            " [ 1.1874107e+00 -1.5080168e+00]\n",
            " [ 1.7521821e+00 -1.5764595e+00]\n",
            " [-2.2680886e+00  1.4570558e+00]\n",
            " [-2.0081558e+00  1.4508579e+00]\n",
            " [ 1.1866961e+00 -1.4714394e+00]\n",
            " [ 1.6385144e+00 -1.5369245e+00]\n",
            " [-1.1838185e+00  7.7177918e-01]\n",
            " [ 1.6303407e+00 -1.4348698e+00]\n",
            " [ 2.5818920e-01 -9.7572494e-01]\n",
            " [ 1.9464215e+00 -1.8547536e+00]\n",
            " [-2.1673379e+00  1.5191619e+00]\n",
            " [-1.6523663e+00  1.0019317e+00]\n",
            " [-4.4478245e-02 -7.4886739e-01]\n",
            " [ 8.3393669e-01 -1.3446422e+00]\n",
            " [ 1.8579568e+00 -1.7655175e+00]\n",
            " [ 6.8810087e-01 -9.6694827e-01]\n",
            " [ 2.0859902e+00 -1.6468254e+00]\n",
            " [ 1.6061314e+00 -1.6626260e+00]\n",
            " [-2.1352742e+00  1.3110137e+00]\n",
            " [-1.9595811e+00  1.3729404e+00]\n",
            " [ 1.5248774e+00 -1.4859171e+00]\n",
            " [-3.6173120e-02 -5.2692747e-01]\n",
            " [ 2.3444965e-02 -2.6275399e-01]\n",
            " [ 5.8899909e-01 -6.6868472e-01]\n",
            " [-1.6016120e+00  9.6067679e-01]\n",
            " [ 1.5746242e+00 -1.8510262e+00]\n",
            " [ 1.8192419e+00 -1.8584287e+00]\n",
            " [-1.5928160e+00  8.1498718e-01]\n",
            " [-7.1598035e-01  2.3492081e-01]\n",
            " [ 3.1063303e-01 -5.0379217e-01]\n",
            " [-1.8930433e+00  1.2114329e+00]\n",
            " [ 1.6478533e+00 -1.2785904e+00]\n",
            " [-8.2078159e-02 -8.9841449e-01]\n",
            " [ 1.1053697e+00 -8.9862573e-01]\n",
            " [-1.2607861e+00  6.5211761e-01]\n",
            " [ 1.5280026e+00 -1.8052611e+00]\n",
            " [ 4.0596217e-01 -9.8340046e-01]\n",
            " [ 8.3977407e-01 -1.5456544e+00]\n",
            " [ 1.0367252e+00 -1.0245667e+00]\n",
            " [ 1.0693756e+00 -1.1658151e+00]\n",
            " [-2.2269442e+00  1.4703741e+00]\n",
            " [-4.0093988e-01 -1.9987230e-01]\n",
            " [ 1.7734486e+00 -1.8919014e+00]\n",
            " [ 1.4229666e+00 -1.5859901e+00]\n",
            " [-1.2107821e+00  3.1234038e-01]\n",
            " [ 8.4242052e-01 -1.4048831e+00]\n",
            " [ 1.2343618e+00 -1.2216305e+00]\n",
            " [ 1.7285565e+00 -2.0258689e+00]\n",
            " [ 7.9171127e-01 -5.5578226e-01]\n",
            " [ 1.3207064e+00 -1.4830880e+00]\n",
            " [ 1.2683953e+00 -1.1534030e+00]\n",
            " [ 1.7978916e+00 -1.6813601e+00]\n",
            " [ 3.1220666e-01 -1.0855193e+00]\n",
            " [-7.7509636e-01 -1.2958743e-01]\n",
            " [-1.4374870e+00  1.0089846e+00]\n",
            " [ 7.9848397e-01 -5.0694269e-01]\n",
            " [-1.5443354e+00  8.9658117e-01]\n",
            " [-1.6998049e+00  1.1040587e+00]\n",
            " [-2.1424477e+00  1.3046131e+00]\n",
            " [ 1.0485872e+00 -7.9483902e-01]\n",
            " [-1.6214808e+00  1.1738846e+00]\n",
            " [-1.9822794e+00  1.3879392e+00]\n",
            " [ 1.6331671e+00 -1.8512313e+00]\n",
            " [ 5.2100152e-01 -5.7685351e-01]\n",
            " [ 6.5608525e-01 -6.9473612e-01]\n",
            " [ 1.2904549e-01 -8.9638096e-01]\n",
            " [-3.6222425e-01 -2.6920429e-01]\n",
            " [ 7.5496274e-01 -7.4383062e-01]\n",
            " [-6.2478822e-02 -4.5904881e-01]\n",
            " [ 6.7378110e-01 -8.9494485e-01]\n",
            " [-2.2351615e+00  1.2356470e+00]\n",
            " [-1.5474330e+00  1.0809677e+00]\n",
            " [-2.3936186e+00  1.5280955e+00]\n",
            " [-1.8551577e+00  1.1570694e+00]\n",
            " [ 7.6912957e-01 -8.4845614e-01]\n",
            " [-2.3022521e+00  1.5516617e+00]\n",
            " [-2.2981639e+00  1.5086352e+00]\n",
            " [-1.5422407e+00  1.1237762e+00]\n",
            " [-2.2332203e+00  1.3880112e+00]\n",
            " [ 9.5287189e-02 -3.6026564e-01]\n",
            " [ 2.1195693e-01 -5.4513609e-01]\n",
            " [-2.7128823e+00  1.5576791e+00]\n",
            " [-1.8757647e+00  1.2514932e+00]\n",
            " [ 9.0495902e-01 -7.1637565e-01]\n",
            " [-2.3074930e+00  1.5367405e+00]\n",
            " [-1.6953236e+00  9.5963466e-01]\n",
            " [-6.2210273e-02 -5.7118726e-01]\n",
            " [-2.2367609e+00  1.5329874e+00]\n",
            " [-1.8706363e+00  9.7264743e-01]\n",
            " [ 1.7809421e+00 -1.7391745e+00]\n",
            " [ 1.4139358e+00 -1.9264014e+00]\n",
            " [ 1.6175424e+00 -1.4644120e+00]\n",
            " [-1.7029794e+00  1.2090201e+00]\n",
            " [ 2.5107035e-01 -9.1888309e-01]\n",
            " [-2.0948391e+00  1.3211343e+00]\n",
            " [ 1.2153097e+00 -1.1424199e+00]\n",
            " [-1.8634852e+00  1.1661677e+00]\n",
            " [-1.9678169e+00  1.3441248e+00]\n",
            " [-1.6349379e+00  8.9021713e-01]\n",
            " [ 3.8396433e-01 -1.0628393e+00]\n",
            " [-1.7188803e+00  7.9304910e-01]\n",
            " [-2.5491512e+00  1.7736310e+00]\n",
            " [-7.3088151e-01  3.0397379e-01]\n",
            " [ 8.5100442e-01 -1.0265839e+00]\n",
            " [-8.0394334e-01 -5.3797502e-02]\n",
            " [-1.1836027e+00  6.8877208e-01]\n",
            " [ 1.2729608e+00 -1.2957968e+00]\n",
            " [-4.4040594e-01 -3.6191065e-02]\n",
            " [ 6.2783998e-01 -1.0166490e+00]\n",
            " [-1.3165466e+00  6.0380256e-01]\n",
            " [ 6.3871987e-02 -3.5051858e-01]\n",
            " [-2.2802894e+00  1.6979117e+00]\n",
            " [-1.2692102e+00  9.6032333e-01]\n",
            " [-1.5167304e+00  5.8550292e-01]\n",
            " [-1.2878968e+00  3.8656476e-01]\n",
            " [-2.0763581e+00  1.1480169e+00]\n",
            " [-1.7326528e+00  1.3232977e+00]\n",
            " [ 5.0406128e-01 -9.1196579e-01]\n",
            " [ 5.2710521e-01 -9.4131154e-01]\n",
            " [-1.6838397e+00  1.1295342e+00]\n",
            " [-2.4300332e+00  1.6310247e+00]\n",
            " [-1.7750543e+00  1.1318382e+00]\n",
            " [-2.3361113e+00  1.4889820e+00]\n",
            " [-2.3118262e+00  1.6432440e+00]\n",
            " [-2.2047374e+00  1.6267660e+00]\n",
            " [ 8.1173152e-01 -1.2439569e+00]\n",
            " [-2.1641209e+00  1.5823812e+00]\n",
            " [ 1.0040296e+00 -1.0621804e+00]\n",
            " [-1.5587615e+00  8.0737251e-01]\n",
            " [ 6.2659472e-01 -4.9529508e-01]\n",
            " [-2.2415667e+00  1.3642716e+00]\n",
            " [ 1.3003017e+00 -1.2375684e+00]\n",
            " [ 1.7479631e+00 -1.2849659e+00]\n",
            " [-2.1418583e+00  1.4954951e+00]\n",
            " [ 8.3232456e-01 -1.0312104e+00]\n",
            " [ 1.8444815e+00 -2.1344976e+00]\n",
            " [ 1.3340560e-01 -7.1518373e-01]\n",
            " [-2.0130284e+00  1.4052452e+00]\n",
            " [ 3.2128516e-01 -7.2036546e-01]\n",
            " [ 5.7145965e-01 -1.1116507e+00]\n",
            " [-2.0121386e+00  1.5215483e+00]\n",
            " [ 1.1033978e+00 -1.2344618e+00]\n",
            " [ 1.3962692e+00 -1.1361129e+00]\n",
            " [-2.3707990e-01  5.0406929e-02]\n",
            " [ 1.3335713e+00 -1.2413988e+00]\n",
            " [-2.1069949e+00  1.1551825e+00]\n",
            " [ 1.5349778e+00 -1.7142940e+00]\n",
            " [ 1.1668066e+00 -1.0359322e+00]\n",
            " [-1.0720376e+00  8.3601052e-01]\n",
            " [ 1.5529386e+00 -1.7502668e+00]\n",
            " [ 7.9183221e-02 -4.6968919e-01]\n",
            " [-3.5535789e-01 -1.2867822e-01]\n",
            " [ 1.0261801e-01 -3.9514646e-01]\n",
            " [ 1.4862443e+00 -1.5296431e+00]\n",
            " [ 1.6285285e+00 -2.1692998e+00]\n",
            " [-5.5178005e-01 -5.4961704e-03]\n",
            " [-7.7332884e-01  1.7921254e-01]\n",
            " [-2.1673977e+00  1.4000502e+00]\n",
            " [ 1.5528216e+00 -1.7681595e+00]\n",
            " [-1.3754731e+00  1.0339795e+00]\n",
            " [ 8.6643249e-01 -9.6102709e-01]\n",
            " [-1.9792367e+00  9.7451186e-01]\n",
            " [ 1.1596720e+00 -1.5107540e+00]\n",
            " [ 1.3048383e+00 -1.2213302e+00]\n",
            " [-2.0765517e+00  1.7099948e+00]\n",
            " [ 1.8719867e-01 -8.2324433e-01]\n",
            " [-1.7765021e+00  1.3134041e+00]\n",
            " [-2.4970598e+00  1.5073617e+00]\n",
            " [-2.5394092e+00  1.6239173e+00]\n",
            " [-1.7900113e+00  1.3219317e+00]\n",
            " [-2.1899753e+00  1.3323191e+00]\n",
            " [-4.2776999e-01  3.2521868e-01]\n",
            " [-5.7720106e-02 -8.8173711e-01]\n",
            " [-2.2759540e+00  1.5813832e+00]\n",
            " [ 1.0767485e+00 -1.5560670e+00]\n",
            " [-1.7397507e+00  1.2754989e+00]\n",
            " [ 7.0162719e-01 -1.3015747e+00]\n",
            " [-1.3344012e+00  7.1817720e-01]\n",
            " [ 1.0969855e+00 -1.2838936e+00]\n",
            " [-1.5978092e+00  7.3757875e-01]\n",
            " [-2.3700681e+00  1.4008527e+00]\n",
            " [ 1.3762848e-01 -4.6031982e-01]\n",
            " [-3.6104506e-01 -9.7672001e-02]\n",
            " [-1.8052864e+00  1.3604834e+00]\n",
            " [-5.3557128e-01  2.2720210e-01]\n",
            " [-7.6151985e-01  4.8628223e-01]\n",
            " [ 1.5969681e+00 -1.7051724e+00]\n",
            " [-1.3591503e+00  8.1698471e-01]\n",
            " [ 1.6384352e+00 -1.5626957e+00]\n",
            " [-3.1518734e-01 -3.6273602e-01]\n",
            " [-2.1933758e+00  1.5409327e+00]\n",
            " [-1.7167927e+00  1.4101870e+00]\n",
            " [ 2.8911743e-02 -8.6055174e-02]\n",
            " [-2.1333443e-01 -4.2104548e-01]\n",
            " [ 7.8249222e-01 -7.9905546e-01]\n",
            " [-1.4322213e+00  8.9008516e-01]\n",
            " [-2.0589232e+00  1.5957326e+00]\n",
            " [ 1.2621390e+00 -8.4256810e-01]\n",
            " [ 1.6316787e+00 -1.7775109e+00]\n",
            " [ 8.2688695e-01 -1.0989716e+00]\n",
            " [-1.7159926e+00  5.8285069e-01]\n",
            " [-1.7684318e+00  1.2077203e+00]\n",
            " [ 1.4993973e+00 -1.6049223e+00]\n",
            " [ 9.8747295e-01 -1.2272186e+00]\n",
            " [-1.8577684e+00  1.4842477e+00]\n",
            " [-1.2881275e+00  5.5683792e-01]\n",
            " [ 7.7381259e-01 -1.3028624e+00]\n",
            " [ 3.0176976e-01 -3.8862038e-01]\n",
            " [-3.6913046e-01  2.2427247e-01]\n",
            " [-3.9262512e-01 -3.7826851e-01]\n",
            " [-2.1426852e+00  1.2003627e+00]\n",
            " [-1.1215625e+00  3.1074148e-01]\n",
            " [ 4.4593665e-01 -7.0848072e-01]\n",
            " [-2.3150250e-02 -1.9113360e-01]\n",
            " [-1.5054044e+00  7.9724133e-01]\n",
            " [-2.4186835e+00  1.6471310e+00]\n",
            " [-1.6652421e+00  1.4078794e+00]\n",
            " [ 9.1456866e-01 -1.3022251e+00]\n",
            " [ 1.5628344e+00 -1.5963589e+00]\n",
            " [-1.6405307e+00  1.0854797e+00]\n",
            " [-2.1209004e+00  1.5479765e+00]\n",
            " [-8.8598686e-01  1.3069394e-01]\n",
            " [-1.2090821e+00  6.5046394e-01]\n",
            " [ 1.2786710e+00 -1.5769224e+00]\n",
            " [-1.3496298e-01  4.0429886e-02]\n",
            " [ 1.4689680e+00 -1.3913158e+00]\n",
            " [-5.6524324e-01  4.6461141e-01]\n",
            " [ 6.9728786e-01 -9.7946393e-01]\n",
            " [-2.6981647e+00  1.6617444e+00]\n",
            " [ 8.9385587e-01 -1.3736901e+00]\n",
            " [ 1.7367860e+00 -1.6514494e+00]\n",
            " [ 1.6062384e+00 -1.5262871e+00]\n",
            " [-1.0613424e+00  9.7199732e-01]\n",
            " [-1.8012820e+00  8.2666278e-01]\n",
            " [-5.0277883e-01 -1.5005788e-01]\n",
            " [-2.5551479e+00  1.8233728e+00]\n",
            " [ 1.9897518e-01 -8.8139200e-01]\n",
            " [-9.6004212e-01  3.1589848e-01]\n",
            " [-7.4153191e-01  1.4281389e-01]\n",
            " [-6.0603611e-02 -3.7639543e-01]\n",
            " [-1.4959425e+00  6.3955611e-01]\n",
            " [-2.4522622e+00  1.3590147e+00]\n",
            " [-2.1397929e+00  1.4211388e+00]\n",
            " [ 1.8666171e+00 -2.0454187e+00]\n",
            " [-1.8234621e+00  1.2110183e+00]\n",
            " [-2.1956620e+00  1.5371640e+00]\n",
            " [-7.0708841e-01  4.3037783e-02]\n",
            " [ 4.8531905e-01 -7.6466066e-01]\n",
            " [-1.9466205e+00  1.1715798e+00]\n",
            " [ 1.7517208e+00 -1.6712967e+00]\n",
            " [ 7.2302181e-01 -7.2839820e-01]\n",
            " [-6.0009539e-01 -1.6118397e-01]\n",
            " [ 8.2771522e-01 -1.0426316e+00]\n",
            " [-1.7427377e+00  1.0899041e+00]\n",
            " [-1.6229149e+00  9.5936334e-01]\n",
            " [-3.4806058e-02 -5.9690952e-01]\n",
            " [-6.6793334e-01 -5.0649498e-02]\n",
            " [ 3.1859455e-01 -5.2216828e-01]\n",
            " [ 1.0619333e+00 -1.0374280e+00]\n",
            " [ 2.6178375e-01 -7.8565836e-01]\n",
            " [-1.0128998e-01  1.5651806e-01]\n",
            " [ 1.6115285e+00 -1.3297977e+00]\n",
            " [-3.4044510e-01 -1.5850426e-01]\n",
            " [ 3.2529166e-01 -5.9908706e-01]\n",
            " [-2.2137935e+00  1.5122838e+00]\n",
            " [-1.3970112e+00  5.3996193e-01]\n",
            " [ 1.2360612e+00 -1.3277464e+00]\n",
            " [ 7.1906972e-01 -9.7362590e-01]\n",
            " [ 1.8225882e+00 -1.7386283e+00]\n",
            " [ 3.6936820e-01 -8.5504770e-01]\n",
            " [ 1.4768416e+00 -1.5852170e+00]\n",
            " [-1.5348939e+00  9.2688787e-01]\n",
            " [-2.0008135e+00  1.3573999e+00]\n",
            " [-4.5896938e-01 -2.4502028e-02]\n",
            " [ 7.9679751e-01 -1.0380661e+00]\n",
            " [-1.8515767e-01 -1.7881595e-01]\n",
            " [-1.2951760e-01 -6.6621339e-01]\n",
            " [-2.1603334e+00  1.4175024e+00]\n",
            " [-4.2310196e-01 -3.5709551e-01]\n",
            " [-7.8791648e-02 -4.3182138e-01]\n",
            " [-2.1301339e+00  1.5126173e+00]\n",
            " [ 1.6602367e+00 -1.8366446e+00]\n",
            " [-2.4146330e+00  1.6155813e+00]\n",
            " [-1.4307524e+00  1.0680730e+00]\n",
            " [-2.1565835e+00  1.6578221e+00]\n",
            " [-1.0703197e+00  5.0520760e-01]\n",
            " [-2.0094242e+00  1.4960573e+00]\n",
            " [ 5.0666672e-01 -1.1085422e+00]\n",
            " [-1.2028756e+00  8.3066666e-01]\n",
            " [-6.0128504e-01 -7.0469722e-02]\n",
            " [ 7.2780982e-02 -3.0650413e-01]\n",
            " [-2.1989272e+00  1.6624854e+00]\n",
            " [-2.1734335e+00  1.8231583e+00]\n",
            " [-2.1572888e+00  1.4443412e+00]\n",
            " [-6.6047138e-01  1.6805391e-01]\n",
            " [ 7.8540319e-01 -7.2259223e-01]\n",
            " [-1.2303057e+00  2.2487499e-01]\n",
            " [ 7.7639765e-01 -1.3694727e+00]\n",
            " [-1.2823519e+00  8.8049614e-01]\n",
            " [-2.3200033e+00  1.4107349e+00]\n",
            " [-2.1811049e+00  1.5507919e+00]\n",
            " [ 1.3422805e+00 -1.1435661e+00]\n",
            " [-1.3530964e+00  8.7504125e-01]\n",
            " [-1.0231127e+00  7.4688613e-01]\n",
            " [ 9.1481632e-01 -1.2921644e+00]\n",
            " [-1.9227291e+00  1.2159107e+00]\n",
            " [ 5.9905022e-01 -1.0415014e+00]\n",
            " [-1.8800559e+00  1.3872116e+00]\n",
            " [ 1.0363812e+00 -1.2232687e+00]\n",
            " [ 1.6418064e-01 -4.7218618e-01]\n",
            " [-1.7899152e+00  1.5852287e+00]\n",
            " [-9.8213035e-01  6.0140055e-01]\n",
            " [ 4.7348163e-01 -8.0234444e-01]\n",
            " [-1.6391689e+00  1.1936181e+00]\n",
            " [ 1.6986967e+00 -1.7937343e+00]\n",
            " [-7.2389251e-01 -5.0081890e-02]\n",
            " [-1.8140213e+00  1.2576574e+00]\n",
            " [ 1.8269651e-01 -6.4977974e-01]\n",
            " [ 4.2287043e-01 -1.0018580e+00]\n",
            " [ 9.7703415e-01 -1.1018083e+00]\n",
            " [ 1.0946881e+00 -1.2176497e+00]\n",
            " [ 1.9776951e+00 -1.3846619e+00]\n",
            " [ 3.1777701e-01 -5.3290361e-01]\n",
            " [-1.5047003e+00  9.9705100e-01]\n",
            " [-1.4320565e+00  6.7628098e-01]\n",
            " [-1.5443047e+00  9.0545183e-01]\n",
            " [-1.8848670e+00  1.2009573e+00]\n",
            " [-6.1965007e-01 -2.1434028e-01]\n",
            " [ 3.7100989e-01 -4.8232415e-01]\n",
            " [ 1.8678590e+00 -2.0706491e+00]\n",
            " [ 1.4167116e+00 -1.4765036e+00]\n",
            " [ 7.2411543e-01 -1.4577572e+00]\n",
            " [-1.9389225e+00  1.3681402e+00]\n",
            " [-2.3816125e+00  1.4391834e+00]\n",
            " [ 1.2605480e+00 -1.0762380e+00]\n",
            " [ 2.8917226e-01 -8.9342290e-01]\n",
            " [-1.4287449e+00  1.2133353e+00]\n",
            " [ 1.3333834e+00 -1.3162938e+00]\n",
            " [ 7.5839716e-01 -1.2019699e+00]\n",
            " [ 2.6016054e-01 -6.2808824e-01]\n",
            " [ 6.3095540e-01 -8.0973756e-01]\n",
            " [ 1.4893969e+00 -1.1881844e+00]\n",
            " [-1.4126936e+00  8.3421147e-01]\n",
            " [-1.2285506e+00 -3.7809275e-03]\n",
            " [-5.0354354e-02 -5.1762497e-01]\n",
            " [-1.4246701e+00  8.0727756e-01]\n",
            " [-2.0317595e+00  1.4785486e+00]\n",
            " [-1.8175577e-01 -3.7612668e-01]\n",
            " [-2.0189247e+00  1.0943004e+00]\n",
            " [ 7.4819273e-01 -1.2933912e+00]\n",
            " [ 1.6333823e+00 -1.6353940e+00]\n",
            " [ 1.8464257e+00 -1.9447873e+00]\n",
            " [-1.4560148e+00  8.7706441e-01]\n",
            " [-1.6771086e+00  1.5700809e+00]\n",
            " [-2.0458386e+00  9.2977917e-01]\n",
            " [-1.7383893e+00  1.1042213e+00]\n",
            " [-6.2052459e-01 -2.5377218e-02]\n",
            " [-2.2255235e+00  1.1409163e+00]\n",
            " [-2.1493056e+00  1.4995174e+00]\n",
            " [-2.1301782e+00  1.3497043e+00]\n",
            " [ 1.9263995e+00 -2.2820711e+00]\n",
            " [ 1.2042648e+00 -1.2322297e+00]\n",
            " [ 1.5063170e+00 -1.2667143e+00]\n",
            " [-4.2352024e-01 -7.4887633e-02]\n",
            " [ 4.8658463e-01 -1.0627689e+00]\n",
            " [ 1.1920694e+00 -1.3207362e+00]\n",
            " [ 1.7048410e+00 -1.4492885e+00]\n",
            " [-3.5364937e-02 -7.7529871e-01]\n",
            " [ 1.0281895e+00 -1.6030591e+00]\n",
            " [-6.1211986e-03 -4.9526310e-01]\n",
            " [ 8.2038945e-01 -1.0350485e+00]\n",
            " [-1.1214304e+00  4.2824602e-01]\n",
            " [-1.1257333e+00  3.6577165e-01]\n",
            " [-1.6832579e+00  1.0885839e+00]\n",
            " [ 9.4003540e-01 -1.1316291e+00]\n",
            " [-1.6545836e+00  1.1520979e+00]\n",
            " [-1.3515794e+00  5.6189013e-01]\n",
            " [ 1.5819440e+00 -1.3796495e+00]\n",
            " [ 7.2552508e-01 -8.2106185e-01]\n",
            " [ 1.6517729e-01 -1.0796182e+00]\n",
            " [-1.9042133e+00  1.0961032e+00]\n",
            " [ 1.4543358e+00 -1.4057450e+00]\n",
            " [-2.1191874e+00  1.5996261e+00]\n",
            " [-2.1613309e+00  1.5194325e+00]\n",
            " [-8.3088607e-01  3.8752362e-01]\n",
            " [ 1.8295201e+00 -1.7932192e+00]\n",
            " [-2.0892484e+00  1.2406881e+00]\n",
            " [ 1.4700691e+00 -1.3771014e+00]\n",
            " [ 1.6133207e+00 -1.6304196e+00]\n",
            " [ 1.8885256e+00 -2.0484483e+00]\n",
            " [ 1.6444917e+00 -1.6107210e+00]\n",
            " [ 1.0341368e+00 -1.0203798e+00]\n",
            " [-2.3527062e+00  1.4100020e+00]\n",
            " [ 1.3002824e+00 -1.5944834e+00]\n",
            " [ 1.3667588e+00 -1.5954434e+00]\n",
            " [-1.1704940e+00  4.6303046e-01]\n",
            " [ 2.1569664e+00 -1.7796804e+00]\n",
            " [-1.7626873e+00  1.4500983e+00]\n",
            " [-2.1883307e+00  1.2971864e+00]\n",
            " [ 1.0112613e+00 -1.0592442e+00]\n",
            " [-1.3901769e+00  9.0609121e-01]\n",
            " [-4.2620653e-01 -1.8630998e-01]\n",
            " [-1.0041176e+00  6.0437185e-01]\n",
            " [-7.5580108e-01  2.1551806e-01]\n",
            " [-1.9936000e+00  1.3696313e+00]\n",
            " [ 4.0436116e-01 -9.1664124e-01]\n",
            " [-1.3861264e+00  5.7184136e-01]\n",
            " [-1.7851349e+00  8.1151247e-01]\n",
            " [ 1.1970950e+00 -1.6054512e+00]\n",
            " [-1.5250046e+00  8.4330517e-01]\n",
            " [ 1.5051513e+00 -1.5422601e+00]\n",
            " [-2.8262392e-01 -7.0446640e-02]\n",
            " [ 1.3424269e+00 -1.6034173e+00]\n",
            " [ 6.2413877e-01 -1.3232282e+00]\n",
            " [ 1.2526960e+00 -1.3371820e+00]\n",
            " [-1.2961036e+00  7.0232552e-01]\n",
            " [-1.3051004e+00  4.9058139e-01]\n",
            " [-1.9412926e+00  1.5278481e+00]\n",
            " [-2.1888223e+00  1.5470660e+00]\n",
            " [ 9.3529624e-01 -1.5726694e+00]\n",
            " [-6.8097788e-01  8.7060034e-06]\n",
            " [-9.9836099e-01  7.1059728e-01]\n",
            " [-2.0978091e+00  1.5805948e+00]\n",
            " [-2.2140634e+00  1.5172905e+00]\n",
            " [-1.9221743e+00  1.5188081e+00]\n",
            " [-1.0053998e+00  5.8720922e-01]\n",
            " [-1.4800607e+00  1.2857553e+00]\n",
            " [-1.3787504e+00  3.4371740e-01]\n",
            " [-5.4570699e-01  1.1563766e-01]\n",
            " [-1.6392535e+00  6.7320323e-01]\n",
            " [ 1.9806060e+00 -1.4844375e+00]\n",
            " [-2.4253573e+00  1.5069152e+00]\n",
            " [-6.5468663e-01  5.8990669e-02]\n",
            " [-5.0305361e-01  2.2623779e-01]\n",
            " [ 1.5300380e+00 -1.6593845e+00]\n",
            " [-1.5129036e+00  8.9477056e-01]\n",
            " [-7.0439023e-01  5.9781428e-02]\n",
            " [ 3.0992576e-01 -7.9476732e-01]\n",
            " [-1.2652148e+00  9.8394394e-01]\n",
            " [-2.9405871e-01 -9.3723089e-02]\n",
            " [-1.3017231e+00  8.8442028e-01]\n",
            " [-2.0274076e+00  1.4885223e+00]\n",
            " [-2.0124872e+00  1.6606610e+00]\n",
            " [ 5.1817423e-01 -8.8618803e-01]\n",
            " [ 2.4325208e-01 -3.7638825e-01]\n",
            " [-2.1847608e+00  1.3659806e+00]\n",
            " [ 2.4309389e-01 -1.1072729e+00]\n",
            " [ 2.0233493e+00 -1.6172899e+00]\n",
            " [-2.3164632e+00  1.2544405e+00]\n",
            " [-7.9953092e-01  2.8023642e-01]\n",
            " [ 2.4848230e-01 -6.2376243e-01]\n",
            " [-1.8489710e+00  1.3251781e+00]\n",
            " [-2.2967436e+00  1.4519818e+00]\n",
            " [-1.1670802e+00  1.7658301e-01]\n",
            " [-2.5652254e+00  1.6221519e+00]\n",
            " [-1.9468542e+00  1.2742848e+00]\n",
            " [-1.9046302e+00  1.0381856e+00]\n",
            " [ 1.7246631e+00 -1.6254165e+00]\n",
            " [-1.5818117e+00  1.0082787e+00]\n",
            " [-1.8684517e+00  1.3213520e+00]\n",
            " [ 2.6515755e-01 -5.6268406e-01]\n",
            " [-1.9829701e+00  1.4646913e+00]\n",
            " [-2.2904403e+00  1.6127883e+00]\n",
            " [-2.1634426e+00  1.2957910e+00]\n",
            " [ 7.1360624e-01 -8.8380456e-01]\n",
            " [-2.5363953e+00  1.5299742e+00]\n",
            " [-1.6411656e+00  8.9834201e-01]\n",
            " [-2.1219051e+00  1.3883433e+00]\n",
            " [ 6.2298363e-01 -3.5440823e-01]\n",
            " [ 9.3322796e-01 -1.3088228e+00]\n",
            " [ 3.9785528e-01 -5.8488280e-01]\n",
            " [-1.6978238e+00  9.5614648e-01]\n",
            " [-2.2445662e+00  1.6882527e+00]\n",
            " [ 8.1206685e-01 -1.1089832e+00]\n",
            " [ 5.9254390e-01 -1.0680853e+00]\n",
            " [ 3.9838860e-03 -2.5120959e-01]\n",
            " [-1.6421878e+00  1.1860549e+00]\n",
            " [-1.9777218e+00  1.5653551e+00]\n",
            " [-2.2587140e+00  1.3582633e+00]\n",
            " [-6.4926624e-02  2.4251331e-01]\n",
            " [-1.0416628e+00  4.5753968e-01]\n",
            " [ 1.1417419e+00 -9.1286731e-01]\n",
            " [ 5.8434111e-01 -7.2749639e-01]\n",
            " [-1.0309134e+00  5.6895804e-01]\n",
            " [-2.0469694e+00  1.4437783e+00]\n",
            " [ 7.8533822e-01 -7.9451257e-01]\n",
            " [-1.3303345e+00  8.8062328e-01]\n",
            " [ 9.8021013e-01 -1.5633360e+00]\n",
            " [-1.8446436e+00  1.3825207e+00]\n",
            " [ 1.1698529e+00 -9.8485637e-01]\n",
            " [-1.7830487e+00  1.1566911e+00]\n",
            " [-1.7541753e+00  1.1233393e+00]\n",
            " [-7.5350142e-01  2.6962164e-01]\n",
            " [-6.5272558e-01  3.1987992e-01]\n",
            " [ 5.8118504e-01 -1.0655098e+00]\n",
            " [ 5.1022071e-01 -7.3619151e-01]\n",
            " [-2.4827564e+00  1.2941017e+00]\n",
            " [-1.1694815e+00  2.5617725e-01]\n",
            " [-2.0276899e+00  1.3437631e+00]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.8 [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1] [1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0\n",
            " 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1\n",
            " 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 0 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0\n",
            " 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
            "##### labels.shape:  (500,) preds.shape:  (500,)\n",
            "##### k, v.shape :  encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140517568929792)\n",
            "##### k, v.shape :  encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140511969017856)\n",
            "##### k, v.shape :  encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140516884480000)\n",
            "##### k, v.shape :  encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140517568933888)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078097408)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568940032)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140516870324224)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568943104)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513550270464)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568946176)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513552629760)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568949248)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513554989056)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568952320)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568955392)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568958464)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140512784809984)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140517568961536)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140513053245440)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568973824)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568976896)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568979968)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513557348352)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568983040)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513489453056)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568986112)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513491812352)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568989184)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513494171648)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568992256)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568995328)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568998400)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511140642816)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140517569001472)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511207751680)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078103552)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078106624)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078109696)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511150080000)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078112768)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511217188864)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078115840)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513496530944)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078118912)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511335677952)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078121984)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078125056)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078128128)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511338037248)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078131200)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511348260864)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078143488)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078146560)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078149632)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511357698048)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078152704)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511402786816)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078155776)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511405146112)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078158848)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511407505408)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078161920)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078164992)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078168064)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511476187136)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078171136)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511543296000)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078183424)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078186496)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078189568)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511485624320)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078192640)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511552733184)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078195712)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511409864704)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078198784)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511412224000)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078201856)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078204928)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078208000)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511671222272)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078211072)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511683805184)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078223360)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078226432)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078229504)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511680659456)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078232576)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511693242368)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078235648)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511738331136)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078238720)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511740690432)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078241792)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078244864)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078247936)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511750914048)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078251008)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511811731456)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078263296)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078266368)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078269440)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511760351232)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078272512)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511821168640)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078275584)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511743049728)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078278656)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511745409024)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078281728)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078284800)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078287872)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511878840320)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078290944)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511939657728)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078303232)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078306304)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078309376)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511747768320)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078312448)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511888277504)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078315520)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511949094912)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078318592)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511952240640)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078321664)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078324736)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078327808)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511954599936)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078330880)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140512080166912)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078343168)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078346240)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078349312)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512089604096)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078352384)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512212287488)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078355456)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512214646784)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078358528)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512217006080)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078361600)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078364672)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078367744)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140512224870400)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078370816)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140512346505216)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078383104)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078386176)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078389248)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512234307584)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078392320)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512355942400)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078395392)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512219365376)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078398464)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512221724672)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078401536)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078404608)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078407680)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140513791442944)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078410752)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140514227650560)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078423040)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078426112)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078429184)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513800880128)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078432256)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514237087744)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078435328)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514496086016)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078438400)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514498445312)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078441472)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078444544)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078447616)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140514932293632)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078450688)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140515234283520)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078462976)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078466048)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078469120)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514941730816)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078472192)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140515243720704)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078475264)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514500804608)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078478336)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514503163904)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078481408)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078484480)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078487552)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140515636936704)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078490624)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140515905372160)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078502912)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078505984)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078509056)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140517568929792)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140511969017856)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140516884480000)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140517568933888)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078097408)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568940032)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140516870324224)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568943104)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513550270464)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568946176)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513552629760)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568949248)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513554989056)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568952320)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568955392)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568958464)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140512784809984)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140517568961536)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140513053245440)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568973824)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568976896)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568979968)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513557348352)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568983040)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513489453056)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568986112)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513491812352)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568989184)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513494171648)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568992256)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568995328)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140517568998400)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511140642816)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140517569001472)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511207751680)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078103552)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078106624)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078109696)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511150080000)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078112768)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511217188864)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078115840)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513496530944)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078118912)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511335677952)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078121984)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078125056)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078128128)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511338037248)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078131200)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511348260864)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078143488)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078146560)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078149632)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511357698048)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078152704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511402786816)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078155776)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511405146112)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078158848)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511407505408)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078161920)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078164992)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078168064)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511476187136)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078171136)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511543296000)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078183424)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078186496)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078189568)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511485624320)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078192640)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511552733184)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078195712)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511409864704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078198784)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511412224000)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078201856)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078204928)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078208000)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511671222272)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078211072)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511683805184)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078223360)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078226432)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078229504)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511680659456)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078232576)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511693242368)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078235648)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511738331136)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078238720)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511740690432)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078241792)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078244864)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078247936)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511750914048)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078251008)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511811731456)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078263296)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078266368)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078269440)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511760351232)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078272512)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511821168640)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078275584)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511743049728)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078278656)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511745409024)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078281728)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078284800)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078287872)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511878840320)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078290944)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140511939657728)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078303232)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078306304)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078309376)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511747768320)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078312448)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511888277504)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078315520)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511949094912)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078318592)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140511952240640)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078321664)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078324736)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078327808)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140511954599936)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078330880)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140512080166912)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078343168)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078346240)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078349312)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512089604096)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078352384)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512212287488)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078355456)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512214646784)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078358528)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512217006080)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078361600)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078364672)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078367744)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140512224870400)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078370816)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140512346505216)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078383104)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078386176)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078389248)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512234307584)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078392320)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512355942400)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078395392)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512219365376)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078398464)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140512221724672)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078401536)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078404608)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078407680)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140513791442944)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078410752)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140514227650560)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078423040)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078426112)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078429184)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140513800880128)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078432256)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514237087744)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078435328)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514496086016)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078438400)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514498445312)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078441472)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078444544)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078447616)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140514932293632)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078450688)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140515234283520)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078462976)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078466048)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078469120)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514941730816)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078472192)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140515243720704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078475264)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514500804608)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078478336)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140514503163904)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078481408)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078484480)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078487552)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140515636936704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140512078490624)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140515905372160)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078502912)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078505984)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140512078509056)\n",
            "##### k, v.shape :  taskmodels_dict.wic.head.span_attention_extractor._global_attention._module.weight torch.Size([1, 768])\n",
            "##### unique_key :  ((1, 768), 140512078512128)\n",
            "##### k, v.shape :  taskmodels_dict.wic.head.span_attention_extractor._global_attention._module.bias torch.Size([1])\n",
            "##### unique_key :  ((1,), 140517569041920)\n",
            "##### k, v.shape :  taskmodels_dict.wic.head.classifier.weight torch.Size([2, 1536])\n",
            "##### unique_key :  ((2, 1536), 140512078515200)\n",
            "##### k, v.shape :  taskmodels_dict.wic.head.classifier.bias torch.Size([2])\n",
            "##### unique_key :  ((2,), 140517569042944)\n",
            "Eval (wic, Val): 100% 16/16 [00:03<00:00,  5.20it/s]\n",
            "##### get_accumulated(), logits :  [[-9.9027389e-01 -2.9570609e-01]\n",
            " [ 1.1874107e+00 -1.5080168e+00]\n",
            " [ 1.7521821e+00 -1.5764595e+00]\n",
            " [-2.2680886e+00  1.4570558e+00]\n",
            " [-2.0081558e+00  1.4508579e+00]\n",
            " [ 1.1866961e+00 -1.4714394e+00]\n",
            " [ 1.6385144e+00 -1.5369245e+00]\n",
            " [-1.1838185e+00  7.7177918e-01]\n",
            " [ 1.6303407e+00 -1.4348698e+00]\n",
            " [ 2.5818920e-01 -9.7572494e-01]\n",
            " [ 1.9464215e+00 -1.8547536e+00]\n",
            " [-2.1673379e+00  1.5191619e+00]\n",
            " [-1.6523663e+00  1.0019317e+00]\n",
            " [-4.4478245e-02 -7.4886739e-01]\n",
            " [ 8.3393669e-01 -1.3446422e+00]\n",
            " [ 1.8579568e+00 -1.7655175e+00]\n",
            " [ 6.8810087e-01 -9.6694827e-01]\n",
            " [ 2.0859902e+00 -1.6468254e+00]\n",
            " [ 1.6061314e+00 -1.6626260e+00]\n",
            " [-2.1352742e+00  1.3110137e+00]\n",
            " [-1.9595811e+00  1.3729404e+00]\n",
            " [ 1.5248774e+00 -1.4859171e+00]\n",
            " [-3.6173120e-02 -5.2692747e-01]\n",
            " [ 2.3444965e-02 -2.6275399e-01]\n",
            " [ 5.8899909e-01 -6.6868472e-01]\n",
            " [-1.6016120e+00  9.6067679e-01]\n",
            " [ 1.5746242e+00 -1.8510262e+00]\n",
            " [ 1.8192419e+00 -1.8584287e+00]\n",
            " [-1.5928160e+00  8.1498718e-01]\n",
            " [-7.1598035e-01  2.3492081e-01]\n",
            " [ 3.1063303e-01 -5.0379217e-01]\n",
            " [-1.8930433e+00  1.2114329e+00]\n",
            " [ 1.6478533e+00 -1.2785904e+00]\n",
            " [-8.2078159e-02 -8.9841449e-01]\n",
            " [ 1.1053697e+00 -8.9862573e-01]\n",
            " [-1.2607861e+00  6.5211761e-01]\n",
            " [ 1.5280026e+00 -1.8052611e+00]\n",
            " [ 4.0596217e-01 -9.8340046e-01]\n",
            " [ 8.3977407e-01 -1.5456544e+00]\n",
            " [ 1.0367252e+00 -1.0245667e+00]\n",
            " [ 1.0693756e+00 -1.1658151e+00]\n",
            " [-2.2269442e+00  1.4703741e+00]\n",
            " [-4.0093988e-01 -1.9987230e-01]\n",
            " [ 1.7734486e+00 -1.8919014e+00]\n",
            " [ 1.4229666e+00 -1.5859901e+00]\n",
            " [-1.2107821e+00  3.1234038e-01]\n",
            " [ 8.4242052e-01 -1.4048831e+00]\n",
            " [ 1.2343618e+00 -1.2216305e+00]\n",
            " [ 1.7285565e+00 -2.0258689e+00]\n",
            " [ 7.9171127e-01 -5.5578226e-01]\n",
            " [ 1.3207064e+00 -1.4830880e+00]\n",
            " [ 1.2683953e+00 -1.1534030e+00]\n",
            " [ 1.7978916e+00 -1.6813601e+00]\n",
            " [ 3.1220666e-01 -1.0855193e+00]\n",
            " [-7.7509636e-01 -1.2958743e-01]\n",
            " [-1.4374870e+00  1.0089846e+00]\n",
            " [ 7.9848397e-01 -5.0694269e-01]\n",
            " [-1.5443354e+00  8.9658117e-01]\n",
            " [-1.6998049e+00  1.1040587e+00]\n",
            " [-2.1424477e+00  1.3046131e+00]\n",
            " [ 1.0485872e+00 -7.9483902e-01]\n",
            " [-1.6214808e+00  1.1738846e+00]\n",
            " [-1.9822794e+00  1.3879392e+00]\n",
            " [ 1.6331671e+00 -1.8512313e+00]\n",
            " [ 5.2100152e-01 -5.7685351e-01]\n",
            " [ 6.5608525e-01 -6.9473612e-01]\n",
            " [ 1.2904549e-01 -8.9638096e-01]\n",
            " [-3.6222425e-01 -2.6920429e-01]\n",
            " [ 7.5496274e-01 -7.4383062e-01]\n",
            " [-6.2478822e-02 -4.5904881e-01]\n",
            " [ 6.7378110e-01 -8.9494485e-01]\n",
            " [-2.2351615e+00  1.2356470e+00]\n",
            " [-1.5474330e+00  1.0809677e+00]\n",
            " [-2.3936186e+00  1.5280955e+00]\n",
            " [-1.8551577e+00  1.1570694e+00]\n",
            " [ 7.6912957e-01 -8.4845614e-01]\n",
            " [-2.3022521e+00  1.5516617e+00]\n",
            " [-2.2981639e+00  1.5086352e+00]\n",
            " [-1.5422407e+00  1.1237762e+00]\n",
            " [-2.2332203e+00  1.3880112e+00]\n",
            " [ 9.5287189e-02 -3.6026564e-01]\n",
            " [ 2.1195693e-01 -5.4513609e-01]\n",
            " [-2.7128823e+00  1.5576791e+00]\n",
            " [-1.8757647e+00  1.2514932e+00]\n",
            " [ 9.0495902e-01 -7.1637565e-01]\n",
            " [-2.3074930e+00  1.5367405e+00]\n",
            " [-1.6953236e+00  9.5963466e-01]\n",
            " [-6.2210273e-02 -5.7118726e-01]\n",
            " [-2.2367609e+00  1.5329874e+00]\n",
            " [-1.8706363e+00  9.7264743e-01]\n",
            " [ 1.7809421e+00 -1.7391745e+00]\n",
            " [ 1.4139358e+00 -1.9264014e+00]\n",
            " [ 1.6175424e+00 -1.4644120e+00]\n",
            " [-1.7029794e+00  1.2090201e+00]\n",
            " [ 2.5107035e-01 -9.1888309e-01]\n",
            " [-2.0948391e+00  1.3211343e+00]\n",
            " [ 1.2153097e+00 -1.1424199e+00]\n",
            " [-1.8634852e+00  1.1661677e+00]\n",
            " [-1.9678169e+00  1.3441248e+00]\n",
            " [-1.6349379e+00  8.9021713e-01]\n",
            " [ 3.8396433e-01 -1.0628393e+00]\n",
            " [-1.7188803e+00  7.9304910e-01]\n",
            " [-2.5491512e+00  1.7736310e+00]\n",
            " [-7.3088151e-01  3.0397379e-01]\n",
            " [ 8.5100442e-01 -1.0265839e+00]\n",
            " [-8.0394334e-01 -5.3797502e-02]\n",
            " [-1.1836027e+00  6.8877208e-01]\n",
            " [ 1.2729608e+00 -1.2957968e+00]\n",
            " [-4.4040594e-01 -3.6191065e-02]\n",
            " [ 6.2783998e-01 -1.0166490e+00]\n",
            " [-1.3165466e+00  6.0380256e-01]\n",
            " [ 6.3871987e-02 -3.5051858e-01]\n",
            " [-2.2802894e+00  1.6979117e+00]\n",
            " [-1.2692102e+00  9.6032333e-01]\n",
            " [-1.5167304e+00  5.8550292e-01]\n",
            " [-1.2878968e+00  3.8656476e-01]\n",
            " [-2.0763581e+00  1.1480169e+00]\n",
            " [-1.7326528e+00  1.3232977e+00]\n",
            " [ 5.0406128e-01 -9.1196579e-01]\n",
            " [ 5.2710521e-01 -9.4131154e-01]\n",
            " [-1.6838397e+00  1.1295342e+00]\n",
            " [-2.4300332e+00  1.6310247e+00]\n",
            " [-1.7750543e+00  1.1318382e+00]\n",
            " [-2.3361113e+00  1.4889820e+00]\n",
            " [-2.3118262e+00  1.6432440e+00]\n",
            " [-2.2047374e+00  1.6267660e+00]\n",
            " [ 8.1173152e-01 -1.2439569e+00]\n",
            " [-2.1641209e+00  1.5823812e+00]\n",
            " [ 1.0040296e+00 -1.0621804e+00]\n",
            " [-1.5587615e+00  8.0737251e-01]\n",
            " [ 6.2659472e-01 -4.9529508e-01]\n",
            " [-2.2415667e+00  1.3642716e+00]\n",
            " [ 1.3003017e+00 -1.2375684e+00]\n",
            " [ 1.7479631e+00 -1.2849659e+00]\n",
            " [-2.1418583e+00  1.4954951e+00]\n",
            " [ 8.3232456e-01 -1.0312104e+00]\n",
            " [ 1.8444815e+00 -2.1344976e+00]\n",
            " [ 1.3340560e-01 -7.1518373e-01]\n",
            " [-2.0130284e+00  1.4052452e+00]\n",
            " [ 3.2128516e-01 -7.2036546e-01]\n",
            " [ 5.7145965e-01 -1.1116507e+00]\n",
            " [-2.0121386e+00  1.5215483e+00]\n",
            " [ 1.1033978e+00 -1.2344618e+00]\n",
            " [ 1.3962692e+00 -1.1361129e+00]\n",
            " [-2.3707990e-01  5.0406929e-02]\n",
            " [ 1.3335713e+00 -1.2413988e+00]\n",
            " [-2.1069949e+00  1.1551825e+00]\n",
            " [ 1.5349778e+00 -1.7142940e+00]\n",
            " [ 1.1668066e+00 -1.0359322e+00]\n",
            " [-1.0720376e+00  8.3601052e-01]\n",
            " [ 1.5529386e+00 -1.7502668e+00]\n",
            " [ 7.9183221e-02 -4.6968919e-01]\n",
            " [-3.5535789e-01 -1.2867822e-01]\n",
            " [ 1.0261801e-01 -3.9514646e-01]\n",
            " [ 1.4862443e+00 -1.5296431e+00]\n",
            " [ 1.6285285e+00 -2.1692998e+00]\n",
            " [-5.5178005e-01 -5.4961704e-03]\n",
            " [-7.7332884e-01  1.7921254e-01]\n",
            " [-2.1673977e+00  1.4000502e+00]\n",
            " [ 1.5528216e+00 -1.7681595e+00]\n",
            " [-1.3754731e+00  1.0339795e+00]\n",
            " [ 8.6643249e-01 -9.6102709e-01]\n",
            " [-1.9792367e+00  9.7451186e-01]\n",
            " [ 1.1596720e+00 -1.5107540e+00]\n",
            " [ 1.3048383e+00 -1.2213302e+00]\n",
            " [-2.0765517e+00  1.7099948e+00]\n",
            " [ 1.8719867e-01 -8.2324433e-01]\n",
            " [-1.7765021e+00  1.3134041e+00]\n",
            " [-2.4970598e+00  1.5073617e+00]\n",
            " [-2.5394092e+00  1.6239173e+00]\n",
            " [-1.7900113e+00  1.3219317e+00]\n",
            " [-2.1899753e+00  1.3323191e+00]\n",
            " [-4.2776999e-01  3.2521868e-01]\n",
            " [-5.7720106e-02 -8.8173711e-01]\n",
            " [-2.2759540e+00  1.5813832e+00]\n",
            " [ 1.0767485e+00 -1.5560670e+00]\n",
            " [-1.7397507e+00  1.2754989e+00]\n",
            " [ 7.0162719e-01 -1.3015747e+00]\n",
            " [-1.3344012e+00  7.1817720e-01]\n",
            " [ 1.0969855e+00 -1.2838936e+00]\n",
            " [-1.5978092e+00  7.3757875e-01]\n",
            " [-2.3700681e+00  1.4008527e+00]\n",
            " [ 1.3762848e-01 -4.6031982e-01]\n",
            " [-3.6104506e-01 -9.7672001e-02]\n",
            " [-1.8052864e+00  1.3604834e+00]\n",
            " [-5.3557128e-01  2.2720210e-01]\n",
            " [-7.6151985e-01  4.8628223e-01]\n",
            " [ 1.5969681e+00 -1.7051724e+00]\n",
            " [-1.3591503e+00  8.1698471e-01]\n",
            " [ 1.6384352e+00 -1.5626957e+00]\n",
            " [-3.1518734e-01 -3.6273602e-01]\n",
            " [-2.1933758e+00  1.5409327e+00]\n",
            " [-1.7167927e+00  1.4101870e+00]\n",
            " [ 2.8911743e-02 -8.6055174e-02]\n",
            " [-2.1333443e-01 -4.2104548e-01]\n",
            " [ 7.8249222e-01 -7.9905546e-01]\n",
            " [-1.4322213e+00  8.9008516e-01]\n",
            " [-2.0589232e+00  1.5957326e+00]\n",
            " [ 1.2621390e+00 -8.4256810e-01]\n",
            " [ 1.6316787e+00 -1.7775109e+00]\n",
            " [ 8.2688695e-01 -1.0989716e+00]\n",
            " [-1.7159926e+00  5.8285069e-01]\n",
            " [-1.7684318e+00  1.2077203e+00]\n",
            " [ 1.4993973e+00 -1.6049223e+00]\n",
            " [ 9.8747295e-01 -1.2272186e+00]\n",
            " [-1.8577684e+00  1.4842477e+00]\n",
            " [-1.2881275e+00  5.5683792e-01]\n",
            " [ 7.7381259e-01 -1.3028624e+00]\n",
            " [ 3.0176976e-01 -3.8862038e-01]\n",
            " [-3.6913046e-01  2.2427247e-01]\n",
            " [-3.9262512e-01 -3.7826851e-01]\n",
            " [-2.1426852e+00  1.2003627e+00]\n",
            " [-1.1215625e+00  3.1074148e-01]\n",
            " [ 4.4593665e-01 -7.0848072e-01]\n",
            " [-2.3150250e-02 -1.9113360e-01]\n",
            " [-1.5054044e+00  7.9724133e-01]\n",
            " [-2.4186835e+00  1.6471310e+00]\n",
            " [-1.6652421e+00  1.4078794e+00]\n",
            " [ 9.1456866e-01 -1.3022251e+00]\n",
            " [ 1.5628344e+00 -1.5963589e+00]\n",
            " [-1.6405307e+00  1.0854797e+00]\n",
            " [-2.1209004e+00  1.5479765e+00]\n",
            " [-8.8598686e-01  1.3069394e-01]\n",
            " [-1.2090821e+00  6.5046394e-01]\n",
            " [ 1.2786710e+00 -1.5769224e+00]\n",
            " [-1.3496298e-01  4.0429886e-02]\n",
            " [ 1.4689680e+00 -1.3913158e+00]\n",
            " [-5.6524324e-01  4.6461141e-01]\n",
            " [ 6.9728786e-01 -9.7946393e-01]\n",
            " [-2.6981647e+00  1.6617444e+00]\n",
            " [ 8.9385587e-01 -1.3736901e+00]\n",
            " [ 1.7367860e+00 -1.6514494e+00]\n",
            " [ 1.6062384e+00 -1.5262871e+00]\n",
            " [-1.0613424e+00  9.7199732e-01]\n",
            " [-1.8012820e+00  8.2666278e-01]\n",
            " [-5.0277883e-01 -1.5005788e-01]\n",
            " [-2.5551479e+00  1.8233728e+00]\n",
            " [ 1.9897518e-01 -8.8139200e-01]\n",
            " [-9.6004212e-01  3.1589848e-01]\n",
            " [-7.4153191e-01  1.4281389e-01]\n",
            " [-6.0603611e-02 -3.7639543e-01]\n",
            " [-1.4959425e+00  6.3955611e-01]\n",
            " [-2.4522622e+00  1.3590147e+00]\n",
            " [-2.1397929e+00  1.4211388e+00]\n",
            " [ 1.8666171e+00 -2.0454187e+00]\n",
            " [-1.8234621e+00  1.2110183e+00]\n",
            " [-2.1956620e+00  1.5371640e+00]\n",
            " [-7.0708841e-01  4.3037783e-02]\n",
            " [ 4.8531905e-01 -7.6466066e-01]\n",
            " [-1.9466205e+00  1.1715798e+00]\n",
            " [ 1.7517208e+00 -1.6712967e+00]\n",
            " [ 7.2302181e-01 -7.2839820e-01]\n",
            " [-6.0009539e-01 -1.6118397e-01]\n",
            " [ 8.2771522e-01 -1.0426316e+00]\n",
            " [-1.7427377e+00  1.0899041e+00]\n",
            " [-1.6229149e+00  9.5936334e-01]\n",
            " [-3.4806058e-02 -5.9690952e-01]\n",
            " [-6.6793334e-01 -5.0649498e-02]\n",
            " [ 3.1859455e-01 -5.2216828e-01]\n",
            " [ 1.0619333e+00 -1.0374280e+00]\n",
            " [ 2.6178375e-01 -7.8565836e-01]\n",
            " [-1.0128998e-01  1.5651806e-01]\n",
            " [ 1.6115285e+00 -1.3297977e+00]\n",
            " [-3.4044510e-01 -1.5850426e-01]\n",
            " [ 3.2529166e-01 -5.9908706e-01]\n",
            " [-2.2137935e+00  1.5122838e+00]\n",
            " [-1.3970112e+00  5.3996193e-01]\n",
            " [ 1.2360612e+00 -1.3277464e+00]\n",
            " [ 7.1906972e-01 -9.7362590e-01]\n",
            " [ 1.8225882e+00 -1.7386283e+00]\n",
            " [ 3.6936820e-01 -8.5504770e-01]\n",
            " [ 1.4768416e+00 -1.5852170e+00]\n",
            " [-1.5348939e+00  9.2688787e-01]\n",
            " [-2.0008135e+00  1.3573999e+00]\n",
            " [-4.5896938e-01 -2.4502028e-02]\n",
            " [ 7.9679751e-01 -1.0380661e+00]\n",
            " [-1.8515767e-01 -1.7881595e-01]\n",
            " [-1.2951760e-01 -6.6621339e-01]\n",
            " [-2.1603334e+00  1.4175024e+00]\n",
            " [-4.2310196e-01 -3.5709551e-01]\n",
            " [-7.8791648e-02 -4.3182138e-01]\n",
            " [-2.1301339e+00  1.5126173e+00]\n",
            " [ 1.6602367e+00 -1.8366446e+00]\n",
            " [-2.4146330e+00  1.6155813e+00]\n",
            " [-1.4307524e+00  1.0680730e+00]\n",
            " [-2.1565835e+00  1.6578221e+00]\n",
            " [-1.0703197e+00  5.0520760e-01]\n",
            " [-2.0094242e+00  1.4960573e+00]\n",
            " [ 5.0666672e-01 -1.1085422e+00]\n",
            " [-1.2028756e+00  8.3066666e-01]\n",
            " [-6.0128504e-01 -7.0469722e-02]\n",
            " [ 7.2780982e-02 -3.0650413e-01]\n",
            " [-2.1989272e+00  1.6624854e+00]\n",
            " [-2.1734335e+00  1.8231583e+00]\n",
            " [-2.1572888e+00  1.4443412e+00]\n",
            " [-6.6047138e-01  1.6805391e-01]\n",
            " [ 7.8540319e-01 -7.2259223e-01]\n",
            " [-1.2303057e+00  2.2487499e-01]\n",
            " [ 7.7639765e-01 -1.3694727e+00]\n",
            " [-1.2823519e+00  8.8049614e-01]\n",
            " [-2.3200033e+00  1.4107349e+00]\n",
            " [-2.1811049e+00  1.5507919e+00]\n",
            " [ 1.3422805e+00 -1.1435661e+00]\n",
            " [-1.3530964e+00  8.7504125e-01]\n",
            " [-1.0231127e+00  7.4688613e-01]\n",
            " [ 9.1481632e-01 -1.2921644e+00]\n",
            " [-1.9227291e+00  1.2159107e+00]\n",
            " [ 5.9905022e-01 -1.0415014e+00]\n",
            " [-1.8800559e+00  1.3872116e+00]\n",
            " [ 1.0363812e+00 -1.2232687e+00]\n",
            " [ 1.6418064e-01 -4.7218618e-01]\n",
            " [-1.7899152e+00  1.5852287e+00]\n",
            " [-9.8213035e-01  6.0140055e-01]\n",
            " [ 4.7348163e-01 -8.0234444e-01]\n",
            " [-1.6391689e+00  1.1936181e+00]\n",
            " [ 1.6986967e+00 -1.7937343e+00]\n",
            " [-7.2389251e-01 -5.0081890e-02]\n",
            " [-1.8140213e+00  1.2576574e+00]\n",
            " [ 1.8269651e-01 -6.4977974e-01]\n",
            " [ 4.2287043e-01 -1.0018580e+00]\n",
            " [ 9.7703415e-01 -1.1018083e+00]\n",
            " [ 1.0946881e+00 -1.2176497e+00]\n",
            " [ 1.9776951e+00 -1.3846619e+00]\n",
            " [ 3.1777701e-01 -5.3290361e-01]\n",
            " [-1.5047003e+00  9.9705100e-01]\n",
            " [-1.4320565e+00  6.7628098e-01]\n",
            " [-1.5443047e+00  9.0545183e-01]\n",
            " [-1.8848670e+00  1.2009573e+00]\n",
            " [-6.1965007e-01 -2.1434028e-01]\n",
            " [ 3.7100989e-01 -4.8232415e-01]\n",
            " [ 1.8678590e+00 -2.0706491e+00]\n",
            " [ 1.4167116e+00 -1.4765036e+00]\n",
            " [ 7.2411543e-01 -1.4577572e+00]\n",
            " [-1.9389225e+00  1.3681402e+00]\n",
            " [-2.3816125e+00  1.4391834e+00]\n",
            " [ 1.2605480e+00 -1.0762380e+00]\n",
            " [ 2.8917226e-01 -8.9342290e-01]\n",
            " [-1.4287449e+00  1.2133353e+00]\n",
            " [ 1.3333834e+00 -1.3162938e+00]\n",
            " [ 7.5839716e-01 -1.2019699e+00]\n",
            " [ 2.6016054e-01 -6.2808824e-01]\n",
            " [ 6.3095540e-01 -8.0973756e-01]\n",
            " [ 1.4893969e+00 -1.1881844e+00]\n",
            " [-1.4126936e+00  8.3421147e-01]\n",
            " [-1.2285506e+00 -3.7809275e-03]\n",
            " [-5.0354354e-02 -5.1762497e-01]\n",
            " [-1.4246701e+00  8.0727756e-01]\n",
            " [-2.0317595e+00  1.4785486e+00]\n",
            " [-1.8175577e-01 -3.7612668e-01]\n",
            " [-2.0189247e+00  1.0943004e+00]\n",
            " [ 7.4819273e-01 -1.2933912e+00]\n",
            " [ 1.6333823e+00 -1.6353940e+00]\n",
            " [ 1.8464257e+00 -1.9447873e+00]\n",
            " [-1.4560148e+00  8.7706441e-01]\n",
            " [-1.6771086e+00  1.5700809e+00]\n",
            " [-2.0458386e+00  9.2977917e-01]\n",
            " [-1.7383893e+00  1.1042213e+00]\n",
            " [-6.2052459e-01 -2.5377218e-02]\n",
            " [-2.2255235e+00  1.1409163e+00]\n",
            " [-2.1493056e+00  1.4995174e+00]\n",
            " [-2.1301782e+00  1.3497043e+00]\n",
            " [ 1.9263995e+00 -2.2820711e+00]\n",
            " [ 1.2042648e+00 -1.2322297e+00]\n",
            " [ 1.5063170e+00 -1.2667143e+00]\n",
            " [-4.2352024e-01 -7.4887633e-02]\n",
            " [ 4.8658463e-01 -1.0627689e+00]\n",
            " [ 1.1920694e+00 -1.3207362e+00]\n",
            " [ 1.7048410e+00 -1.4492885e+00]\n",
            " [-3.5364937e-02 -7.7529871e-01]\n",
            " [ 1.0281895e+00 -1.6030591e+00]\n",
            " [-6.1211986e-03 -4.9526310e-01]\n",
            " [ 8.2038945e-01 -1.0350485e+00]\n",
            " [-1.1214304e+00  4.2824602e-01]\n",
            " [-1.1257333e+00  3.6577165e-01]\n",
            " [-1.6832579e+00  1.0885839e+00]\n",
            " [ 9.4003540e-01 -1.1316291e+00]\n",
            " [-1.6545836e+00  1.1520979e+00]\n",
            " [-1.3515794e+00  5.6189013e-01]\n",
            " [ 1.5819440e+00 -1.3796495e+00]\n",
            " [ 7.2552508e-01 -8.2106185e-01]\n",
            " [ 1.6517729e-01 -1.0796182e+00]\n",
            " [-1.9042133e+00  1.0961032e+00]\n",
            " [ 1.4543358e+00 -1.4057450e+00]\n",
            " [-2.1191874e+00  1.5996261e+00]\n",
            " [-2.1613309e+00  1.5194325e+00]\n",
            " [-8.3088607e-01  3.8752362e-01]\n",
            " [ 1.8295201e+00 -1.7932192e+00]\n",
            " [-2.0892484e+00  1.2406881e+00]\n",
            " [ 1.4700691e+00 -1.3771014e+00]\n",
            " [ 1.6133207e+00 -1.6304196e+00]\n",
            " [ 1.8885256e+00 -2.0484483e+00]\n",
            " [ 1.6444917e+00 -1.6107210e+00]\n",
            " [ 1.0341368e+00 -1.0203798e+00]\n",
            " [-2.3527062e+00  1.4100020e+00]\n",
            " [ 1.3002824e+00 -1.5944834e+00]\n",
            " [ 1.3667588e+00 -1.5954434e+00]\n",
            " [-1.1704940e+00  4.6303046e-01]\n",
            " [ 2.1569664e+00 -1.7796804e+00]\n",
            " [-1.7626873e+00  1.4500983e+00]\n",
            " [-2.1883307e+00  1.2971864e+00]\n",
            " [ 1.0112613e+00 -1.0592442e+00]\n",
            " [-1.3901769e+00  9.0609121e-01]\n",
            " [-4.2620653e-01 -1.8630998e-01]\n",
            " [-1.0041176e+00  6.0437185e-01]\n",
            " [-7.5580108e-01  2.1551806e-01]\n",
            " [-1.9936000e+00  1.3696313e+00]\n",
            " [ 4.0436116e-01 -9.1664124e-01]\n",
            " [-1.3861264e+00  5.7184136e-01]\n",
            " [-1.7851349e+00  8.1151247e-01]\n",
            " [ 1.1970950e+00 -1.6054512e+00]\n",
            " [-1.5250046e+00  8.4330517e-01]\n",
            " [ 1.5051513e+00 -1.5422601e+00]\n",
            " [-2.8262392e-01 -7.0446640e-02]\n",
            " [ 1.3424269e+00 -1.6034173e+00]\n",
            " [ 6.2413877e-01 -1.3232282e+00]\n",
            " [ 1.2526960e+00 -1.3371820e+00]\n",
            " [-1.2961036e+00  7.0232552e-01]\n",
            " [-1.3051004e+00  4.9058139e-01]\n",
            " [-1.9412926e+00  1.5278481e+00]\n",
            " [-2.1888223e+00  1.5470660e+00]\n",
            " [ 9.3529624e-01 -1.5726694e+00]\n",
            " [-6.8097788e-01  8.7060034e-06]\n",
            " [-9.9836099e-01  7.1059728e-01]\n",
            " [-2.0978091e+00  1.5805948e+00]\n",
            " [-2.2140634e+00  1.5172905e+00]\n",
            " [-1.9221743e+00  1.5188081e+00]\n",
            " [-1.0053998e+00  5.8720922e-01]\n",
            " [-1.4800607e+00  1.2857553e+00]\n",
            " [-1.3787504e+00  3.4371740e-01]\n",
            " [-5.4570699e-01  1.1563766e-01]\n",
            " [-1.6392535e+00  6.7320323e-01]\n",
            " [ 1.9806060e+00 -1.4844375e+00]\n",
            " [-2.4253573e+00  1.5069152e+00]\n",
            " [-6.5468663e-01  5.8990669e-02]\n",
            " [-5.0305361e-01  2.2623779e-01]\n",
            " [ 1.5300380e+00 -1.6593845e+00]\n",
            " [-1.5129036e+00  8.9477056e-01]\n",
            " [-7.0439023e-01  5.9781428e-02]\n",
            " [ 3.0992576e-01 -7.9476732e-01]\n",
            " [-1.2652148e+00  9.8394394e-01]\n",
            " [-2.9405871e-01 -9.3723089e-02]\n",
            " [-1.3017231e+00  8.8442028e-01]\n",
            " [-2.0274076e+00  1.4885223e+00]\n",
            " [-2.0124872e+00  1.6606610e+00]\n",
            " [ 5.1817423e-01 -8.8618803e-01]\n",
            " [ 2.4325208e-01 -3.7638825e-01]\n",
            " [-2.1847608e+00  1.3659806e+00]\n",
            " [ 2.4309389e-01 -1.1072729e+00]\n",
            " [ 2.0233493e+00 -1.6172899e+00]\n",
            " [-2.3164632e+00  1.2544405e+00]\n",
            " [-7.9953092e-01  2.8023642e-01]\n",
            " [ 2.4848230e-01 -6.2376243e-01]\n",
            " [-1.8489710e+00  1.3251781e+00]\n",
            " [-2.2967436e+00  1.4519818e+00]\n",
            " [-1.1670802e+00  1.7658301e-01]\n",
            " [-2.5652254e+00  1.6221519e+00]\n",
            " [-1.9468542e+00  1.2742848e+00]\n",
            " [-1.9046302e+00  1.0381856e+00]\n",
            " [ 1.7246631e+00 -1.6254165e+00]\n",
            " [-1.5818117e+00  1.0082787e+00]\n",
            " [-1.8684517e+00  1.3213520e+00]\n",
            " [ 2.6515755e-01 -5.6268406e-01]\n",
            " [-1.9829701e+00  1.4646913e+00]\n",
            " [-2.2904403e+00  1.6127883e+00]\n",
            " [-2.1634426e+00  1.2957910e+00]\n",
            " [ 7.1360624e-01 -8.8380456e-01]\n",
            " [-2.5363953e+00  1.5299742e+00]\n",
            " [-1.6411656e+00  8.9834201e-01]\n",
            " [-2.1219051e+00  1.3883433e+00]\n",
            " [ 6.2298363e-01 -3.5440823e-01]\n",
            " [ 9.3322796e-01 -1.3088228e+00]\n",
            " [ 3.9785528e-01 -5.8488280e-01]\n",
            " [-1.6978238e+00  9.5614648e-01]\n",
            " [-2.2445662e+00  1.6882527e+00]\n",
            " [ 8.1206685e-01 -1.1089832e+00]\n",
            " [ 5.9254390e-01 -1.0680853e+00]\n",
            " [ 3.9838860e-03 -2.5120959e-01]\n",
            " [-1.6421878e+00  1.1860549e+00]\n",
            " [-1.9777218e+00  1.5653551e+00]\n",
            " [-2.2587140e+00  1.3582633e+00]\n",
            " [-6.4926624e-02  2.4251331e-01]\n",
            " [-1.0416628e+00  4.5753968e-01]\n",
            " [ 1.1417419e+00 -9.1286731e-01]\n",
            " [ 5.8434111e-01 -7.2749639e-01]\n",
            " [-1.0309134e+00  5.6895804e-01]\n",
            " [-2.0469694e+00  1.4437783e+00]\n",
            " [ 7.8533822e-01 -7.9451257e-01]\n",
            " [-1.3303345e+00  8.8062328e-01]\n",
            " [ 9.8021013e-01 -1.5633360e+00]\n",
            " [-1.8446436e+00  1.3825207e+00]\n",
            " [ 1.1698529e+00 -9.8485637e-01]\n",
            " [-1.7830487e+00  1.1566911e+00]\n",
            " [-1.7541753e+00  1.1233393e+00]\n",
            " [-7.5350142e-01  2.6962164e-01]\n",
            " [-6.5272558e-01  3.1987992e-01]\n",
            " [ 5.8118504e-01 -1.0655098e+00]\n",
            " [ 5.1022071e-01 -7.3619151e-01]\n",
            " [-2.4827564e+00  1.2941017e+00]\n",
            " [-1.1694815e+00  2.5617725e-01]\n",
            " [-2.0276899e+00  1.3437631e+00]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.8 [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1] [1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0\n",
            " 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1\n",
            " 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 0 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0\n",
            " 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
            "##### labels.shape:  (500,) preds.shape:  (500,)\n",
            "Loading Best\n",
            "Eval (wic, Val): 100% 37/37 [00:07<00:00,  5.25it/s]\n",
            "##### get_accumulated(), logits :  [[-0.9902739  -0.2957061 ]\n",
            " [ 1.1874107  -1.5080168 ]\n",
            " [ 1.7521821  -1.5764595 ]\n",
            " ...\n",
            " [-2.3494072   1.0212669 ]\n",
            " [ 1.8328875  -2.0947852 ]\n",
            " [ 0.27835554 -0.83211535]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.8379073756432247 [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0] [1 0 0 ... 1 0 0]\n",
            "##### labels.shape:  (1166,) preds.shape:  (1166,)\n",
            "{\n",
            "  \"aggregated\": 0.8379073756432247,\n",
            "  \"wic\": {\n",
            "    \"loss\": 0.39631063732746485,\n",
            "    \"metrics\": {\n",
            "      \"major\": 0.8379073756432247,\n",
            "      \"minor\": {\n",
            "        \"acc\": 0.8379073756432247\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "Eval (wic, Test): 100% 39/39 [00:09<00:00,  4.16it/s]\n",
            "##### get_accumulated(), logits :  [[-2.120594    1.2983896 ]\n",
            " [-0.34196642 -0.31046003]\n",
            " [-0.58823013  0.3123639 ]\n",
            " ...\n",
            " [ 0.6671542  -0.90621084]\n",
            " [-2.3528535   1.3174655 ]\n",
            " [-2.8121083   1.7841647 ]]\n",
            "test_task_list : ['wic']\n",
            "##### write_preds(), task_name:  wic 1246\n",
            "[1 1 1 ... 0 1 1]\n",
            "['test-1' 'test-2' 'test-3' ... 'test-1244' 'test-1245' 'test-1246']\n",
            "##### preds_dic_list:  [{'idx': 1, 'label': True}, {'idx': 2, 'label': True}, {'idx': 3, 'label': True}, {'idx': 4, 'label': True}, {'idx': 5, 'label': False}, {'idx': 6, 'label': True}, {'idx': 7, 'label': False}, {'idx': 8, 'label': True}, {'idx': 9, 'label': False}, {'idx': 10, 'label': True}, {'idx': 11, 'label': False}, {'idx': 12, 'label': False}, {'idx': 13, 'label': True}, {'idx': 14, 'label': True}, {'idx': 15, 'label': True}, {'idx': 16, 'label': True}, {'idx': 17, 'label': False}, {'idx': 18, 'label': True}, {'idx': 19, 'label': True}, {'idx': 20, 'label': False}, {'idx': 21, 'label': True}, {'idx': 22, 'label': True}, {'idx': 23, 'label': True}, {'idx': 24, 'label': True}, {'idx': 25, 'label': False}, {'idx': 26, 'label': False}, {'idx': 27, 'label': True}, {'idx': 28, 'label': False}, {'idx': 29, 'label': False}, {'idx': 30, 'label': True}, {'idx': 31, 'label': False}, {'idx': 32, 'label': False}, {'idx': 33, 'label': True}, {'idx': 34, 'label': True}, {'idx': 35, 'label': True}, {'idx': 36, 'label': False}, {'idx': 37, 'label': True}, {'idx': 38, 'label': True}, {'idx': 39, 'label': True}, {'idx': 40, 'label': False}, {'idx': 41, 'label': False}, {'idx': 42, 'label': False}, {'idx': 43, 'label': False}, {'idx': 44, 'label': True}, {'idx': 45, 'label': False}, {'idx': 46, 'label': True}, {'idx': 47, 'label': True}, {'idx': 48, 'label': True}, {'idx': 49, 'label': False}, {'idx': 50, 'label': True}, {'idx': 51, 'label': True}, {'idx': 52, 'label': False}, {'idx': 53, 'label': True}, {'idx': 54, 'label': True}, {'idx': 55, 'label': True}, {'idx': 56, 'label': False}, {'idx': 57, 'label': False}, {'idx': 58, 'label': False}, {'idx': 59, 'label': True}, {'idx': 60, 'label': False}, {'idx': 61, 'label': False}, {'idx': 62, 'label': False}, {'idx': 63, 'label': True}, {'idx': 64, 'label': True}, {'idx': 65, 'label': True}, {'idx': 66, 'label': True}, {'idx': 67, 'label': True}, {'idx': 68, 'label': False}, {'idx': 69, 'label': False}, {'idx': 70, 'label': False}, {'idx': 71, 'label': True}, {'idx': 72, 'label': False}, {'idx': 73, 'label': False}, {'idx': 74, 'label': False}, {'idx': 75, 'label': False}, {'idx': 76, 'label': True}, {'idx': 77, 'label': False}, {'idx': 78, 'label': False}, {'idx': 79, 'label': True}, {'idx': 80, 'label': True}, {'idx': 81, 'label': False}, {'idx': 82, 'label': True}, {'idx': 83, 'label': True}, {'idx': 84, 'label': True}, {'idx': 85, 'label': False}, {'idx': 86, 'label': True}, {'idx': 87, 'label': False}, {'idx': 88, 'label': True}, {'idx': 89, 'label': False}, {'idx': 90, 'label': False}, {'idx': 91, 'label': True}, {'idx': 92, 'label': False}, {'idx': 93, 'label': False}, {'idx': 94, 'label': True}, {'idx': 95, 'label': False}, {'idx': 96, 'label': True}, {'idx': 97, 'label': False}, {'idx': 98, 'label': True}, {'idx': 99, 'label': True}, {'idx': 100, 'label': False}, {'idx': 101, 'label': True}, {'idx': 102, 'label': True}, {'idx': 103, 'label': False}, {'idx': 104, 'label': False}, {'idx': 105, 'label': True}, {'idx': 106, 'label': False}, {'idx': 107, 'label': True}, {'idx': 108, 'label': True}, {'idx': 109, 'label': False}, {'idx': 110, 'label': True}, {'idx': 111, 'label': False}, {'idx': 112, 'label': False}, {'idx': 113, 'label': False}, {'idx': 114, 'label': False}, {'idx': 115, 'label': True}, {'idx': 116, 'label': True}, {'idx': 117, 'label': True}, {'idx': 118, 'label': False}, {'idx': 119, 'label': False}, {'idx': 120, 'label': False}, {'idx': 121, 'label': False}, {'idx': 122, 'label': False}, {'idx': 123, 'label': True}, {'idx': 124, 'label': True}, {'idx': 125, 'label': True}, {'idx': 126, 'label': True}, {'idx': 127, 'label': False}, {'idx': 128, 'label': True}, {'idx': 129, 'label': False}, {'idx': 130, 'label': False}, {'idx': 131, 'label': True}, {'idx': 132, 'label': True}, {'idx': 133, 'label': True}, {'idx': 134, 'label': True}, {'idx': 135, 'label': True}, {'idx': 136, 'label': True}, {'idx': 137, 'label': True}, {'idx': 138, 'label': False}, {'idx': 139, 'label': True}, {'idx': 140, 'label': True}, {'idx': 141, 'label': True}, {'idx': 142, 'label': False}, {'idx': 143, 'label': True}, {'idx': 144, 'label': False}, {'idx': 145, 'label': True}, {'idx': 146, 'label': True}, {'idx': 147, 'label': True}, {'idx': 148, 'label': False}, {'idx': 149, 'label': True}, {'idx': 150, 'label': True}, {'idx': 151, 'label': True}, {'idx': 152, 'label': True}, {'idx': 153, 'label': True}, {'idx': 154, 'label': True}, {'idx': 155, 'label': False}, {'idx': 156, 'label': True}, {'idx': 157, 'label': True}, {'idx': 158, 'label': True}, {'idx': 159, 'label': False}, {'idx': 160, 'label': False}, {'idx': 161, 'label': True}, {'idx': 162, 'label': True}, {'idx': 163, 'label': False}, {'idx': 164, 'label': False}, {'idx': 165, 'label': False}, {'idx': 166, 'label': True}, {'idx': 167, 'label': False}, {'idx': 168, 'label': True}, {'idx': 169, 'label': False}, {'idx': 170, 'label': False}, {'idx': 171, 'label': True}, {'idx': 172, 'label': True}, {'idx': 173, 'label': False}, {'idx': 174, 'label': False}, {'idx': 175, 'label': True}, {'idx': 176, 'label': True}, {'idx': 177, 'label': False}, {'idx': 178, 'label': False}, {'idx': 179, 'label': False}, {'idx': 180, 'label': False}, {'idx': 181, 'label': False}, {'idx': 182, 'label': False}, {'idx': 183, 'label': True}, {'idx': 184, 'label': True}, {'idx': 185, 'label': True}, {'idx': 186, 'label': True}, {'idx': 187, 'label': True}, {'idx': 188, 'label': False}, {'idx': 189, 'label': True}, {'idx': 190, 'label': False}, {'idx': 191, 'label': True}, {'idx': 192, 'label': True}, {'idx': 193, 'label': True}, {'idx': 194, 'label': True}, {'idx': 195, 'label': False}, {'idx': 196, 'label': True}, {'idx': 197, 'label': True}, {'idx': 198, 'label': True}, {'idx': 199, 'label': True}, {'idx': 200, 'label': True}, {'idx': 201, 'label': False}, {'idx': 202, 'label': False}, {'idx': 203, 'label': False}, {'idx': 204, 'label': True}, {'idx': 205, 'label': True}, {'idx': 206, 'label': True}, {'idx': 207, 'label': False}, {'idx': 208, 'label': False}, {'idx': 209, 'label': True}, {'idx': 210, 'label': True}, {'idx': 211, 'label': True}, {'idx': 212, 'label': False}, {'idx': 213, 'label': True}, {'idx': 214, 'label': False}, {'idx': 215, 'label': True}, {'idx': 216, 'label': False}, {'idx': 217, 'label': True}, {'idx': 218, 'label': False}, {'idx': 219, 'label': True}, {'idx': 220, 'label': False}, {'idx': 221, 'label': True}, {'idx': 222, 'label': True}, {'idx': 223, 'label': True}, {'idx': 224, 'label': False}, {'idx': 225, 'label': False}, {'idx': 226, 'label': True}, {'idx': 227, 'label': True}, {'idx': 228, 'label': False}, {'idx': 229, 'label': False}, {'idx': 230, 'label': True}, {'idx': 231, 'label': True}, {'idx': 232, 'label': True}, {'idx': 233, 'label': True}, {'idx': 234, 'label': False}, {'idx': 235, 'label': True}, {'idx': 236, 'label': True}, {'idx': 237, 'label': False}, {'idx': 238, 'label': True}, {'idx': 239, 'label': True}, {'idx': 240, 'label': True}, {'idx': 241, 'label': False}, {'idx': 242, 'label': False}, {'idx': 243, 'label': False}, {'idx': 244, 'label': True}, {'idx': 245, 'label': True}, {'idx': 246, 'label': True}, {'idx': 247, 'label': True}, {'idx': 248, 'label': False}, {'idx': 249, 'label': True}, {'idx': 250, 'label': False}, {'idx': 251, 'label': False}, {'idx': 252, 'label': True}, {'idx': 253, 'label': True}, {'idx': 254, 'label': True}, {'idx': 255, 'label': False}, {'idx': 256, 'label': True}, {'idx': 257, 'label': True}, {'idx': 258, 'label': True}, {'idx': 259, 'label': True}, {'idx': 260, 'label': True}, {'idx': 261, 'label': True}, {'idx': 262, 'label': False}, {'idx': 263, 'label': True}, {'idx': 264, 'label': True}, {'idx': 265, 'label': False}, {'idx': 266, 'label': False}, {'idx': 267, 'label': True}, {'idx': 268, 'label': False}, {'idx': 269, 'label': False}, {'idx': 270, 'label': False}, {'idx': 271, 'label': False}, {'idx': 272, 'label': True}, {'idx': 273, 'label': False}, {'idx': 274, 'label': True}, {'idx': 275, 'label': False}, {'idx': 276, 'label': False}, {'idx': 277, 'label': False}, {'idx': 278, 'label': True}, {'idx': 279, 'label': True}, {'idx': 280, 'label': False}, {'idx': 281, 'label': False}, {'idx': 282, 'label': True}, {'idx': 283, 'label': True}, {'idx': 284, 'label': True}, {'idx': 285, 'label': True}, {'idx': 286, 'label': True}, {'idx': 287, 'label': True}, {'idx': 288, 'label': False}, {'idx': 289, 'label': True}, {'idx': 290, 'label': True}, {'idx': 291, 'label': True}, {'idx': 292, 'label': False}, {'idx': 293, 'label': True}, {'idx': 294, 'label': False}, {'idx': 295, 'label': False}, {'idx': 296, 'label': True}, {'idx': 297, 'label': True}, {'idx': 298, 'label': True}, {'idx': 299, 'label': True}, {'idx': 300, 'label': True}, {'idx': 301, 'label': True}, {'idx': 302, 'label': True}, {'idx': 303, 'label': True}, {'idx': 304, 'label': True}, {'idx': 305, 'label': False}, {'idx': 306, 'label': True}, {'idx': 307, 'label': False}, {'idx': 308, 'label': False}, {'idx': 309, 'label': True}, {'idx': 310, 'label': True}, {'idx': 311, 'label': True}, {'idx': 312, 'label': False}, {'idx': 313, 'label': True}, {'idx': 314, 'label': False}, {'idx': 315, 'label': True}, {'idx': 316, 'label': True}, {'idx': 317, 'label': True}, {'idx': 318, 'label': False}, {'idx': 319, 'label': True}, {'idx': 320, 'label': True}, {'idx': 321, 'label': True}, {'idx': 322, 'label': False}, {'idx': 323, 'label': False}, {'idx': 324, 'label': False}, {'idx': 325, 'label': True}, {'idx': 326, 'label': True}, {'idx': 327, 'label': False}, {'idx': 328, 'label': False}, {'idx': 329, 'label': False}, {'idx': 330, 'label': True}, {'idx': 331, 'label': True}, {'idx': 332, 'label': True}, {'idx': 333, 'label': True}, {'idx': 334, 'label': True}, {'idx': 335, 'label': True}, {'idx': 336, 'label': True}, {'idx': 337, 'label': False}, {'idx': 338, 'label': False}, {'idx': 339, 'label': False}, {'idx': 340, 'label': False}, {'idx': 341, 'label': True}, {'idx': 342, 'label': True}, {'idx': 343, 'label': True}, {'idx': 344, 'label': True}, {'idx': 345, 'label': False}, {'idx': 346, 'label': True}, {'idx': 347, 'label': True}, {'idx': 348, 'label': True}, {'idx': 349, 'label': True}, {'idx': 350, 'label': False}, {'idx': 351, 'label': False}, {'idx': 352, 'label': False}, {'idx': 353, 'label': True}, {'idx': 354, 'label': False}, {'idx': 355, 'label': True}, {'idx': 356, 'label': True}, {'idx': 357, 'label': True}, {'idx': 358, 'label': True}, {'idx': 359, 'label': False}, {'idx': 360, 'label': True}, {'idx': 361, 'label': True}, {'idx': 362, 'label': False}, {'idx': 363, 'label': True}, {'idx': 364, 'label': True}, {'idx': 365, 'label': False}, {'idx': 366, 'label': False}, {'idx': 367, 'label': True}, {'idx': 368, 'label': False}, {'idx': 369, 'label': True}, {'idx': 370, 'label': True}, {'idx': 371, 'label': False}, {'idx': 372, 'label': True}, {'idx': 373, 'label': True}, {'idx': 374, 'label': False}, {'idx': 375, 'label': False}, {'idx': 376, 'label': True}, {'idx': 377, 'label': True}, {'idx': 378, 'label': True}, {'idx': 379, 'label': False}, {'idx': 380, 'label': True}, {'idx': 381, 'label': False}, {'idx': 382, 'label': False}, {'idx': 383, 'label': True}, {'idx': 384, 'label': False}, {'idx': 385, 'label': True}, {'idx': 386, 'label': True}, {'idx': 387, 'label': True}, {'idx': 388, 'label': False}, {'idx': 389, 'label': True}, {'idx': 390, 'label': True}, {'idx': 391, 'label': True}, {'idx': 392, 'label': True}, {'idx': 393, 'label': False}, {'idx': 394, 'label': False}, {'idx': 395, 'label': True}, {'idx': 396, 'label': False}, {'idx': 397, 'label': True}, {'idx': 398, 'label': True}, {'idx': 399, 'label': False}, {'idx': 400, 'label': False}, {'idx': 401, 'label': False}, {'idx': 402, 'label': False}, {'idx': 403, 'label': True}, {'idx': 404, 'label': True}, {'idx': 405, 'label': True}, {'idx': 406, 'label': False}, {'idx': 407, 'label': True}, {'idx': 408, 'label': True}, {'idx': 409, 'label': True}, {'idx': 410, 'label': True}, {'idx': 411, 'label': True}, {'idx': 412, 'label': False}, {'idx': 413, 'label': False}, {'idx': 414, 'label': False}, {'idx': 415, 'label': True}, {'idx': 416, 'label': False}, {'idx': 417, 'label': True}, {'idx': 418, 'label': False}, {'idx': 419, 'label': True}, {'idx': 420, 'label': True}, {'idx': 421, 'label': False}, {'idx': 422, 'label': True}, {'idx': 423, 'label': False}, {'idx': 424, 'label': False}, {'idx': 425, 'label': True}, {'idx': 426, 'label': False}, {'idx': 427, 'label': True}, {'idx': 428, 'label': True}, {'idx': 429, 'label': False}, {'idx': 430, 'label': True}, {'idx': 431, 'label': True}, {'idx': 432, 'label': False}, {'idx': 433, 'label': False}, {'idx': 434, 'label': False}, {'idx': 435, 'label': True}, {'idx': 436, 'label': True}, {'idx': 437, 'label': False}, {'idx': 438, 'label': False}, {'idx': 439, 'label': False}, {'idx': 440, 'label': False}, {'idx': 441, 'label': False}, {'idx': 442, 'label': False}, {'idx': 443, 'label': False}, {'idx': 444, 'label': True}, {'idx': 445, 'label': False}, {'idx': 446, 'label': True}, {'idx': 447, 'label': True}, {'idx': 448, 'label': True}, {'idx': 449, 'label': True}, {'idx': 450, 'label': True}, {'idx': 451, 'label': False}, {'idx': 452, 'label': False}, {'idx': 453, 'label': False}, {'idx': 454, 'label': True}, {'idx': 455, 'label': True}, {'idx': 456, 'label': True}, {'idx': 457, 'label': False}, {'idx': 458, 'label': True}, {'idx': 459, 'label': False}, {'idx': 460, 'label': True}, {'idx': 461, 'label': True}, {'idx': 462, 'label': True}, {'idx': 463, 'label': True}, {'idx': 464, 'label': False}, {'idx': 465, 'label': True}, {'idx': 466, 'label': True}, {'idx': 467, 'label': False}, {'idx': 468, 'label': True}, {'idx': 469, 'label': True}, {'idx': 470, 'label': False}, {'idx': 471, 'label': True}, {'idx': 472, 'label': False}, {'idx': 473, 'label': True}, {'idx': 474, 'label': False}, {'idx': 475, 'label': True}, {'idx': 476, 'label': True}, {'idx': 477, 'label': True}, {'idx': 478, 'label': True}, {'idx': 479, 'label': True}, {'idx': 480, 'label': False}, {'idx': 481, 'label': True}, {'idx': 482, 'label': True}, {'idx': 483, 'label': True}, {'idx': 484, 'label': True}, {'idx': 485, 'label': True}, {'idx': 486, 'label': False}, {'idx': 487, 'label': True}, {'idx': 488, 'label': False}, {'idx': 489, 'label': True}, {'idx': 490, 'label': True}, {'idx': 491, 'label': True}, {'idx': 492, 'label': True}, {'idx': 493, 'label': True}, {'idx': 494, 'label': True}, {'idx': 495, 'label': True}, {'idx': 496, 'label': True}, {'idx': 497, 'label': False}, {'idx': 498, 'label': False}, {'idx': 499, 'label': False}, {'idx': 500, 'label': False}, {'idx': 501, 'label': True}, {'idx': 502, 'label': True}, {'idx': 503, 'label': True}, {'idx': 504, 'label': False}, {'idx': 505, 'label': True}, {'idx': 506, 'label': False}, {'idx': 507, 'label': True}, {'idx': 508, 'label': False}, {'idx': 509, 'label': True}, {'idx': 510, 'label': True}, {'idx': 511, 'label': True}, {'idx': 512, 'label': False}, {'idx': 513, 'label': True}, {'idx': 514, 'label': True}, {'idx': 515, 'label': True}, {'idx': 516, 'label': False}, {'idx': 517, 'label': True}, {'idx': 518, 'label': False}, {'idx': 519, 'label': False}, {'idx': 520, 'label': False}, {'idx': 521, 'label': False}, {'idx': 522, 'label': True}, {'idx': 523, 'label': False}, {'idx': 524, 'label': False}, {'idx': 525, 'label': False}, {'idx': 526, 'label': True}, {'idx': 527, 'label': True}, {'idx': 528, 'label': True}, {'idx': 529, 'label': True}, {'idx': 530, 'label': True}, {'idx': 531, 'label': False}, {'idx': 532, 'label': False}, {'idx': 533, 'label': False}, {'idx': 534, 'label': False}, {'idx': 535, 'label': True}, {'idx': 536, 'label': True}, {'idx': 537, 'label': True}, {'idx': 538, 'label': True}, {'idx': 539, 'label': True}, {'idx': 540, 'label': True}, {'idx': 541, 'label': True}, {'idx': 542, 'label': True}, {'idx': 543, 'label': False}, {'idx': 544, 'label': True}, {'idx': 545, 'label': False}, {'idx': 546, 'label': False}, {'idx': 547, 'label': True}, {'idx': 548, 'label': True}, {'idx': 549, 'label': True}, {'idx': 550, 'label': True}, {'idx': 551, 'label': False}, {'idx': 552, 'label': False}, {'idx': 553, 'label': False}, {'idx': 554, 'label': False}, {'idx': 555, 'label': False}, {'idx': 556, 'label': False}, {'idx': 557, 'label': False}, {'idx': 558, 'label': False}, {'idx': 559, 'label': True}, {'idx': 560, 'label': False}, {'idx': 561, 'label': True}, {'idx': 562, 'label': True}, {'idx': 563, 'label': True}, {'idx': 564, 'label': False}, {'idx': 565, 'label': False}, {'idx': 566, 'label': True}, {'idx': 567, 'label': False}, {'idx': 568, 'label': True}, {'idx': 569, 'label': True}, {'idx': 570, 'label': False}, {'idx': 571, 'label': True}, {'idx': 572, 'label': True}, {'idx': 573, 'label': True}, {'idx': 574, 'label': True}, {'idx': 575, 'label': True}, {'idx': 576, 'label': True}, {'idx': 577, 'label': True}, {'idx': 578, 'label': False}, {'idx': 579, 'label': True}, {'idx': 580, 'label': False}, {'idx': 581, 'label': True}, {'idx': 582, 'label': False}, {'idx': 583, 'label': False}, {'idx': 584, 'label': False}, {'idx': 585, 'label': True}, {'idx': 586, 'label': False}, {'idx': 587, 'label': False}, {'idx': 588, 'label': False}, {'idx': 589, 'label': False}, {'idx': 590, 'label': True}, {'idx': 591, 'label': False}, {'idx': 592, 'label': False}, {'idx': 593, 'label': True}, {'idx': 594, 'label': True}, {'idx': 595, 'label': True}, {'idx': 596, 'label': True}, {'idx': 597, 'label': True}, {'idx': 598, 'label': True}, {'idx': 599, 'label': False}, {'idx': 600, 'label': False}, {'idx': 601, 'label': True}, {'idx': 602, 'label': True}, {'idx': 603, 'label': False}, {'idx': 604, 'label': False}, {'idx': 605, 'label': False}, {'idx': 606, 'label': False}, {'idx': 607, 'label': True}, {'idx': 608, 'label': False}, {'idx': 609, 'label': True}, {'idx': 610, 'label': True}, {'idx': 611, 'label': True}, {'idx': 612, 'label': True}, {'idx': 613, 'label': True}, {'idx': 614, 'label': False}, {'idx': 615, 'label': True}, {'idx': 616, 'label': True}, {'idx': 617, 'label': True}, {'idx': 618, 'label': False}, {'idx': 619, 'label': True}, {'idx': 620, 'label': True}, {'idx': 621, 'label': True}, {'idx': 622, 'label': True}, {'idx': 623, 'label': True}, {'idx': 624, 'label': False}, {'idx': 625, 'label': True}, {'idx': 626, 'label': True}, {'idx': 627, 'label': True}, {'idx': 628, 'label': False}, {'idx': 629, 'label': False}, {'idx': 630, 'label': False}, {'idx': 631, 'label': False}, {'idx': 632, 'label': False}, {'idx': 633, 'label': False}, {'idx': 634, 'label': False}, {'idx': 635, 'label': True}, {'idx': 636, 'label': False}, {'idx': 637, 'label': False}, {'idx': 638, 'label': True}, {'idx': 639, 'label': False}, {'idx': 640, 'label': False}, {'idx': 641, 'label': True}, {'idx': 642, 'label': True}, {'idx': 643, 'label': True}, {'idx': 644, 'label': True}, {'idx': 645, 'label': True}, {'idx': 646, 'label': True}, {'idx': 647, 'label': True}, {'idx': 648, 'label': False}, {'idx': 649, 'label': True}, {'idx': 650, 'label': True}, {'idx': 651, 'label': True}, {'idx': 652, 'label': True}, {'idx': 653, 'label': True}, {'idx': 654, 'label': False}, {'idx': 655, 'label': False}, {'idx': 656, 'label': True}, {'idx': 657, 'label': False}, {'idx': 658, 'label': True}, {'idx': 659, 'label': False}, {'idx': 660, 'label': True}, {'idx': 661, 'label': True}, {'idx': 662, 'label': True}, {'idx': 663, 'label': False}, {'idx': 664, 'label': True}, {'idx': 665, 'label': False}, {'idx': 666, 'label': False}, {'idx': 667, 'label': True}, {'idx': 668, 'label': False}, {'idx': 669, 'label': False}, {'idx': 670, 'label': False}, {'idx': 671, 'label': False}, {'idx': 672, 'label': True}, {'idx': 673, 'label': True}, {'idx': 674, 'label': True}, {'idx': 675, 'label': True}, {'idx': 676, 'label': True}, {'idx': 677, 'label': True}, {'idx': 678, 'label': False}, {'idx': 679, 'label': True}, {'idx': 680, 'label': False}, {'idx': 681, 'label': True}, {'idx': 682, 'label': False}, {'idx': 683, 'label': True}, {'idx': 684, 'label': True}, {'idx': 685, 'label': True}, {'idx': 686, 'label': True}, {'idx': 687, 'label': False}, {'idx': 688, 'label': False}, {'idx': 689, 'label': True}, {'idx': 690, 'label': False}, {'idx': 691, 'label': True}, {'idx': 692, 'label': False}, {'idx': 693, 'label': True}, {'idx': 694, 'label': True}, {'idx': 695, 'label': True}, {'idx': 696, 'label': False}, {'idx': 697, 'label': True}, {'idx': 698, 'label': True}, {'idx': 699, 'label': True}, {'idx': 700, 'label': True}, {'idx': 701, 'label': True}, {'idx': 702, 'label': False}, {'idx': 703, 'label': True}, {'idx': 704, 'label': True}, {'idx': 705, 'label': True}, {'idx': 706, 'label': True}, {'idx': 707, 'label': True}, {'idx': 708, 'label': False}, {'idx': 709, 'label': True}, {'idx': 710, 'label': False}, {'idx': 711, 'label': True}, {'idx': 712, 'label': True}, {'idx': 713, 'label': False}, {'idx': 714, 'label': True}, {'idx': 715, 'label': True}, {'idx': 716, 'label': False}, {'idx': 717, 'label': False}, {'idx': 718, 'label': False}, {'idx': 719, 'label': False}, {'idx': 720, 'label': False}, {'idx': 721, 'label': False}, {'idx': 722, 'label': True}, {'idx': 723, 'label': True}, {'idx': 724, 'label': True}, {'idx': 725, 'label': False}, {'idx': 726, 'label': True}, {'idx': 727, 'label': True}, {'idx': 728, 'label': True}, {'idx': 729, 'label': True}, {'idx': 730, 'label': True}, {'idx': 731, 'label': False}, {'idx': 732, 'label': True}, {'idx': 733, 'label': True}, {'idx': 734, 'label': True}, {'idx': 735, 'label': True}, {'idx': 736, 'label': False}, {'idx': 737, 'label': True}, {'idx': 738, 'label': False}, {'idx': 739, 'label': False}, {'idx': 740, 'label': True}, {'idx': 741, 'label': True}, {'idx': 742, 'label': True}, {'idx': 743, 'label': True}, {'idx': 744, 'label': True}, {'idx': 745, 'label': False}, {'idx': 746, 'label': False}, {'idx': 747, 'label': True}, {'idx': 748, 'label': False}, {'idx': 749, 'label': False}, {'idx': 750, 'label': False}, {'idx': 751, 'label': False}, {'idx': 752, 'label': False}, {'idx': 753, 'label': False}, {'idx': 754, 'label': False}, {'idx': 755, 'label': True}, {'idx': 756, 'label': False}, {'idx': 757, 'label': True}, {'idx': 758, 'label': True}, {'idx': 759, 'label': True}, {'idx': 760, 'label': True}, {'idx': 761, 'label': True}, {'idx': 762, 'label': True}, {'idx': 763, 'label': False}, {'idx': 764, 'label': True}, {'idx': 765, 'label': False}, {'idx': 766, 'label': True}, {'idx': 767, 'label': True}, {'idx': 768, 'label': False}, {'idx': 769, 'label': False}, {'idx': 770, 'label': False}, {'idx': 771, 'label': True}, {'idx': 772, 'label': True}, {'idx': 773, 'label': True}, {'idx': 774, 'label': True}, {'idx': 775, 'label': True}, {'idx': 776, 'label': True}, {'idx': 777, 'label': True}, {'idx': 778, 'label': False}, {'idx': 779, 'label': True}, {'idx': 780, 'label': False}, {'idx': 781, 'label': True}, {'idx': 782, 'label': True}, {'idx': 783, 'label': False}, {'idx': 784, 'label': False}, {'idx': 785, 'label': True}, {'idx': 786, 'label': False}, {'idx': 787, 'label': True}, {'idx': 788, 'label': True}, {'idx': 789, 'label': False}, {'idx': 790, 'label': True}, {'idx': 791, 'label': True}, {'idx': 792, 'label': True}, {'idx': 793, 'label': False}, {'idx': 794, 'label': True}, {'idx': 795, 'label': False}, {'idx': 796, 'label': False}, {'idx': 797, 'label': False}, {'idx': 798, 'label': True}, {'idx': 799, 'label': True}, {'idx': 800, 'label': True}, {'idx': 801, 'label': False}, {'idx': 802, 'label': True}, {'idx': 803, 'label': True}, {'idx': 804, 'label': False}, {'idx': 805, 'label': True}, {'idx': 806, 'label': True}, {'idx': 807, 'label': True}, {'idx': 808, 'label': False}, {'idx': 809, 'label': False}, {'idx': 810, 'label': True}, {'idx': 811, 'label': False}, {'idx': 812, 'label': True}, {'idx': 813, 'label': True}, {'idx': 814, 'label': True}, {'idx': 815, 'label': False}, {'idx': 816, 'label': False}, {'idx': 817, 'label': False}, {'idx': 818, 'label': False}, {'idx': 819, 'label': False}, {'idx': 820, 'label': True}, {'idx': 821, 'label': False}, {'idx': 822, 'label': False}, {'idx': 823, 'label': False}, {'idx': 824, 'label': True}, {'idx': 825, 'label': False}, {'idx': 826, 'label': False}, {'idx': 827, 'label': True}, {'idx': 828, 'label': False}, {'idx': 829, 'label': True}, {'idx': 830, 'label': True}, {'idx': 831, 'label': False}, {'idx': 832, 'label': False}, {'idx': 833, 'label': False}, {'idx': 834, 'label': True}, {'idx': 835, 'label': True}, {'idx': 836, 'label': True}, {'idx': 837, 'label': True}, {'idx': 838, 'label': True}, {'idx': 839, 'label': False}, {'idx': 840, 'label': True}, {'idx': 841, 'label': False}, {'idx': 842, 'label': True}, {'idx': 843, 'label': True}, {'idx': 844, 'label': False}, {'idx': 845, 'label': True}, {'idx': 846, 'label': True}, {'idx': 847, 'label': True}, {'idx': 848, 'label': True}, {'idx': 849, 'label': False}, {'idx': 850, 'label': True}, {'idx': 851, 'label': False}, {'idx': 852, 'label': True}, {'idx': 853, 'label': True}, {'idx': 854, 'label': True}, {'idx': 855, 'label': False}, {'idx': 856, 'label': False}, {'idx': 857, 'label': False}, {'idx': 858, 'label': True}, {'idx': 859, 'label': False}, {'idx': 860, 'label': False}, {'idx': 861, 'label': True}, {'idx': 862, 'label': False}, {'idx': 863, 'label': True}, {'idx': 864, 'label': True}, {'idx': 865, 'label': False}, {'idx': 866, 'label': True}, {'idx': 867, 'label': True}, {'idx': 868, 'label': True}, {'idx': 869, 'label': True}, {'idx': 870, 'label': False}, {'idx': 871, 'label': False}, {'idx': 872, 'label': False}, {'idx': 873, 'label': False}, {'idx': 874, 'label': True}, {'idx': 875, 'label': False}, {'idx': 876, 'label': True}, {'idx': 877, 'label': False}, {'idx': 878, 'label': False}, {'idx': 879, 'label': True}, {'idx': 880, 'label': False}, {'idx': 881, 'label': True}, {'idx': 882, 'label': False}, {'idx': 883, 'label': False}, {'idx': 884, 'label': False}, {'idx': 885, 'label': True}, {'idx': 886, 'label': True}, {'idx': 887, 'label': False}, {'idx': 888, 'label': False}, {'idx': 889, 'label': False}, {'idx': 890, 'label': True}, {'idx': 891, 'label': False}, {'idx': 892, 'label': False}, {'idx': 893, 'label': False}, {'idx': 894, 'label': True}, {'idx': 895, 'label': True}, {'idx': 896, 'label': True}, {'idx': 897, 'label': False}, {'idx': 898, 'label': False}, {'idx': 899, 'label': False}, {'idx': 900, 'label': False}, {'idx': 901, 'label': True}, {'idx': 902, 'label': True}, {'idx': 903, 'label': True}, {'idx': 904, 'label': True}, {'idx': 905, 'label': False}, {'idx': 906, 'label': True}, {'idx': 907, 'label': True}, {'idx': 908, 'label': False}, {'idx': 909, 'label': True}, {'idx': 910, 'label': False}, {'idx': 911, 'label': False}, {'idx': 912, 'label': True}, {'idx': 913, 'label': False}, {'idx': 914, 'label': False}, {'idx': 915, 'label': True}, {'idx': 916, 'label': False}, {'idx': 917, 'label': False}, {'idx': 918, 'label': True}, {'idx': 919, 'label': True}, {'idx': 920, 'label': True}, {'idx': 921, 'label': True}, {'idx': 922, 'label': True}, {'idx': 923, 'label': True}, {'idx': 924, 'label': True}, {'idx': 925, 'label': True}, {'idx': 926, 'label': True}, {'idx': 927, 'label': False}, {'idx': 928, 'label': False}, {'idx': 929, 'label': False}, {'idx': 930, 'label': True}, {'idx': 931, 'label': False}, {'idx': 932, 'label': True}, {'idx': 933, 'label': False}, {'idx': 934, 'label': False}, {'idx': 935, 'label': True}, {'idx': 936, 'label': True}, {'idx': 937, 'label': True}, {'idx': 938, 'label': False}, {'idx': 939, 'label': True}, {'idx': 940, 'label': False}, {'idx': 941, 'label': False}, {'idx': 942, 'label': True}, {'idx': 943, 'label': True}, {'idx': 944, 'label': True}, {'idx': 945, 'label': True}, {'idx': 946, 'label': True}, {'idx': 947, 'label': False}, {'idx': 948, 'label': True}, {'idx': 949, 'label': False}, {'idx': 950, 'label': True}, {'idx': 951, 'label': False}, {'idx': 952, 'label': False}, {'idx': 953, 'label': False}, {'idx': 954, 'label': True}, {'idx': 955, 'label': False}, {'idx': 956, 'label': False}, {'idx': 957, 'label': True}, {'idx': 958, 'label': False}, {'idx': 959, 'label': False}, {'idx': 960, 'label': True}, {'idx': 961, 'label': True}, {'idx': 962, 'label': True}, {'idx': 963, 'label': True}, {'idx': 964, 'label': True}, {'idx': 965, 'label': False}, {'idx': 966, 'label': True}, {'idx': 967, 'label': True}, {'idx': 968, 'label': False}, {'idx': 969, 'label': True}, {'idx': 970, 'label': False}, {'idx': 971, 'label': False}, {'idx': 972, 'label': True}, {'idx': 973, 'label': False}, {'idx': 974, 'label': True}, {'idx': 975, 'label': False}, {'idx': 976, 'label': True}, {'idx': 977, 'label': False}, {'idx': 978, 'label': False}, {'idx': 979, 'label': False}, {'idx': 980, 'label': True}, {'idx': 981, 'label': False}, {'idx': 982, 'label': True}, {'idx': 983, 'label': False}, {'idx': 984, 'label': False}, {'idx': 985, 'label': True}, {'idx': 986, 'label': False}, {'idx': 987, 'label': False}, {'idx': 988, 'label': True}, {'idx': 989, 'label': True}, {'idx': 990, 'label': False}, {'idx': 991, 'label': True}, {'idx': 992, 'label': False}, {'idx': 993, 'label': False}, {'idx': 994, 'label': True}, {'idx': 995, 'label': True}, {'idx': 996, 'label': False}, {'idx': 997, 'label': True}, {'idx': 998, 'label': False}, {'idx': 999, 'label': True}, {'idx': 1000, 'label': True}, {'idx': 1001, 'label': True}, {'idx': 1002, 'label': True}, {'idx': 1003, 'label': True}, {'idx': 1004, 'label': False}, {'idx': 1005, 'label': True}, {'idx': 1006, 'label': True}, {'idx': 1007, 'label': True}, {'idx': 1008, 'label': False}, {'idx': 1009, 'label': False}, {'idx': 1010, 'label': False}, {'idx': 1011, 'label': True}, {'idx': 1012, 'label': False}, {'idx': 1013, 'label': False}, {'idx': 1014, 'label': True}, {'idx': 1015, 'label': True}, {'idx': 1016, 'label': False}, {'idx': 1017, 'label': False}, {'idx': 1018, 'label': True}, {'idx': 1019, 'label': False}, {'idx': 1020, 'label': True}, {'idx': 1021, 'label': True}, {'idx': 1022, 'label': False}, {'idx': 1023, 'label': False}, {'idx': 1024, 'label': False}, {'idx': 1025, 'label': True}, {'idx': 1026, 'label': True}, {'idx': 1027, 'label': False}, {'idx': 1028, 'label': False}, {'idx': 1029, 'label': True}, {'idx': 1030, 'label': True}, {'idx': 1031, 'label': True}, {'idx': 1032, 'label': True}, {'idx': 1033, 'label': False}, {'idx': 1034, 'label': True}, {'idx': 1035, 'label': True}, {'idx': 1036, 'label': True}, {'idx': 1037, 'label': True}, {'idx': 1038, 'label': False}, {'idx': 1039, 'label': False}, {'idx': 1040, 'label': False}, {'idx': 1041, 'label': False}, {'idx': 1042, 'label': False}, {'idx': 1043, 'label': True}, {'idx': 1044, 'label': False}, {'idx': 1045, 'label': True}, {'idx': 1046, 'label': True}, {'idx': 1047, 'label': False}, {'idx': 1048, 'label': False}, {'idx': 1049, 'label': True}, {'idx': 1050, 'label': True}, {'idx': 1051, 'label': False}, {'idx': 1052, 'label': True}, {'idx': 1053, 'label': True}, {'idx': 1054, 'label': True}, {'idx': 1055, 'label': False}, {'idx': 1056, 'label': False}, {'idx': 1057, 'label': True}, {'idx': 1058, 'label': True}, {'idx': 1059, 'label': True}, {'idx': 1060, 'label': False}, {'idx': 1061, 'label': False}, {'idx': 1062, 'label': True}, {'idx': 1063, 'label': False}, {'idx': 1064, 'label': False}, {'idx': 1065, 'label': True}, {'idx': 1066, 'label': True}, {'idx': 1067, 'label': True}, {'idx': 1068, 'label': False}, {'idx': 1069, 'label': False}, {'idx': 1070, 'label': False}, {'idx': 1071, 'label': True}, {'idx': 1072, 'label': False}, {'idx': 1073, 'label': True}, {'idx': 1074, 'label': False}, {'idx': 1075, 'label': True}, {'idx': 1076, 'label': True}, {'idx': 1077, 'label': True}, {'idx': 1078, 'label': True}, {'idx': 1079, 'label': True}, {'idx': 1080, 'label': False}, {'idx': 1081, 'label': False}, {'idx': 1082, 'label': True}, {'idx': 1083, 'label': True}, {'idx': 1084, 'label': False}, {'idx': 1085, 'label': False}, {'idx': 1086, 'label': True}, {'idx': 1087, 'label': False}, {'idx': 1088, 'label': True}, {'idx': 1089, 'label': True}, {'idx': 1090, 'label': False}, {'idx': 1091, 'label': False}, {'idx': 1092, 'label': True}, {'idx': 1093, 'label': False}, {'idx': 1094, 'label': False}, {'idx': 1095, 'label': False}, {'idx': 1096, 'label': True}, {'idx': 1097, 'label': False}, {'idx': 1098, 'label': False}, {'idx': 1099, 'label': False}, {'idx': 1100, 'label': False}, {'idx': 1101, 'label': True}, {'idx': 1102, 'label': False}, {'idx': 1103, 'label': False}, {'idx': 1104, 'label': False}, {'idx': 1105, 'label': False}, {'idx': 1106, 'label': True}, {'idx': 1107, 'label': False}, {'idx': 1108, 'label': False}, {'idx': 1109, 'label': True}, {'idx': 1110, 'label': False}, {'idx': 1111, 'label': False}, {'idx': 1112, 'label': False}, {'idx': 1113, 'label': False}, {'idx': 1114, 'label': True}, {'idx': 1115, 'label': False}, {'idx': 1116, 'label': True}, {'idx': 1117, 'label': False}, {'idx': 1118, 'label': True}, {'idx': 1119, 'label': True}, {'idx': 1120, 'label': True}, {'idx': 1121, 'label': False}, {'idx': 1122, 'label': True}, {'idx': 1123, 'label': False}, {'idx': 1124, 'label': True}, {'idx': 1125, 'label': False}, {'idx': 1126, 'label': True}, {'idx': 1127, 'label': False}, {'idx': 1128, 'label': False}, {'idx': 1129, 'label': True}, {'idx': 1130, 'label': True}, {'idx': 1131, 'label': True}, {'idx': 1132, 'label': False}, {'idx': 1133, 'label': False}, {'idx': 1134, 'label': True}, {'idx': 1135, 'label': True}, {'idx': 1136, 'label': False}, {'idx': 1137, 'label': True}, {'idx': 1138, 'label': False}, {'idx': 1139, 'label': True}, {'idx': 1140, 'label': True}, {'idx': 1141, 'label': True}, {'idx': 1142, 'label': False}, {'idx': 1143, 'label': False}, {'idx': 1144, 'label': False}, {'idx': 1145, 'label': False}, {'idx': 1146, 'label': False}, {'idx': 1147, 'label': True}, {'idx': 1148, 'label': True}, {'idx': 1149, 'label': True}, {'idx': 1150, 'label': True}, {'idx': 1151, 'label': False}, {'idx': 1152, 'label': False}, {'idx': 1153, 'label': True}, {'idx': 1154, 'label': True}, {'idx': 1155, 'label': False}, {'idx': 1156, 'label': False}, {'idx': 1157, 'label': False}, {'idx': 1158, 'label': False}, {'idx': 1159, 'label': False}, {'idx': 1160, 'label': False}, {'idx': 1161, 'label': False}, {'idx': 1162, 'label': False}, {'idx': 1163, 'label': False}, {'idx': 1164, 'label': True}, {'idx': 1165, 'label': True}, {'idx': 1166, 'label': False}, {'idx': 1167, 'label': True}, {'idx': 1168, 'label': False}, {'idx': 1169, 'label': False}, {'idx': 1170, 'label': False}, {'idx': 1171, 'label': False}, {'idx': 1172, 'label': True}, {'idx': 1173, 'label': True}, {'idx': 1174, 'label': True}, {'idx': 1175, 'label': False}, {'idx': 1176, 'label': True}, {'idx': 1177, 'label': True}, {'idx': 1178, 'label': True}, {'idx': 1179, 'label': True}, {'idx': 1180, 'label': False}, {'idx': 1181, 'label': False}, {'idx': 1182, 'label': False}, {'idx': 1183, 'label': True}, {'idx': 1184, 'label': True}, {'idx': 1185, 'label': False}, {'idx': 1186, 'label': False}, {'idx': 1187, 'label': True}, {'idx': 1188, 'label': False}, {'idx': 1189, 'label': True}, {'idx': 1190, 'label': True}, {'idx': 1191, 'label': False}, {'idx': 1192, 'label': False}, {'idx': 1193, 'label': True}, {'idx': 1194, 'label': True}, {'idx': 1195, 'label': False}, {'idx': 1196, 'label': True}, {'idx': 1197, 'label': True}, {'idx': 1198, 'label': True}, {'idx': 1199, 'label': False}, {'idx': 1200, 'label': False}, {'idx': 1201, 'label': True}, {'idx': 1202, 'label': True}, {'idx': 1203, 'label': True}, {'idx': 1204, 'label': True}, {'idx': 1205, 'label': True}, {'idx': 1206, 'label': True}, {'idx': 1207, 'label': True}, {'idx': 1208, 'label': True}, {'idx': 1209, 'label': False}, {'idx': 1210, 'label': True}, {'idx': 1211, 'label': True}, {'idx': 1212, 'label': True}, {'idx': 1213, 'label': True}, {'idx': 1214, 'label': True}, {'idx': 1215, 'label': False}, {'idx': 1216, 'label': True}, {'idx': 1217, 'label': True}, {'idx': 1218, 'label': True}, {'idx': 1219, 'label': True}, {'idx': 1220, 'label': False}, {'idx': 1221, 'label': True}, {'idx': 1222, 'label': False}, {'idx': 1223, 'label': False}, {'idx': 1224, 'label': True}, {'idx': 1225, 'label': True}, {'idx': 1226, 'label': True}, {'idx': 1227, 'label': True}, {'idx': 1228, 'label': True}, {'idx': 1229, 'label': False}, {'idx': 1230, 'label': False}, {'idx': 1231, 'label': True}, {'idx': 1232, 'label': True}, {'idx': 1233, 'label': False}, {'idx': 1234, 'label': True}, {'idx': 1235, 'label': False}, {'idx': 1236, 'label': True}, {'idx': 1237, 'label': False}, {'idx': 1238, 'label': True}, {'idx': 1239, 'label': True}, {'idx': 1240, 'label': False}, {'idx': 1241, 'label': False}, {'idx': 1242, 'label': True}, {'idx': 1243, 'label': False}, {'idx': 1244, 'label': False}, {'idx': 1245, 'label': True}, {'idx': 1246, 'label': True}]\n",
            "##### write_json to :  /content/jiant-rev/exp/runs/simple/test_preds.p.wic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhO42Jz8p0MC"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/jiant-rev')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVHW_oMzo6-l"
      },
      "source": [
        "!rm -rf ./exp/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxCdwa0Wo9AS"
      },
      "source": [
        "!rm -rf /root/.cache/huggingface/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSyoXJXNp9Mb",
        "outputId": "a593b3b6-e00f-46b1-eec2-10d890ace2b8"
      },
      "source": [
        "# write predictions to file (boolq)\n",
        "from jiant.proj.simple import runscript as run\n",
        "import jiant.scripts.download_data.runscript as downloader\n",
        "\n",
        "#EXP_DIR = \"/content/jiant-rev/exp\"\n",
        "EXP_DIR = \"./exp\"\n",
        "\n",
        "# Download the Data\n",
        "downloader.download_data([\"boolq\"], f\"{EXP_DIR}/tasks\")\n",
        "\n",
        "# Set up the arguments for the Simple API\n",
        "args = run.RunConfiguration(\n",
        "   run_name=\"simple\",\n",
        "   exp_dir=EXP_DIR,\n",
        "   data_dir=f\"{EXP_DIR}/tasks\",\n",
        "   hf_pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
        "   tasks=\"boolq\",\n",
        "   train_batch_size=16,\n",
        "   num_train_epochs=3,\n",
        "   write_test_preds=True\n",
        ")\n",
        "\n",
        "# Run!\n",
        "run.run_simple(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### hf_datasets_tasks_download, task_name:  boolq , task_data_path:  /content/jiant-rev/exp/tasks/data/boolq\n",
            "##### load_dataset(), path= super_glue , name= boolq\n",
            "##### is_ko_model :  True\n",
            "Using custom data configuration default-586ba5d19d21afc7\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-586ba5d19d21afc7/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n",
            "100% 3/3 [00:00<00:00, 13329.36it/s]\n",
            "100% 3/3 [00:00<00:00, 1524.83it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-586ba5d19d21afc7/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 1040.60it/s]\n",
            "Downloaded and generated configs for 'boolq' (1/1)\n",
            "##### run_simple(): Tokenizing Task 'boolq' for phases 'train,val,test'\n",
            "BoolQTask\n",
            "  [train]: /content/jiant-rev/exp/tasks/data/boolq/train.jsonl\n",
            "  [val]: /content/jiant-rev/exp/tasks/data/boolq/val.jsonl\n",
            "  [test]: /content/jiant-rev/exp/tasks/data/boolq/test.jsonl\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "Tokenizing: 100% 3665/3665 [00:02<00:00, 1658.73it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 3665/3665 [00:00<00:00, 128686.56it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
            "Tokenizing: 100% 700/700 [00:00<00:00, 969.78it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 700/700 [00:00<00:00, 86679.64it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  5.28it/s]\n",
            "Tokenizing: 100% 704/704 [00:00<00:00, 1665.04it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 704/704 [00:00<00:00, 139743.97it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  6.34it/s]\n",
            "Running from start\n",
            "  jiant_task_container_config_path: /content/jiant-rev/exp/run_configs/simple_config.json\n",
            "  output_dir: /content/jiant-rev/exp/runs/simple\n",
            "  hf_pretrained_model_name_or_path: monologg/koelectra-base-v3-discriminator\n",
            "  model_path: /content/jiant-rev/exp/models/electra/model/model.p\n",
            "  model_config_path: /content/jiant-rev/exp/models/electra/model/config.json\n",
            "  model_load_mode: from_transformers\n",
            "  do_train: True\n",
            "  do_val: True\n",
            "  do_save: False\n",
            "  do_save_last: False\n",
            "  do_save_best: False\n",
            "  write_val_preds: False\n",
            "  write_test_preds: True\n",
            "  eval_every_steps: 0\n",
            "  save_every_steps: 0\n",
            "  save_checkpoint_every_steps: 0\n",
            "  no_improvements_for_n_evals: 0\n",
            "  keep_checkpoint_when_done: False\n",
            "  force_overwrite: False\n",
            "  seed: -1\n",
            "  learning_rate: 1e-05\n",
            "  adam_epsilon: 1e-08\n",
            "  max_grad_norm: 1.0\n",
            "  optimizer_type: adam\n",
            "  no_cuda: False\n",
            "  fp16: False\n",
            "  fp16_opt_level: O1\n",
            "  local_rank: -1\n",
            "  server_ip: \n",
            "  server_port: \n",
            "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Using seed: 588727188\n",
            "{\n",
            "  \"jiant_task_container_config_path\": \"/content/jiant-rev/exp/run_configs/simple_config.json\",\n",
            "  \"output_dir\": \"/content/jiant-rev/exp/runs/simple\",\n",
            "  \"hf_pretrained_model_name_or_path\": \"monologg/koelectra-base-v3-discriminator\",\n",
            "  \"model_path\": \"/content/jiant-rev/exp/models/electra/model/model.p\",\n",
            "  \"model_config_path\": \"/content/jiant-rev/exp/models/electra/model/config.json\",\n",
            "  \"model_load_mode\": \"from_transformers\",\n",
            "  \"do_train\": true,\n",
            "  \"do_val\": true,\n",
            "  \"do_save\": false,\n",
            "  \"do_save_last\": false,\n",
            "  \"do_save_best\": false,\n",
            "  \"write_val_preds\": false,\n",
            "  \"write_test_preds\": true,\n",
            "  \"eval_every_steps\": 0,\n",
            "  \"save_every_steps\": 0,\n",
            "  \"save_checkpoint_every_steps\": 0,\n",
            "  \"no_improvements_for_n_evals\": 0,\n",
            "  \"keep_checkpoint_when_done\": false,\n",
            "  \"force_overwrite\": false,\n",
            "  \"seed\": 588727188,\n",
            "  \"learning_rate\": 1e-05,\n",
            "  \"adam_epsilon\": 1e-08,\n",
            "  \"max_grad_norm\": 1.0,\n",
            "  \"optimizer_type\": \"adam\",\n",
            "  \"no_cuda\": false,\n",
            "  \"fp16\": false,\n",
            "  \"fp16_opt_level\": \"O1\",\n",
            "  \"local_rank\": -1,\n",
            "  \"server_ip\": \"\",\n",
            "  \"server_port\": \"\"\n",
            "}\n",
            "1\n",
            "Creating Tasks:\n",
            "    boolq (BoolQTask): /content/jiant-rev/exp/tasks/configs/boolq_config.json\n",
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "##### encoder_prefix: electra.\n",
            "##### k :  electra.embeddings.position_ids\n",
            "##### k :  electra.embeddings.word_embeddings.weight\n",
            "##### k :  electra.embeddings.position_embeddings.weight\n",
            "##### k :  electra.embeddings.token_type_embeddings.weight\n",
            "##### k :  electra.embeddings.LayerNorm.weight\n",
            "##### k :  electra.embeddings.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.bias\n",
            "##### k :  discriminator_predictions.dense.weight\n",
            "##### k :  discriminator_predictions.dense.bias\n",
            "##### k :  discriminator_predictions.dense_prediction.weight\n",
            "##### k :  discriminator_predictions.dense_prediction.bias\n",
            "No optimizer decay for:\n",
            "  encoder.embeddings.LayerNorm.weight\n",
            "  encoder.embeddings.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.attention.self.query.bias\n",
            "  encoder.encoder.layer.0.attention.self.key.bias\n",
            "  encoder.encoder.layer.0.attention.self.value.bias\n",
            "  encoder.encoder.layer.0.attention.output.dense.bias\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.intermediate.dense.bias\n",
            "  encoder.encoder.layer.0.output.dense.bias\n",
            "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.attention.self.query.bias\n",
            "  encoder.encoder.layer.1.attention.self.key.bias\n",
            "  encoder.encoder.layer.1.attention.self.value.bias\n",
            "  encoder.encoder.layer.1.attention.output.dense.bias\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.intermediate.dense.bias\n",
            "  encoder.encoder.layer.1.output.dense.bias\n",
            "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.attention.self.query.bias\n",
            "  encoder.encoder.layer.2.attention.self.key.bias\n",
            "  encoder.encoder.layer.2.attention.self.value.bias\n",
            "  encoder.encoder.layer.2.attention.output.dense.bias\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.intermediate.dense.bias\n",
            "  encoder.encoder.layer.2.output.dense.bias\n",
            "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.attention.self.query.bias\n",
            "  encoder.encoder.layer.3.attention.self.key.bias\n",
            "  encoder.encoder.layer.3.attention.self.value.bias\n",
            "  encoder.encoder.layer.3.attention.output.dense.bias\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.intermediate.dense.bias\n",
            "  encoder.encoder.layer.3.output.dense.bias\n",
            "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.attention.self.query.bias\n",
            "  encoder.encoder.layer.4.attention.self.key.bias\n",
            "  encoder.encoder.layer.4.attention.self.value.bias\n",
            "  encoder.encoder.layer.4.attention.output.dense.bias\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.intermediate.dense.bias\n",
            "  encoder.encoder.layer.4.output.dense.bias\n",
            "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.attention.self.query.bias\n",
            "  encoder.encoder.layer.5.attention.self.key.bias\n",
            "  encoder.encoder.layer.5.attention.self.value.bias\n",
            "  encoder.encoder.layer.5.attention.output.dense.bias\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.intermediate.dense.bias\n",
            "  encoder.encoder.layer.5.output.dense.bias\n",
            "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.attention.self.query.bias\n",
            "  encoder.encoder.layer.6.attention.self.key.bias\n",
            "  encoder.encoder.layer.6.attention.self.value.bias\n",
            "  encoder.encoder.layer.6.attention.output.dense.bias\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.intermediate.dense.bias\n",
            "  encoder.encoder.layer.6.output.dense.bias\n",
            "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.attention.self.query.bias\n",
            "  encoder.encoder.layer.7.attention.self.key.bias\n",
            "  encoder.encoder.layer.7.attention.self.value.bias\n",
            "  encoder.encoder.layer.7.attention.output.dense.bias\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.intermediate.dense.bias\n",
            "  encoder.encoder.layer.7.output.dense.bias\n",
            "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.attention.self.query.bias\n",
            "  encoder.encoder.layer.8.attention.self.key.bias\n",
            "  encoder.encoder.layer.8.attention.self.value.bias\n",
            "  encoder.encoder.layer.8.attention.output.dense.bias\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.intermediate.dense.bias\n",
            "  encoder.encoder.layer.8.output.dense.bias\n",
            "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.attention.self.query.bias\n",
            "  encoder.encoder.layer.9.attention.self.key.bias\n",
            "  encoder.encoder.layer.9.attention.self.value.bias\n",
            "  encoder.encoder.layer.9.attention.output.dense.bias\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.intermediate.dense.bias\n",
            "  encoder.encoder.layer.9.output.dense.bias\n",
            "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.attention.self.query.bias\n",
            "  encoder.encoder.layer.10.attention.self.key.bias\n",
            "  encoder.encoder.layer.10.attention.self.value.bias\n",
            "  encoder.encoder.layer.10.attention.output.dense.bias\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.intermediate.dense.bias\n",
            "  encoder.encoder.layer.10.output.dense.bias\n",
            "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.attention.self.query.bias\n",
            "  encoder.encoder.layer.11.attention.self.key.bias\n",
            "  encoder.encoder.layer.11.attention.self.value.bias\n",
            "  encoder.encoder.layer.11.attention.output.dense.bias\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.intermediate.dense.bias\n",
            "  encoder.encoder.layer.11.output.dense.bias\n",
            "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
            "  taskmodels_dict.boolq.head.dense.bias\n",
            "  taskmodels_dict.boolq.head.out_proj.bias\n",
            "Using AdamW\n",
            "##### do_train #####\n",
            "##### run_train_context() #####\n",
            "##### get_train_dataloader_dict() :  1\n",
            "Training: 100% 689/690 [04:39<00:00,  2.46it/s]\n",
            "Eval (boolq, Val): 100% 16/16 [00:04<00:00,  3.97it/s]\n",
            "##### get_accumulated(), logits :  [[ 2.03408718e-01 -3.24311495e-01]\n",
            " [-7.76127756e-01  7.37709641e-01]\n",
            " [ 1.14059913e+00 -1.40508556e+00]\n",
            " [ 6.23067856e-01 -7.60961115e-01]\n",
            " [-1.21315825e+00  1.30660880e+00]\n",
            " [-9.58542705e-01  9.92949545e-01]\n",
            " [ 9.18907762e-01 -1.23884499e+00]\n",
            " [ 9.77537572e-01 -1.24133420e+00]\n",
            " [ 7.32273221e-01 -1.00446677e+00]\n",
            " [ 7.75670290e-01 -1.01815152e+00]\n",
            " [-5.60040891e-01  6.40259683e-01]\n",
            " [-1.29942203e+00  1.48279607e+00]\n",
            " [ 1.10529053e+00 -1.34755456e+00]\n",
            " [-1.29871333e+00  1.40045369e+00]\n",
            " [ 6.50232732e-01 -8.62470150e-01]\n",
            " [-8.69810641e-01  7.61020958e-01]\n",
            " [ 1.09264767e+00 -1.39885604e+00]\n",
            " [-1.13181865e+00  1.19874895e+00]\n",
            " [-4.05005425e-01  2.34159350e-01]\n",
            " [ 1.13804185e+00 -1.40507853e+00]\n",
            " [ 7.30890632e-01 -9.18195307e-01]\n",
            " [-3.65828335e-01  4.54162359e-01]\n",
            " [-1.30571294e+00  1.42349005e+00]\n",
            " [-1.12415338e+00  1.33048260e+00]\n",
            " [-1.16908216e+00  1.22052920e+00]\n",
            " [ 1.09443438e+00 -1.35829401e+00]\n",
            " [ 9.12882626e-01 -1.17560613e+00]\n",
            " [ 1.10521519e+00 -1.34307015e+00]\n",
            " [-7.06612349e-01  5.44907033e-01]\n",
            " [-7.93397427e-01  7.15368688e-01]\n",
            " [ 1.09070611e+00 -1.32769835e+00]\n",
            " [ 6.95458293e-01 -1.01200628e+00]\n",
            " [-1.32840586e+00  1.55340135e+00]\n",
            " [-1.15076721e+00  1.23530233e+00]\n",
            " [ 1.66134834e-02 -2.28444874e-01]\n",
            " [ 1.12069356e+00 -1.39891851e+00]\n",
            " [ 1.06504595e+00 -1.33046091e+00]\n",
            " [ 8.79666328e-01 -1.12162411e+00]\n",
            " [ 1.15948272e+00 -1.42668569e+00]\n",
            " [-4.15460378e-01  2.66266614e-01]\n",
            " [-1.04093325e+00  1.18222797e+00]\n",
            " [ 1.11659205e+00 -1.37921858e+00]\n",
            " [ 1.01128745e+00 -1.31391752e+00]\n",
            " [ 1.18543565e+00 -1.47785270e+00]\n",
            " [-9.64527607e-01  9.47045147e-01]\n",
            " [ 1.04140699e+00 -1.32656133e+00]\n",
            " [-8.21671188e-01  7.90841043e-01]\n",
            " [ 6.03242874e-01 -8.01709712e-01]\n",
            " [ 2.55136102e-01 -3.83187830e-01]\n",
            " [-1.03649163e+00  1.22191632e+00]\n",
            " [-1.02022898e+00  9.94234860e-01]\n",
            " [-1.21816134e+00  1.32338738e+00]\n",
            " [-5.62528849e-01  3.52707624e-01]\n",
            " [-1.19171417e+00  1.39499271e+00]\n",
            " [-1.14032137e+00  1.16021907e+00]\n",
            " [-8.76923501e-01  9.07122076e-01]\n",
            " [-1.23558342e+00  1.43729103e+00]\n",
            " [ 1.14873278e+00 -1.44910407e+00]\n",
            " [ 1.13326037e+00 -1.40417671e+00]\n",
            " [ 1.05331397e+00 -1.32718861e+00]\n",
            " [ 1.15765786e+00 -1.43592680e+00]\n",
            " [-1.79551750e-01  1.14746299e-02]\n",
            " [ 8.77303854e-02 -3.95560920e-01]\n",
            " [ 3.97664130e-01 -5.62590778e-01]\n",
            " [ 5.39188564e-01 -8.92660439e-01]\n",
            " [ 7.50279903e-01 -9.67354000e-01]\n",
            " [ 1.08476663e+00 -1.34960401e+00]\n",
            " [-1.03969586e+00  1.15668130e+00]\n",
            " [-1.25906074e+00  1.29906881e+00]\n",
            " [ 1.17163813e+00 -1.37881267e+00]\n",
            " [-9.72739100e-01  1.03009069e+00]\n",
            " [ 8.84924114e-01 -1.05926800e+00]\n",
            " [ 3.83316785e-01 -6.54441059e-01]\n",
            " [-9.65408921e-01  1.05859649e+00]\n",
            " [ 1.69085115e-01 -3.36405605e-01]\n",
            " [ 1.08713639e+00 -1.28522193e+00]\n",
            " [ 1.13203418e+00 -1.43476427e+00]\n",
            " [-1.05255830e+00  1.07140791e+00]\n",
            " [-9.51314628e-01  9.00759399e-01]\n",
            " [ 1.11393929e+00 -1.40890479e+00]\n",
            " [-1.18260849e+00  1.28031051e+00]\n",
            " [ 1.05783105e+00 -1.30479550e+00]\n",
            " [-1.12915146e+00  1.18731856e+00]\n",
            " [-7.88290560e-01  7.01267719e-01]\n",
            " [ 1.10043371e+00 -1.38645613e+00]\n",
            " [ 9.82699454e-01 -1.16548002e+00]\n",
            " [-7.09632516e-01  7.39810169e-01]\n",
            " [-1.10868180e+00  1.13726890e+00]\n",
            " [ 1.10382712e+00 -1.30338347e+00]\n",
            " [ 1.02005541e+00 -1.25199497e+00]\n",
            " [-1.29679167e+00  1.50171995e+00]\n",
            " [ 1.05704558e+00 -1.33028769e+00]\n",
            " [-1.27912772e+00  1.35188591e+00]\n",
            " [ 9.16856170e-01 -1.21436679e+00]\n",
            " [-1.02021766e+00  1.14701521e+00]\n",
            " [ 7.50576317e-01 -1.00038147e+00]\n",
            " [ 1.14437139e+00 -1.39360976e+00]\n",
            " [ 1.04622328e+00 -1.28036582e+00]\n",
            " [-4.67650861e-01  3.43399972e-01]\n",
            " [ 9.65692461e-01 -1.24392307e+00]\n",
            " [-6.70049012e-01  7.16176808e-01]\n",
            " [ 1.17381442e+00 -1.46830869e+00]\n",
            " [-1.17132032e+00  1.31901097e+00]\n",
            " [ 1.02606857e+00 -1.31149590e+00]\n",
            " [-1.10890853e+00  1.18091476e+00]\n",
            " [-9.92637634e-01  9.73284185e-01]\n",
            " [-9.71481264e-01  1.00181472e+00]\n",
            " [-2.65308946e-01  9.14474390e-03]\n",
            " [ 1.07989681e+00 -1.35624301e+00]\n",
            " [ 1.08180535e+00 -1.34661686e+00]\n",
            " [-1.16735375e+00  1.23397386e+00]\n",
            " [ 1.16030657e+00 -1.42699170e+00]\n",
            " [-1.27442825e+00  1.37166667e+00]\n",
            " [ 1.65426314e-01 -2.86040515e-01]\n",
            " [-9.31378126e-01  9.56928372e-01]\n",
            " [ 7.93288827e-01 -1.06636512e+00]\n",
            " [ 8.57371271e-01 -1.27392995e+00]\n",
            " [ 7.32941985e-01 -1.03942454e+00]\n",
            " [-1.29162157e+00  1.47556078e+00]\n",
            " [-1.19710767e+00  1.33202779e+00]\n",
            " [-1.28230894e+00  1.46190369e+00]\n",
            " [ 1.14693224e+00 -1.39063144e+00]\n",
            " [ 4.06986684e-01 -6.22931123e-01]\n",
            " [ 9.78159308e-01 -1.19741189e+00]\n",
            " [-4.43720609e-01  4.70659316e-01]\n",
            " [-1.11806571e+00  1.16806519e+00]\n",
            " [ 1.09514487e+00 -1.37723660e+00]\n",
            " [ 4.40321952e-01 -8.39402556e-01]\n",
            " [-1.17865074e+00  1.29314673e+00]\n",
            " [ 8.95676851e-01 -1.11841309e+00]\n",
            " [ 1.10418117e+00 -1.35422111e+00]\n",
            " [ 9.99172032e-01 -1.28557217e+00]\n",
            " [ 1.03556478e+00 -1.25649989e+00]\n",
            " [-5.00455141e-01  4.60455596e-01]\n",
            " [-1.33608449e+00  1.41857851e+00]\n",
            " [ 4.23569918e-01 -6.67873800e-01]\n",
            " [ 1.15247881e+00 -1.42432380e+00]\n",
            " [ 4.09880936e-01 -6.09030783e-01]\n",
            " [-8.12288642e-01  9.56813037e-01]\n",
            " [ 9.58894968e-01 -1.21897674e+00]\n",
            " [ 2.66889304e-01 -4.23970759e-01]\n",
            " [ 3.27536374e-01 -5.06964982e-01]\n",
            " [ 1.07867324e+00 -1.37776887e+00]\n",
            " [-3.68262708e-01  1.01949736e-01]\n",
            " [ 1.10230815e+00 -1.35317814e+00]\n",
            " [ 1.09291220e+00 -1.41196632e+00]\n",
            " [-8.04803491e-01  7.89504826e-01]\n",
            " [ 9.07178521e-01 -1.25761580e+00]\n",
            " [-1.21434164e+00  1.34604800e+00]\n",
            " [ 1.08914602e+00 -1.31990469e+00]\n",
            " [ 6.68071032e-01 -7.45229542e-01]\n",
            " [-1.05632663e+00  1.08870852e+00]\n",
            " [-1.06849992e+00  1.16732895e+00]\n",
            " [ 1.14418590e+00 -1.46522796e+00]\n",
            " [-1.15855682e+00  1.21676481e+00]\n",
            " [ 1.20263016e+00 -1.43285477e+00]\n",
            " [ 8.29408884e-01 -1.04758763e+00]\n",
            " [-1.27927792e+00  1.44956088e+00]\n",
            " [ 1.05245841e+00 -1.33061206e+00]\n",
            " [ 5.47294021e-01 -7.42614031e-01]\n",
            " [-1.03987634e+00  1.15596795e+00]\n",
            " [ 8.90087128e-01 -1.09805226e+00]\n",
            " [ 1.17566574e+00 -1.45216036e+00]\n",
            " [ 1.09257543e+00 -1.37199652e+00]\n",
            " [-1.19215429e+00  1.27317154e+00]\n",
            " [ 1.02236056e+00 -1.36472762e+00]\n",
            " [-1.11248899e+00  1.13445187e+00]\n",
            " [-9.38819528e-01  8.59339297e-01]\n",
            " [-4.64737684e-01  3.83746535e-01]\n",
            " [ 7.44789958e-01 -9.17906761e-01]\n",
            " [ 9.92788196e-01 -1.18115985e+00]\n",
            " [ 4.89202380e-01 -6.32176995e-01]\n",
            " [ 1.08806813e+00 -1.41791403e+00]\n",
            " [ 7.87196636e-01 -1.06405783e+00]\n",
            " [-1.65639855e-02 -1.91245556e-01]\n",
            " [ 1.14932215e+00 -1.46242785e+00]\n",
            " [-8.75971377e-01  8.17362607e-01]\n",
            " [-1.17875707e+00  1.20549512e+00]\n",
            " [-9.77978468e-01  8.47680330e-01]\n",
            " [ 1.17508185e+00 -1.41771495e+00]\n",
            " [-8.52219880e-01  8.64568233e-01]\n",
            " [-1.08864200e+00  1.26430047e+00]\n",
            " [ 7.17897773e-01 -8.44781816e-01]\n",
            " [ 1.10393763e+00 -1.44345665e+00]\n",
            " [-1.10162413e+00  1.18649781e+00]\n",
            " [-1.32226872e+00  1.42010975e+00]\n",
            " [-8.59331906e-01  8.68518412e-01]\n",
            " [ 1.11758578e+00 -1.37065351e+00]\n",
            " [-6.10381961e-01  6.14814639e-01]\n",
            " [-8.20527792e-01  8.73277545e-01]\n",
            " [-1.06860387e+00  1.13862550e+00]\n",
            " [ 6.01350293e-02 -3.62976670e-01]\n",
            " [ 1.12842441e+00 -1.41807759e+00]\n",
            " [ 7.81534553e-01 -1.04946184e+00]\n",
            " [-1.07022297e+00  1.20234358e+00]\n",
            " [ 1.06819022e+00 -1.28199708e+00]\n",
            " [-7.40319490e-01  7.00379789e-01]\n",
            " [ 1.06595755e+00 -1.34162521e+00]\n",
            " [-5.93703866e-01  6.60700381e-01]\n",
            " [-9.65647995e-01  1.00945747e+00]\n",
            " [ 7.10531116e-01 -9.08273280e-01]\n",
            " [ 1.18472087e+00 -1.40029085e+00]\n",
            " [-7.46189117e-01  8.10726702e-01]\n",
            " [ 9.89771843e-01 -1.23008943e+00]\n",
            " [-2.12502897e-01  1.00099593e-01]\n",
            " [ 9.36319947e-01 -1.19137788e+00]\n",
            " [-1.18629634e+00  1.42986310e+00]\n",
            " [ 1.05706656e+00 -1.30081618e+00]\n",
            " [ 1.15333235e+00 -1.41523588e+00]\n",
            " [ 8.47519040e-01 -1.08755136e+00]\n",
            " [ 8.97471368e-01 -1.25727451e+00]\n",
            " [-5.39801717e-01  4.67192680e-01]\n",
            " [ 1.17333233e+00 -1.45631111e+00]\n",
            " [-9.24358726e-01  1.12285125e+00]\n",
            " [ 3.26826960e-01 -5.59697330e-01]\n",
            " [ 1.96748450e-02 -1.79789647e-01]\n",
            " [-1.21122587e+00  1.34904253e+00]\n",
            " [ 9.54174519e-01 -1.13309228e+00]\n",
            " [ 1.10303712e+00 -1.34472477e+00]\n",
            " [-1.51983500e-01  1.92971062e-02]\n",
            " [-1.20109212e+00  1.40931594e+00]\n",
            " [-7.38133192e-01  6.46295428e-01]\n",
            " [ 1.04681718e+00 -1.24698508e+00]\n",
            " [ 1.13313246e+00 -1.44253910e+00]\n",
            " [ 1.10171068e+00 -1.35494876e+00]\n",
            " [-7.81895518e-01  7.44098067e-01]\n",
            " [-8.51249456e-01  8.16605687e-01]\n",
            " [-1.04479289e+00  1.09208596e+00]\n",
            " [ 1.83757961e-01 -4.02915537e-01]\n",
            " [ 9.69524324e-01 -1.29097688e+00]\n",
            " [ 1.14423656e+00 -1.43949115e+00]\n",
            " [-8.12803626e-01  8.73099506e-01]\n",
            " [-7.70340085e-01  8.76633108e-01]\n",
            " [-2.52279669e-01  1.02619320e-01]\n",
            " [ 1.17825162e+00 -1.47599769e+00]\n",
            " [ 8.73911858e-01 -1.16267812e+00]\n",
            " [ 1.14684403e+00 -1.41606283e+00]\n",
            " [ 9.49321389e-01 -1.24453235e+00]\n",
            " [ 1.14279640e+00 -1.40764058e+00]\n",
            " [-2.31774807e-01  1.68732792e-01]\n",
            " [ 1.06902277e+00 -1.35559106e+00]\n",
            " [ 1.10162818e+00 -1.35915864e+00]\n",
            " [ 1.20619094e+00 -1.43940318e+00]\n",
            " [ 1.10531223e+00 -1.39612758e+00]\n",
            " [-1.21440208e+00  1.32312465e+00]\n",
            " [-6.29723191e-01  5.62791765e-01]\n",
            " [ 1.01182044e+00 -1.19970810e+00]\n",
            " [-1.24540949e+00  1.37800658e+00]\n",
            " [-1.30271614e-01 -6.20549396e-02]\n",
            " [ 4.74748015e-01 -7.19948173e-01]\n",
            " [ 1.14443779e+00 -1.37185252e+00]\n",
            " [ 4.53917801e-01 -5.65400183e-01]\n",
            " [-1.55810326e-01  1.05754934e-01]\n",
            " [ 1.23493135e+00 -1.52002406e+00]\n",
            " [ 5.53350486e-02 -1.22074813e-01]\n",
            " [-1.10531080e+00  1.19290781e+00]\n",
            " [-1.92852795e-01 -4.98836115e-03]\n",
            " [-1.03512526e+00  1.18663478e+00]\n",
            " [ 6.55820370e-02 -2.55918801e-01]\n",
            " [ 1.10725749e+00 -1.38645232e+00]\n",
            " [-9.50335026e-01  9.43541229e-01]\n",
            " [-3.28784227e-01  2.68597364e-01]\n",
            " [-1.27348840e+00  1.36750126e+00]\n",
            " [-2.47292131e-01  5.56656793e-02]\n",
            " [ 1.11300719e+00 -1.34854853e+00]\n",
            " [-9.89474416e-01  9.68941987e-01]\n",
            " [ 3.51083726e-01 -5.70830882e-01]\n",
            " [ 4.26540911e-01 -6.20359838e-01]\n",
            " [ 1.75988674e-01 -3.93034190e-01]\n",
            " [ 8.73974562e-01 -1.20020092e+00]\n",
            " [-1.16156971e+00  1.30236733e+00]\n",
            " [-8.68482530e-01  1.01130927e+00]\n",
            " [-1.22361898e+00  1.35942018e+00]\n",
            " [-1.28201926e+00  1.45099294e+00]\n",
            " [ 4.69946921e-01 -7.89601803e-01]\n",
            " [-4.98955697e-01  2.92575628e-01]\n",
            " [ 8.94385517e-01 -1.16476297e+00]\n",
            " [ 4.12307113e-01 -6.67970121e-01]\n",
            " [-8.02784204e-01  8.21082473e-01]\n",
            " [ 5.89984804e-02 -2.04129174e-01]\n",
            " [ 9.60893631e-01 -1.28480744e+00]\n",
            " [ 1.18585622e+00 -1.39871299e+00]\n",
            " [ 1.02657771e+00 -1.24631751e+00]\n",
            " [ 9.59015846e-01 -1.17647839e+00]\n",
            " [-9.57113385e-01  9.75935936e-01]\n",
            " [-9.23089683e-04 -1.35331005e-01]\n",
            " [-8.21787357e-01  8.63287568e-01]\n",
            " [-8.19907665e-01  8.38387072e-01]\n",
            " [-1.23766661e+00  1.37893343e+00]\n",
            " [-9.45045233e-01  9.91176307e-01]\n",
            " [ 1.20331180e+00 -1.44620419e+00]\n",
            " [ 1.00859344e+00 -1.23758543e+00]\n",
            " [ 1.14899564e+00 -1.42169583e+00]\n",
            " [ 6.67146683e-01 -9.28442001e-01]\n",
            " [ 5.99315405e-01 -9.53264594e-01]\n",
            " [ 9.61181343e-01 -1.20001006e+00]\n",
            " [ 9.44094881e-02 -2.87366569e-01]\n",
            " [ 1.15805805e+00 -1.41867018e+00]\n",
            " [-1.28306973e+00  1.42304683e+00]\n",
            " [ 1.11433923e+00 -1.39672160e+00]\n",
            " [ 7.08617747e-01 -9.98146713e-01]\n",
            " [-5.74544311e-01  4.40550029e-01]\n",
            " [-1.21479106e+00  1.30483449e+00]\n",
            " [-1.52320474e-01  2.13776767e-01]\n",
            " [ 9.66629982e-01 -1.16503179e+00]\n",
            " [ 1.10952628e+00 -1.36667740e+00]\n",
            " [ 2.19687760e-01 -5.31314731e-01]\n",
            " [-5.78171790e-01  5.53274393e-01]\n",
            " [-1.82953775e-01  2.04531416e-01]\n",
            " [-1.35817456e+00  1.42823935e+00]\n",
            " [ 1.06136763e+00 -1.29287887e+00]\n",
            " [ 2.37149090e-01 -4.30402994e-01]\n",
            " [ 1.01421201e+00 -1.33759773e+00]\n",
            " [-1.19298565e+00  1.27078068e+00]\n",
            " [-1.07507455e+00  1.14383996e+00]\n",
            " [-1.07022417e+00  1.22200942e+00]\n",
            " [ 4.07359272e-01 -6.84803545e-01]\n",
            " [ 6.84370041e-01 -9.39036787e-01]\n",
            " [ 1.05664384e+00 -1.26098669e+00]\n",
            " [ 1.27991945e-01 -2.44119734e-01]\n",
            " [-1.66192740e-01 -1.74476832e-01]\n",
            " [ 1.04704940e+00 -1.28464782e+00]\n",
            " [ 1.00469381e-01 -2.43088901e-01]\n",
            " [ 1.10008311e+00 -1.37664628e+00]\n",
            " [ 1.06622696e+00 -1.34709156e+00]\n",
            " [-5.91981947e-01  3.84375751e-01]\n",
            " [-1.28410161e+00  1.36229336e+00]\n",
            " [-1.22652209e+00  1.35041618e+00]\n",
            " [ 6.57474875e-01 -9.57764626e-01]\n",
            " [-9.00430560e-01  9.52438414e-01]\n",
            " [ 1.14378381e+00 -1.41514409e+00]\n",
            " [-6.69887304e-01  6.64072037e-01]\n",
            " [-1.29090607e+00  1.48932469e+00]\n",
            " [ 1.16611922e+00 -1.44646335e+00]\n",
            " [-9.80826691e-02 -1.63462043e-01]\n",
            " [ 9.70399141e-01 -1.31307960e+00]\n",
            " [-9.83086109e-01  9.82834518e-01]\n",
            " [-8.72388303e-01  8.98599923e-01]\n",
            " [-8.74299407e-01  9.07565892e-01]\n",
            " [ 1.13605225e+00 -1.40739632e+00]\n",
            " [ 1.11453235e+00 -1.37150991e+00]\n",
            " [-6.32961273e-01  5.55896699e-01]\n",
            " [-1.24192166e+00  1.34934556e+00]\n",
            " [ 1.14998162e+00 -1.43262446e+00]\n",
            " [-8.99067447e-02 -2.83612330e-02]\n",
            " [-1.64281398e-01 -2.37233378e-03]\n",
            " [ 6.11876667e-01 -1.00872493e+00]\n",
            " [ 8.05928528e-01 -1.09971821e+00]\n",
            " [ 6.39989600e-02 -3.27097028e-01]\n",
            " [-1.03770411e+00  1.12864649e+00]\n",
            " [-1.13715494e+00  1.21599615e+00]\n",
            " [ 9.27309990e-01 -1.11772025e+00]\n",
            " [ 1.15742409e+00 -1.42235065e+00]\n",
            " [-1.21465719e+00  1.37596405e+00]\n",
            " [-1.25479496e+00  1.30677283e+00]\n",
            " [ 7.97210872e-01 -1.08656299e+00]\n",
            " [-1.21780479e+00  1.38347590e+00]\n",
            " [ 1.07470953e+00 -1.35459185e+00]\n",
            " [ 1.12087572e+00 -1.37534249e+00]\n",
            " [-6.92922533e-01  6.27468765e-01]\n",
            " [-9.07267928e-01  9.92479622e-01]\n",
            " [-8.95658493e-01  8.42294931e-01]\n",
            " [ 9.63369131e-01 -1.19068265e+00]\n",
            " [ 1.04357302e+00 -1.34496045e+00]\n",
            " [ 5.84043443e-01 -8.38796914e-01]\n",
            " [-9.33292627e-01  9.40438330e-01]\n",
            " [ 1.14091182e+00 -1.45584941e+00]\n",
            " [ 1.10835373e+00 -1.36978829e+00]\n",
            " [ 9.25081253e-01 -1.18422520e+00]\n",
            " [ 2.81806812e-02 -7.08917528e-02]\n",
            " [ 6.08723044e-01 -8.15732896e-01]\n",
            " [-1.05238497e+00  1.08882892e+00]\n",
            " [-4.22179729e-01  3.53288800e-01]\n",
            " [ 5.59847832e-01 -7.58853316e-01]\n",
            " [-1.29880834e+00  1.54452229e+00]\n",
            " [ 7.61108279e-01 -1.04080307e+00]\n",
            " [-6.06913686e-01  4.89287406e-01]\n",
            " [ 1.16713881e+00 -1.42843401e+00]\n",
            " [-9.31654453e-01  8.78019750e-01]\n",
            " [ 1.13269246e+00 -1.37642992e+00]\n",
            " [ 1.00637245e+00 -1.33546364e+00]\n",
            " [-7.50007480e-03 -1.26571149e-01]\n",
            " [ 1.09761727e+00 -1.37467360e+00]\n",
            " [-3.80451739e-01  1.93237364e-01]\n",
            " [-3.58033836e-01  1.71727568e-01]\n",
            " [-1.08905244e+00  1.15904546e+00]\n",
            " [ 7.56124854e-01 -1.08158338e+00]\n",
            " [-8.44999194e-01  8.42184424e-01]\n",
            " [-2.30199665e-01  7.64577985e-02]\n",
            " [ 6.21595740e-01 -8.40017676e-01]\n",
            " [-6.75668716e-01  7.36119092e-01]\n",
            " [-1.26007450e+00  1.37694275e+00]\n",
            " [-6.86068296e-01  5.35275638e-01]\n",
            " [ 1.11111641e+00 -1.36080539e+00]\n",
            " [-6.30443871e-01  5.08875906e-01]\n",
            " [-1.27277184e+00  1.46237457e+00]\n",
            " [ 4.26053077e-01 -5.96294224e-01]\n",
            " [ 6.16513610e-01 -9.37192976e-01]\n",
            " [ 9.64308619e-01 -1.17983246e+00]\n",
            " [-1.24616015e+00  1.39353836e+00]\n",
            " [ 6.55586004e-01 -8.44339073e-01]\n",
            " [-1.12871206e+00  1.24040902e+00]\n",
            " [ 6.69061899e-01 -9.03881550e-01]\n",
            " [-9.21995223e-01  9.34374750e-01]\n",
            " [-1.07133949e+00  1.18026245e+00]\n",
            " [ 1.09041512e+00 -1.36947775e+00]\n",
            " [ 1.07221878e+00 -1.32428300e+00]\n",
            " [ 1.15473676e+00 -1.44638145e+00]\n",
            " [-8.18763375e-01  8.48754764e-01]\n",
            " [ 1.11272371e+00 -1.41389215e+00]\n",
            " [ 7.84468889e-01 -1.03728139e+00]\n",
            " [-1.16945243e+00  1.32770193e+00]\n",
            " [ 7.99681991e-02 -1.47287354e-01]\n",
            " [ 1.12114441e+00 -1.34674585e+00]\n",
            " [-9.57593858e-01  8.49507689e-01]\n",
            " [-1.23541009e+00  1.47245061e+00]\n",
            " [-9.15666819e-01  1.06162190e+00]\n",
            " [-9.84548450e-01  9.62469041e-01]\n",
            " [ 9.16078150e-01 -1.19311619e+00]\n",
            " [-9.20739830e-01  8.79156113e-01]\n",
            " [ 6.84576452e-01 -9.88383353e-01]\n",
            " [-1.32816327e+00  1.50733638e+00]\n",
            " [ 1.18218553e+00 -1.42260206e+00]\n",
            " [-2.75473148e-01  2.30407923e-01]\n",
            " [-8.78776431e-01  8.55005682e-01]\n",
            " [ 1.11781561e+00 -1.36478055e+00]\n",
            " [ 1.13535273e+00 -1.43416274e+00]\n",
            " [ 1.13349628e+00 -1.39345741e+00]\n",
            " [ 1.14266002e+00 -1.44338298e+00]\n",
            " [-7.18508482e-01  6.62721574e-01]\n",
            " [ 1.06208837e+00 -1.32543147e+00]\n",
            " [ 9.26718354e-01 -1.17470181e+00]\n",
            " [-3.71739864e-01  1.81942493e-01]\n",
            " [-1.19511425e+00  1.34354973e+00]\n",
            " [-3.80529493e-01  2.53247112e-01]\n",
            " [-1.33067083e+00  1.45626688e+00]\n",
            " [-1.31159246e+00  1.50588357e+00]\n",
            " [-1.31324542e+00  1.43869042e+00]\n",
            " [ 1.02580225e+00 -1.26849794e+00]\n",
            " [ 9.75372970e-01 -1.24356616e+00]\n",
            " [ 6.05977535e-01 -8.03869247e-01]\n",
            " [-1.07901251e+00  1.15053380e+00]\n",
            " [ 1.05948579e+00 -1.36418712e+00]\n",
            " [-6.32450938e-01  4.56460714e-01]\n",
            " [ 1.11967123e+00 -1.41123426e+00]\n",
            " [-3.26313555e-01  1.77064896e-01]\n",
            " [ 5.60003698e-01 -8.32592487e-01]\n",
            " [ 1.00189686e+00 -1.22770643e+00]\n",
            " [ 9.56896305e-01 -1.18916738e+00]\n",
            " [ 1.09829521e+00 -1.40479887e+00]\n",
            " [-1.12619030e+00  1.34478486e+00]\n",
            " [ 6.33433819e-01 -8.33094537e-01]\n",
            " [ 4.04995605e-02 -2.97147751e-01]\n",
            " [-1.10022593e+00  1.21490157e+00]\n",
            " [ 9.96197581e-01 -1.26307404e+00]\n",
            " [ 1.05726826e+00 -1.33803546e+00]\n",
            " [ 1.03719413e+00 -1.28329122e+00]\n",
            " [-1.13419974e+00  1.30484235e+00]\n",
            " [-7.30374515e-01  6.86731339e-01]\n",
            " [-1.16003168e+00  1.25274575e+00]\n",
            " [-9.21554685e-01  9.57211196e-01]\n",
            " [-1.67751685e-02  1.06375637e-02]\n",
            " [-1.17123759e+00  1.22096920e+00]\n",
            " [-8.15104246e-01  9.06752050e-01]\n",
            " [-3.20612699e-01  8.46648738e-02]\n",
            " [ 5.29663384e-01 -8.13907981e-01]\n",
            " [-1.20397651e+00  1.17692697e+00]\n",
            " [ 1.08141053e+00 -1.41952670e+00]\n",
            " [-9.99188781e-01  9.33887064e-01]\n",
            " [-1.05858684e+00  1.08380425e+00]\n",
            " [ 6.38681650e-03 -1.40522867e-01]\n",
            " [ 1.16312492e+00 -1.52496231e+00]\n",
            " [ 9.27627325e-01 -1.13494813e+00]\n",
            " [ 8.42206657e-01 -1.12878597e+00]\n",
            " [-7.73257852e-01  7.73560226e-01]\n",
            " [ 9.65873837e-01 -1.23584187e+00]\n",
            " [ 1.16027200e+00 -1.48879910e+00]\n",
            " [-8.63493443e-01  9.03951764e-01]\n",
            " [-1.32544541e+00  1.45099223e+00]\n",
            " [ 1.10175753e+00 -1.35155344e+00]\n",
            " [-1.06424630e+00  1.12592232e+00]\n",
            " [-1.15800583e+00  1.21297109e+00]\n",
            " [ 5.16282737e-01 -8.04655969e-01]\n",
            " [-7.65659392e-01  7.58280754e-01]\n",
            " [-1.23625958e+00  1.33330619e+00]\n",
            " [ 1.13608527e+00 -1.40359962e+00]\n",
            " [-2.02101380e-01  9.04691666e-02]\n",
            " [ 1.12990868e+00 -1.43319404e+00]\n",
            " [-1.09829772e+00  1.18176031e+00]\n",
            " [ 6.47605598e-01 -8.03360164e-01]\n",
            " [ 1.39786184e-01 -4.06730950e-01]\n",
            " [ 1.14201295e+00 -1.41632855e+00]\n",
            " [-1.02480936e+00  1.14443886e+00]\n",
            " [ 1.00865757e+00 -1.23147810e+00]\n",
            " [-1.14448702e+00  1.22101963e+00]\n",
            " [-1.18774319e+00  1.33667052e+00]\n",
            " [ 1.05019891e+00 -1.35179269e+00]\n",
            " [ 7.40765482e-02 -1.51693240e-01]\n",
            " [ 9.04344440e-01 -1.14363420e+00]\n",
            " [ 2.33368725e-01 -4.48231131e-01]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.806 [0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1] [0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1\n",
            " 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0\n",
            " 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1\n",
            " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0]\n",
            "##### labels.shape:  (500,) preds.shape:  (500,)\n",
            "##### k, v.shape :  encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140417274725888)\n",
            "##### k, v.shape :  encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140411137949696)\n",
            "##### k, v.shape :  encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140413644570624)\n",
            "##### k, v.shape :  encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140417274729984)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735677952)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274736128)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140415958253568)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274739200)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140416230883328)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274742272)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140416297992192)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274745344)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140415892979712)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274748416)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274751488)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274754560)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140410382974976)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140417274757632)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140410450083840)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274769920)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274772992)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274776064)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410392412160)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274779136)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410459521024)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274782208)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140415895339008)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274785280)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410517192704)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274788352)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274791424)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274794496)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140410519552000)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140417274797568)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140410584301568)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274809856)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274812928)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274816000)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410593738752)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274819072)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410651410432)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735684096)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410653769728)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735687168)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410656129024)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735690240)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735693312)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735696384)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140410718519296)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735699456)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140410785628160)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735711744)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735714816)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735717888)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410727956480)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735720960)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410795065344)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735724032)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410658488320)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735727104)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410660847616)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735730176)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735733248)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735736320)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140410852737024)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735739392)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140410919845888)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735751680)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735754752)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735757824)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410862174208)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735760896)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410929283072)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735763968)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410986954752)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735767040)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410989314048)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735770112)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735773184)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735776256)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411054063616)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735779328)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411121172480)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735791616)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735794688)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735797760)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411063500800)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735800832)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411130609664)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735803904)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410991673344)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735806976)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410994032640)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735810048)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735813120)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735816192)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411247001600)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735819264)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411259584512)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735831552)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735834624)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735837696)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410996391936)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735840768)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411256438784)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735843840)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411269021696)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735846912)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411381219328)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735849984)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735853056)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735856128)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411383578624)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735859200)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411393802240)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735871488)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735874560)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735877632)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411403239424)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735880704)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411515437056)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735883776)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411517796352)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735886848)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411520155648)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735889920)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735892992)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735896064)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411528019968)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735899136)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411649654784)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735911424)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735914496)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735917568)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411537457152)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735920640)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411659091968)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735923712)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411522514944)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735926784)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411524874240)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735929856)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735932928)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735936000)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411662237696)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735939072)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411792261120)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735951360)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735954432)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735957504)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411671674880)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735960576)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411801698304)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735963648)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411892924416)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735966720)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411895283712)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735969792)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735972864)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735975936)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140412396240896)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735979008)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140412731785216)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735991296)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735994368)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735997440)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140412405678080)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736000512)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140412741222400)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736003584)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411897643008)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736006656)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411900002304)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736009728)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736012800)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736015872)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140413201547264)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411736018944)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140413537091584)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736031232)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736034304)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736037376)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411902361600)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736040448)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140413210984448)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736043520)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140413546528768)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736046592)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140414040408064)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736049664)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736052736)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736055808)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140414042767360)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411736058880)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140414375952384)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736071168)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736074240)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736077312)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140417274725888)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140411137949696)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140413644570624)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140417274729984)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735677952)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274736128)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140415958253568)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274739200)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140416230883328)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274742272)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140416297992192)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274745344)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140415892979712)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274748416)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274751488)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274754560)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140410382974976)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140417274757632)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140410450083840)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274769920)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274772992)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274776064)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410392412160)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274779136)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410459521024)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274782208)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140415895339008)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274785280)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410517192704)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274788352)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274791424)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274794496)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140410519552000)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140417274797568)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140410584301568)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274809856)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274812928)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274816000)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410593738752)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140417274819072)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410651410432)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735684096)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410653769728)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735687168)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410656129024)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735690240)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735693312)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735696384)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140410718519296)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735699456)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140410785628160)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735711744)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735714816)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735717888)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410727956480)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735720960)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410795065344)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735724032)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410658488320)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735727104)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410660847616)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735730176)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735733248)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735736320)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140410852737024)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735739392)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140410919845888)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735751680)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735754752)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735757824)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410862174208)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735760896)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410929283072)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735763968)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410986954752)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735767040)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410989314048)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735770112)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735773184)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735776256)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411054063616)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735779328)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411121172480)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735791616)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735794688)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735797760)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411063500800)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735800832)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411130609664)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735803904)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410991673344)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735806976)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410994032640)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735810048)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735813120)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735816192)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411247001600)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735819264)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411259584512)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735831552)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735834624)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735837696)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140410996391936)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735840768)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411256438784)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735843840)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411269021696)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735846912)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411381219328)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735849984)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735853056)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735856128)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411383578624)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735859200)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411393802240)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735871488)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735874560)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735877632)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411403239424)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735880704)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411515437056)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735883776)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411517796352)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735886848)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411520155648)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735889920)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735892992)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735896064)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411528019968)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735899136)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411649654784)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735911424)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735914496)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735917568)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411537457152)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735920640)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411659091968)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735923712)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411522514944)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735926784)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411524874240)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735929856)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735932928)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735936000)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140411662237696)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735939072)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140411792261120)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735951360)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735954432)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735957504)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411671674880)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735960576)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411801698304)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735963648)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411892924416)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735966720)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411895283712)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735969792)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735972864)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735975936)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140412396240896)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411735979008)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140412731785216)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735991296)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735994368)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411735997440)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140412405678080)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736000512)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140412741222400)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736003584)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411897643008)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736006656)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411900002304)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736009728)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736012800)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736015872)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140413201547264)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411736018944)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140413537091584)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736031232)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736034304)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736037376)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140411902361600)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736040448)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140413210984448)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736043520)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140413546528768)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736046592)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140414040408064)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736049664)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736052736)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736055808)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140414042767360)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140411736058880)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140414375952384)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736071168)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736074240)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736077312)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.head.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140414385389568)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.head.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140411736080384)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.head.out_proj.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140411736083456)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.head.out_proj.bias torch.Size([2])\n",
            "##### unique_key :  ((2,), 140417274869760)\n",
            "Eval (boolq, Val): 100% 16/16 [00:04<00:00,  3.98it/s]\n",
            "##### get_accumulated(), logits :  [[ 2.03408718e-01 -3.24311495e-01]\n",
            " [-7.76127756e-01  7.37709641e-01]\n",
            " [ 1.14059913e+00 -1.40508556e+00]\n",
            " [ 6.23067856e-01 -7.60961115e-01]\n",
            " [-1.21315825e+00  1.30660880e+00]\n",
            " [-9.58542705e-01  9.92949545e-01]\n",
            " [ 9.18907762e-01 -1.23884499e+00]\n",
            " [ 9.77537572e-01 -1.24133420e+00]\n",
            " [ 7.32273221e-01 -1.00446677e+00]\n",
            " [ 7.75670290e-01 -1.01815152e+00]\n",
            " [-5.60040891e-01  6.40259683e-01]\n",
            " [-1.29942203e+00  1.48279607e+00]\n",
            " [ 1.10529053e+00 -1.34755456e+00]\n",
            " [-1.29871333e+00  1.40045369e+00]\n",
            " [ 6.50232732e-01 -8.62470150e-01]\n",
            " [-8.69810641e-01  7.61020958e-01]\n",
            " [ 1.09264767e+00 -1.39885604e+00]\n",
            " [-1.13181865e+00  1.19874895e+00]\n",
            " [-4.05005425e-01  2.34159350e-01]\n",
            " [ 1.13804185e+00 -1.40507853e+00]\n",
            " [ 7.30890632e-01 -9.18195307e-01]\n",
            " [-3.65828335e-01  4.54162359e-01]\n",
            " [-1.30571294e+00  1.42349005e+00]\n",
            " [-1.12415338e+00  1.33048260e+00]\n",
            " [-1.16908216e+00  1.22052920e+00]\n",
            " [ 1.09443438e+00 -1.35829401e+00]\n",
            " [ 9.12882626e-01 -1.17560613e+00]\n",
            " [ 1.10521519e+00 -1.34307015e+00]\n",
            " [-7.06612349e-01  5.44907033e-01]\n",
            " [-7.93397427e-01  7.15368688e-01]\n",
            " [ 1.09070611e+00 -1.32769835e+00]\n",
            " [ 6.95458293e-01 -1.01200628e+00]\n",
            " [-1.32840586e+00  1.55340135e+00]\n",
            " [-1.15076721e+00  1.23530233e+00]\n",
            " [ 1.66134834e-02 -2.28444874e-01]\n",
            " [ 1.12069356e+00 -1.39891851e+00]\n",
            " [ 1.06504595e+00 -1.33046091e+00]\n",
            " [ 8.79666328e-01 -1.12162411e+00]\n",
            " [ 1.15948272e+00 -1.42668569e+00]\n",
            " [-4.15460378e-01  2.66266614e-01]\n",
            " [-1.04093325e+00  1.18222797e+00]\n",
            " [ 1.11659205e+00 -1.37921858e+00]\n",
            " [ 1.01128745e+00 -1.31391752e+00]\n",
            " [ 1.18543565e+00 -1.47785270e+00]\n",
            " [-9.64527607e-01  9.47045147e-01]\n",
            " [ 1.04140699e+00 -1.32656133e+00]\n",
            " [-8.21671188e-01  7.90841043e-01]\n",
            " [ 6.03242874e-01 -8.01709712e-01]\n",
            " [ 2.55136102e-01 -3.83187830e-01]\n",
            " [-1.03649163e+00  1.22191632e+00]\n",
            " [-1.02022898e+00  9.94234860e-01]\n",
            " [-1.21816134e+00  1.32338738e+00]\n",
            " [-5.62528849e-01  3.52707624e-01]\n",
            " [-1.19171417e+00  1.39499271e+00]\n",
            " [-1.14032137e+00  1.16021907e+00]\n",
            " [-8.76923501e-01  9.07122076e-01]\n",
            " [-1.23558342e+00  1.43729103e+00]\n",
            " [ 1.14873278e+00 -1.44910407e+00]\n",
            " [ 1.13326037e+00 -1.40417671e+00]\n",
            " [ 1.05331397e+00 -1.32718861e+00]\n",
            " [ 1.15765786e+00 -1.43592680e+00]\n",
            " [-1.79551750e-01  1.14746299e-02]\n",
            " [ 8.77303854e-02 -3.95560920e-01]\n",
            " [ 3.97664130e-01 -5.62590778e-01]\n",
            " [ 5.39188564e-01 -8.92660439e-01]\n",
            " [ 7.50279903e-01 -9.67354000e-01]\n",
            " [ 1.08476663e+00 -1.34960401e+00]\n",
            " [-1.03969586e+00  1.15668130e+00]\n",
            " [-1.25906074e+00  1.29906881e+00]\n",
            " [ 1.17163813e+00 -1.37881267e+00]\n",
            " [-9.72739100e-01  1.03009069e+00]\n",
            " [ 8.84924114e-01 -1.05926800e+00]\n",
            " [ 3.83316785e-01 -6.54441059e-01]\n",
            " [-9.65408921e-01  1.05859649e+00]\n",
            " [ 1.69085115e-01 -3.36405605e-01]\n",
            " [ 1.08713639e+00 -1.28522193e+00]\n",
            " [ 1.13203418e+00 -1.43476427e+00]\n",
            " [-1.05255830e+00  1.07140791e+00]\n",
            " [-9.51314628e-01  9.00759399e-01]\n",
            " [ 1.11393929e+00 -1.40890479e+00]\n",
            " [-1.18260849e+00  1.28031051e+00]\n",
            " [ 1.05783105e+00 -1.30479550e+00]\n",
            " [-1.12915146e+00  1.18731856e+00]\n",
            " [-7.88290560e-01  7.01267719e-01]\n",
            " [ 1.10043371e+00 -1.38645613e+00]\n",
            " [ 9.82699454e-01 -1.16548002e+00]\n",
            " [-7.09632516e-01  7.39810169e-01]\n",
            " [-1.10868180e+00  1.13726890e+00]\n",
            " [ 1.10382712e+00 -1.30338347e+00]\n",
            " [ 1.02005541e+00 -1.25199497e+00]\n",
            " [-1.29679167e+00  1.50171995e+00]\n",
            " [ 1.05704558e+00 -1.33028769e+00]\n",
            " [-1.27912772e+00  1.35188591e+00]\n",
            " [ 9.16856170e-01 -1.21436679e+00]\n",
            " [-1.02021766e+00  1.14701521e+00]\n",
            " [ 7.50576317e-01 -1.00038147e+00]\n",
            " [ 1.14437139e+00 -1.39360976e+00]\n",
            " [ 1.04622328e+00 -1.28036582e+00]\n",
            " [-4.67650861e-01  3.43399972e-01]\n",
            " [ 9.65692461e-01 -1.24392307e+00]\n",
            " [-6.70049012e-01  7.16176808e-01]\n",
            " [ 1.17381442e+00 -1.46830869e+00]\n",
            " [-1.17132032e+00  1.31901097e+00]\n",
            " [ 1.02606857e+00 -1.31149590e+00]\n",
            " [-1.10890853e+00  1.18091476e+00]\n",
            " [-9.92637634e-01  9.73284185e-01]\n",
            " [-9.71481264e-01  1.00181472e+00]\n",
            " [-2.65308946e-01  9.14474390e-03]\n",
            " [ 1.07989681e+00 -1.35624301e+00]\n",
            " [ 1.08180535e+00 -1.34661686e+00]\n",
            " [-1.16735375e+00  1.23397386e+00]\n",
            " [ 1.16030657e+00 -1.42699170e+00]\n",
            " [-1.27442825e+00  1.37166667e+00]\n",
            " [ 1.65426314e-01 -2.86040515e-01]\n",
            " [-9.31378126e-01  9.56928372e-01]\n",
            " [ 7.93288827e-01 -1.06636512e+00]\n",
            " [ 8.57371271e-01 -1.27392995e+00]\n",
            " [ 7.32941985e-01 -1.03942454e+00]\n",
            " [-1.29162157e+00  1.47556078e+00]\n",
            " [-1.19710767e+00  1.33202779e+00]\n",
            " [-1.28230894e+00  1.46190369e+00]\n",
            " [ 1.14693224e+00 -1.39063144e+00]\n",
            " [ 4.06986684e-01 -6.22931123e-01]\n",
            " [ 9.78159308e-01 -1.19741189e+00]\n",
            " [-4.43720609e-01  4.70659316e-01]\n",
            " [-1.11806571e+00  1.16806519e+00]\n",
            " [ 1.09514487e+00 -1.37723660e+00]\n",
            " [ 4.40321952e-01 -8.39402556e-01]\n",
            " [-1.17865074e+00  1.29314673e+00]\n",
            " [ 8.95676851e-01 -1.11841309e+00]\n",
            " [ 1.10418117e+00 -1.35422111e+00]\n",
            " [ 9.99172032e-01 -1.28557217e+00]\n",
            " [ 1.03556478e+00 -1.25649989e+00]\n",
            " [-5.00455141e-01  4.60455596e-01]\n",
            " [-1.33608449e+00  1.41857851e+00]\n",
            " [ 4.23569918e-01 -6.67873800e-01]\n",
            " [ 1.15247881e+00 -1.42432380e+00]\n",
            " [ 4.09880936e-01 -6.09030783e-01]\n",
            " [-8.12288642e-01  9.56813037e-01]\n",
            " [ 9.58894968e-01 -1.21897674e+00]\n",
            " [ 2.66889304e-01 -4.23970759e-01]\n",
            " [ 3.27536374e-01 -5.06964982e-01]\n",
            " [ 1.07867324e+00 -1.37776887e+00]\n",
            " [-3.68262708e-01  1.01949736e-01]\n",
            " [ 1.10230815e+00 -1.35317814e+00]\n",
            " [ 1.09291220e+00 -1.41196632e+00]\n",
            " [-8.04803491e-01  7.89504826e-01]\n",
            " [ 9.07178521e-01 -1.25761580e+00]\n",
            " [-1.21434164e+00  1.34604800e+00]\n",
            " [ 1.08914602e+00 -1.31990469e+00]\n",
            " [ 6.68071032e-01 -7.45229542e-01]\n",
            " [-1.05632663e+00  1.08870852e+00]\n",
            " [-1.06849992e+00  1.16732895e+00]\n",
            " [ 1.14418590e+00 -1.46522796e+00]\n",
            " [-1.15855682e+00  1.21676481e+00]\n",
            " [ 1.20263016e+00 -1.43285477e+00]\n",
            " [ 8.29408884e-01 -1.04758763e+00]\n",
            " [-1.27927792e+00  1.44956088e+00]\n",
            " [ 1.05245841e+00 -1.33061206e+00]\n",
            " [ 5.47294021e-01 -7.42614031e-01]\n",
            " [-1.03987634e+00  1.15596795e+00]\n",
            " [ 8.90087128e-01 -1.09805226e+00]\n",
            " [ 1.17566574e+00 -1.45216036e+00]\n",
            " [ 1.09257543e+00 -1.37199652e+00]\n",
            " [-1.19215429e+00  1.27317154e+00]\n",
            " [ 1.02236056e+00 -1.36472762e+00]\n",
            " [-1.11248899e+00  1.13445187e+00]\n",
            " [-9.38819528e-01  8.59339297e-01]\n",
            " [-4.64737684e-01  3.83746535e-01]\n",
            " [ 7.44789958e-01 -9.17906761e-01]\n",
            " [ 9.92788196e-01 -1.18115985e+00]\n",
            " [ 4.89202380e-01 -6.32176995e-01]\n",
            " [ 1.08806813e+00 -1.41791403e+00]\n",
            " [ 7.87196636e-01 -1.06405783e+00]\n",
            " [-1.65639855e-02 -1.91245556e-01]\n",
            " [ 1.14932215e+00 -1.46242785e+00]\n",
            " [-8.75971377e-01  8.17362607e-01]\n",
            " [-1.17875707e+00  1.20549512e+00]\n",
            " [-9.77978468e-01  8.47680330e-01]\n",
            " [ 1.17508185e+00 -1.41771495e+00]\n",
            " [-8.52219880e-01  8.64568233e-01]\n",
            " [-1.08864200e+00  1.26430047e+00]\n",
            " [ 7.17897773e-01 -8.44781816e-01]\n",
            " [ 1.10393763e+00 -1.44345665e+00]\n",
            " [-1.10162413e+00  1.18649781e+00]\n",
            " [-1.32226872e+00  1.42010975e+00]\n",
            " [-8.59331906e-01  8.68518412e-01]\n",
            " [ 1.11758578e+00 -1.37065351e+00]\n",
            " [-6.10381961e-01  6.14814639e-01]\n",
            " [-8.20527792e-01  8.73277545e-01]\n",
            " [-1.06860387e+00  1.13862550e+00]\n",
            " [ 6.01350293e-02 -3.62976670e-01]\n",
            " [ 1.12842441e+00 -1.41807759e+00]\n",
            " [ 7.81534553e-01 -1.04946184e+00]\n",
            " [-1.07022297e+00  1.20234358e+00]\n",
            " [ 1.06819022e+00 -1.28199708e+00]\n",
            " [-7.40319490e-01  7.00379789e-01]\n",
            " [ 1.06595755e+00 -1.34162521e+00]\n",
            " [-5.93703866e-01  6.60700381e-01]\n",
            " [-9.65647995e-01  1.00945747e+00]\n",
            " [ 7.10531116e-01 -9.08273280e-01]\n",
            " [ 1.18472087e+00 -1.40029085e+00]\n",
            " [-7.46189117e-01  8.10726702e-01]\n",
            " [ 9.89771843e-01 -1.23008943e+00]\n",
            " [-2.12502897e-01  1.00099593e-01]\n",
            " [ 9.36319947e-01 -1.19137788e+00]\n",
            " [-1.18629634e+00  1.42986310e+00]\n",
            " [ 1.05706656e+00 -1.30081618e+00]\n",
            " [ 1.15333235e+00 -1.41523588e+00]\n",
            " [ 8.47519040e-01 -1.08755136e+00]\n",
            " [ 8.97471368e-01 -1.25727451e+00]\n",
            " [-5.39801717e-01  4.67192680e-01]\n",
            " [ 1.17333233e+00 -1.45631111e+00]\n",
            " [-9.24358726e-01  1.12285125e+00]\n",
            " [ 3.26826960e-01 -5.59697330e-01]\n",
            " [ 1.96748450e-02 -1.79789647e-01]\n",
            " [-1.21122587e+00  1.34904253e+00]\n",
            " [ 9.54174519e-01 -1.13309228e+00]\n",
            " [ 1.10303712e+00 -1.34472477e+00]\n",
            " [-1.51983500e-01  1.92971062e-02]\n",
            " [-1.20109212e+00  1.40931594e+00]\n",
            " [-7.38133192e-01  6.46295428e-01]\n",
            " [ 1.04681718e+00 -1.24698508e+00]\n",
            " [ 1.13313246e+00 -1.44253910e+00]\n",
            " [ 1.10171068e+00 -1.35494876e+00]\n",
            " [-7.81895518e-01  7.44098067e-01]\n",
            " [-8.51249456e-01  8.16605687e-01]\n",
            " [-1.04479289e+00  1.09208596e+00]\n",
            " [ 1.83757961e-01 -4.02915537e-01]\n",
            " [ 9.69524324e-01 -1.29097688e+00]\n",
            " [ 1.14423656e+00 -1.43949115e+00]\n",
            " [-8.12803626e-01  8.73099506e-01]\n",
            " [-7.70340085e-01  8.76633108e-01]\n",
            " [-2.52279669e-01  1.02619320e-01]\n",
            " [ 1.17825162e+00 -1.47599769e+00]\n",
            " [ 8.73911858e-01 -1.16267812e+00]\n",
            " [ 1.14684403e+00 -1.41606283e+00]\n",
            " [ 9.49321389e-01 -1.24453235e+00]\n",
            " [ 1.14279640e+00 -1.40764058e+00]\n",
            " [-2.31774807e-01  1.68732792e-01]\n",
            " [ 1.06902277e+00 -1.35559106e+00]\n",
            " [ 1.10162818e+00 -1.35915864e+00]\n",
            " [ 1.20619094e+00 -1.43940318e+00]\n",
            " [ 1.10531223e+00 -1.39612758e+00]\n",
            " [-1.21440208e+00  1.32312465e+00]\n",
            " [-6.29723191e-01  5.62791765e-01]\n",
            " [ 1.01182044e+00 -1.19970810e+00]\n",
            " [-1.24540949e+00  1.37800658e+00]\n",
            " [-1.30271614e-01 -6.20549396e-02]\n",
            " [ 4.74748015e-01 -7.19948173e-01]\n",
            " [ 1.14443779e+00 -1.37185252e+00]\n",
            " [ 4.53917801e-01 -5.65400183e-01]\n",
            " [-1.55810326e-01  1.05754934e-01]\n",
            " [ 1.23493135e+00 -1.52002406e+00]\n",
            " [ 5.53350486e-02 -1.22074813e-01]\n",
            " [-1.10531080e+00  1.19290781e+00]\n",
            " [-1.92852795e-01 -4.98836115e-03]\n",
            " [-1.03512526e+00  1.18663478e+00]\n",
            " [ 6.55820370e-02 -2.55918801e-01]\n",
            " [ 1.10725749e+00 -1.38645232e+00]\n",
            " [-9.50335026e-01  9.43541229e-01]\n",
            " [-3.28784227e-01  2.68597364e-01]\n",
            " [-1.27348840e+00  1.36750126e+00]\n",
            " [-2.47292131e-01  5.56656793e-02]\n",
            " [ 1.11300719e+00 -1.34854853e+00]\n",
            " [-9.89474416e-01  9.68941987e-01]\n",
            " [ 3.51083726e-01 -5.70830882e-01]\n",
            " [ 4.26540911e-01 -6.20359838e-01]\n",
            " [ 1.75988674e-01 -3.93034190e-01]\n",
            " [ 8.73974562e-01 -1.20020092e+00]\n",
            " [-1.16156971e+00  1.30236733e+00]\n",
            " [-8.68482530e-01  1.01130927e+00]\n",
            " [-1.22361898e+00  1.35942018e+00]\n",
            " [-1.28201926e+00  1.45099294e+00]\n",
            " [ 4.69946921e-01 -7.89601803e-01]\n",
            " [-4.98955697e-01  2.92575628e-01]\n",
            " [ 8.94385517e-01 -1.16476297e+00]\n",
            " [ 4.12307113e-01 -6.67970121e-01]\n",
            " [-8.02784204e-01  8.21082473e-01]\n",
            " [ 5.89984804e-02 -2.04129174e-01]\n",
            " [ 9.60893631e-01 -1.28480744e+00]\n",
            " [ 1.18585622e+00 -1.39871299e+00]\n",
            " [ 1.02657771e+00 -1.24631751e+00]\n",
            " [ 9.59015846e-01 -1.17647839e+00]\n",
            " [-9.57113385e-01  9.75935936e-01]\n",
            " [-9.23089683e-04 -1.35331005e-01]\n",
            " [-8.21787357e-01  8.63287568e-01]\n",
            " [-8.19907665e-01  8.38387072e-01]\n",
            " [-1.23766661e+00  1.37893343e+00]\n",
            " [-9.45045233e-01  9.91176307e-01]\n",
            " [ 1.20331180e+00 -1.44620419e+00]\n",
            " [ 1.00859344e+00 -1.23758543e+00]\n",
            " [ 1.14899564e+00 -1.42169583e+00]\n",
            " [ 6.67146683e-01 -9.28442001e-01]\n",
            " [ 5.99315405e-01 -9.53264594e-01]\n",
            " [ 9.61181343e-01 -1.20001006e+00]\n",
            " [ 9.44094881e-02 -2.87366569e-01]\n",
            " [ 1.15805805e+00 -1.41867018e+00]\n",
            " [-1.28306973e+00  1.42304683e+00]\n",
            " [ 1.11433923e+00 -1.39672160e+00]\n",
            " [ 7.08617747e-01 -9.98146713e-01]\n",
            " [-5.74544311e-01  4.40550029e-01]\n",
            " [-1.21479106e+00  1.30483449e+00]\n",
            " [-1.52320474e-01  2.13776767e-01]\n",
            " [ 9.66629982e-01 -1.16503179e+00]\n",
            " [ 1.10952628e+00 -1.36667740e+00]\n",
            " [ 2.19687760e-01 -5.31314731e-01]\n",
            " [-5.78171790e-01  5.53274393e-01]\n",
            " [-1.82953775e-01  2.04531416e-01]\n",
            " [-1.35817456e+00  1.42823935e+00]\n",
            " [ 1.06136763e+00 -1.29287887e+00]\n",
            " [ 2.37149090e-01 -4.30402994e-01]\n",
            " [ 1.01421201e+00 -1.33759773e+00]\n",
            " [-1.19298565e+00  1.27078068e+00]\n",
            " [-1.07507455e+00  1.14383996e+00]\n",
            " [-1.07022417e+00  1.22200942e+00]\n",
            " [ 4.07359272e-01 -6.84803545e-01]\n",
            " [ 6.84370041e-01 -9.39036787e-01]\n",
            " [ 1.05664384e+00 -1.26098669e+00]\n",
            " [ 1.27991945e-01 -2.44119734e-01]\n",
            " [-1.66192740e-01 -1.74476832e-01]\n",
            " [ 1.04704940e+00 -1.28464782e+00]\n",
            " [ 1.00469381e-01 -2.43088901e-01]\n",
            " [ 1.10008311e+00 -1.37664628e+00]\n",
            " [ 1.06622696e+00 -1.34709156e+00]\n",
            " [-5.91981947e-01  3.84375751e-01]\n",
            " [-1.28410161e+00  1.36229336e+00]\n",
            " [-1.22652209e+00  1.35041618e+00]\n",
            " [ 6.57474875e-01 -9.57764626e-01]\n",
            " [-9.00430560e-01  9.52438414e-01]\n",
            " [ 1.14378381e+00 -1.41514409e+00]\n",
            " [-6.69887304e-01  6.64072037e-01]\n",
            " [-1.29090607e+00  1.48932469e+00]\n",
            " [ 1.16611922e+00 -1.44646335e+00]\n",
            " [-9.80826691e-02 -1.63462043e-01]\n",
            " [ 9.70399141e-01 -1.31307960e+00]\n",
            " [-9.83086109e-01  9.82834518e-01]\n",
            " [-8.72388303e-01  8.98599923e-01]\n",
            " [-8.74299407e-01  9.07565892e-01]\n",
            " [ 1.13605225e+00 -1.40739632e+00]\n",
            " [ 1.11453235e+00 -1.37150991e+00]\n",
            " [-6.32961273e-01  5.55896699e-01]\n",
            " [-1.24192166e+00  1.34934556e+00]\n",
            " [ 1.14998162e+00 -1.43262446e+00]\n",
            " [-8.99067447e-02 -2.83612330e-02]\n",
            " [-1.64281398e-01 -2.37233378e-03]\n",
            " [ 6.11876667e-01 -1.00872493e+00]\n",
            " [ 8.05928528e-01 -1.09971821e+00]\n",
            " [ 6.39989600e-02 -3.27097028e-01]\n",
            " [-1.03770411e+00  1.12864649e+00]\n",
            " [-1.13715494e+00  1.21599615e+00]\n",
            " [ 9.27309990e-01 -1.11772025e+00]\n",
            " [ 1.15742409e+00 -1.42235065e+00]\n",
            " [-1.21465719e+00  1.37596405e+00]\n",
            " [-1.25479496e+00  1.30677283e+00]\n",
            " [ 7.97210872e-01 -1.08656299e+00]\n",
            " [-1.21780479e+00  1.38347590e+00]\n",
            " [ 1.07470953e+00 -1.35459185e+00]\n",
            " [ 1.12087572e+00 -1.37534249e+00]\n",
            " [-6.92922533e-01  6.27468765e-01]\n",
            " [-9.07267928e-01  9.92479622e-01]\n",
            " [-8.95658493e-01  8.42294931e-01]\n",
            " [ 9.63369131e-01 -1.19068265e+00]\n",
            " [ 1.04357302e+00 -1.34496045e+00]\n",
            " [ 5.84043443e-01 -8.38796914e-01]\n",
            " [-9.33292627e-01  9.40438330e-01]\n",
            " [ 1.14091182e+00 -1.45584941e+00]\n",
            " [ 1.10835373e+00 -1.36978829e+00]\n",
            " [ 9.25081253e-01 -1.18422520e+00]\n",
            " [ 2.81806812e-02 -7.08917528e-02]\n",
            " [ 6.08723044e-01 -8.15732896e-01]\n",
            " [-1.05238497e+00  1.08882892e+00]\n",
            " [-4.22179729e-01  3.53288800e-01]\n",
            " [ 5.59847832e-01 -7.58853316e-01]\n",
            " [-1.29880834e+00  1.54452229e+00]\n",
            " [ 7.61108279e-01 -1.04080307e+00]\n",
            " [-6.06913686e-01  4.89287406e-01]\n",
            " [ 1.16713881e+00 -1.42843401e+00]\n",
            " [-9.31654453e-01  8.78019750e-01]\n",
            " [ 1.13269246e+00 -1.37642992e+00]\n",
            " [ 1.00637245e+00 -1.33546364e+00]\n",
            " [-7.50007480e-03 -1.26571149e-01]\n",
            " [ 1.09761727e+00 -1.37467360e+00]\n",
            " [-3.80451739e-01  1.93237364e-01]\n",
            " [-3.58033836e-01  1.71727568e-01]\n",
            " [-1.08905244e+00  1.15904546e+00]\n",
            " [ 7.56124854e-01 -1.08158338e+00]\n",
            " [-8.44999194e-01  8.42184424e-01]\n",
            " [-2.30199665e-01  7.64577985e-02]\n",
            " [ 6.21595740e-01 -8.40017676e-01]\n",
            " [-6.75668716e-01  7.36119092e-01]\n",
            " [-1.26007450e+00  1.37694275e+00]\n",
            " [-6.86068296e-01  5.35275638e-01]\n",
            " [ 1.11111641e+00 -1.36080539e+00]\n",
            " [-6.30443871e-01  5.08875906e-01]\n",
            " [-1.27277184e+00  1.46237457e+00]\n",
            " [ 4.26053077e-01 -5.96294224e-01]\n",
            " [ 6.16513610e-01 -9.37192976e-01]\n",
            " [ 9.64308619e-01 -1.17983246e+00]\n",
            " [-1.24616015e+00  1.39353836e+00]\n",
            " [ 6.55586004e-01 -8.44339073e-01]\n",
            " [-1.12871206e+00  1.24040902e+00]\n",
            " [ 6.69061899e-01 -9.03881550e-01]\n",
            " [-9.21995223e-01  9.34374750e-01]\n",
            " [-1.07133949e+00  1.18026245e+00]\n",
            " [ 1.09041512e+00 -1.36947775e+00]\n",
            " [ 1.07221878e+00 -1.32428300e+00]\n",
            " [ 1.15473676e+00 -1.44638145e+00]\n",
            " [-8.18763375e-01  8.48754764e-01]\n",
            " [ 1.11272371e+00 -1.41389215e+00]\n",
            " [ 7.84468889e-01 -1.03728139e+00]\n",
            " [-1.16945243e+00  1.32770193e+00]\n",
            " [ 7.99681991e-02 -1.47287354e-01]\n",
            " [ 1.12114441e+00 -1.34674585e+00]\n",
            " [-9.57593858e-01  8.49507689e-01]\n",
            " [-1.23541009e+00  1.47245061e+00]\n",
            " [-9.15666819e-01  1.06162190e+00]\n",
            " [-9.84548450e-01  9.62469041e-01]\n",
            " [ 9.16078150e-01 -1.19311619e+00]\n",
            " [-9.20739830e-01  8.79156113e-01]\n",
            " [ 6.84576452e-01 -9.88383353e-01]\n",
            " [-1.32816327e+00  1.50733638e+00]\n",
            " [ 1.18218553e+00 -1.42260206e+00]\n",
            " [-2.75473148e-01  2.30407923e-01]\n",
            " [-8.78776431e-01  8.55005682e-01]\n",
            " [ 1.11781561e+00 -1.36478055e+00]\n",
            " [ 1.13535273e+00 -1.43416274e+00]\n",
            " [ 1.13349628e+00 -1.39345741e+00]\n",
            " [ 1.14266002e+00 -1.44338298e+00]\n",
            " [-7.18508482e-01  6.62721574e-01]\n",
            " [ 1.06208837e+00 -1.32543147e+00]\n",
            " [ 9.26718354e-01 -1.17470181e+00]\n",
            " [-3.71739864e-01  1.81942493e-01]\n",
            " [-1.19511425e+00  1.34354973e+00]\n",
            " [-3.80529493e-01  2.53247112e-01]\n",
            " [-1.33067083e+00  1.45626688e+00]\n",
            " [-1.31159246e+00  1.50588357e+00]\n",
            " [-1.31324542e+00  1.43869042e+00]\n",
            " [ 1.02580225e+00 -1.26849794e+00]\n",
            " [ 9.75372970e-01 -1.24356616e+00]\n",
            " [ 6.05977535e-01 -8.03869247e-01]\n",
            " [-1.07901251e+00  1.15053380e+00]\n",
            " [ 1.05948579e+00 -1.36418712e+00]\n",
            " [-6.32450938e-01  4.56460714e-01]\n",
            " [ 1.11967123e+00 -1.41123426e+00]\n",
            " [-3.26313555e-01  1.77064896e-01]\n",
            " [ 5.60003698e-01 -8.32592487e-01]\n",
            " [ 1.00189686e+00 -1.22770643e+00]\n",
            " [ 9.56896305e-01 -1.18916738e+00]\n",
            " [ 1.09829521e+00 -1.40479887e+00]\n",
            " [-1.12619030e+00  1.34478486e+00]\n",
            " [ 6.33433819e-01 -8.33094537e-01]\n",
            " [ 4.04995605e-02 -2.97147751e-01]\n",
            " [-1.10022593e+00  1.21490157e+00]\n",
            " [ 9.96197581e-01 -1.26307404e+00]\n",
            " [ 1.05726826e+00 -1.33803546e+00]\n",
            " [ 1.03719413e+00 -1.28329122e+00]\n",
            " [-1.13419974e+00  1.30484235e+00]\n",
            " [-7.30374515e-01  6.86731339e-01]\n",
            " [-1.16003168e+00  1.25274575e+00]\n",
            " [-9.21554685e-01  9.57211196e-01]\n",
            " [-1.67751685e-02  1.06375637e-02]\n",
            " [-1.17123759e+00  1.22096920e+00]\n",
            " [-8.15104246e-01  9.06752050e-01]\n",
            " [-3.20612699e-01  8.46648738e-02]\n",
            " [ 5.29663384e-01 -8.13907981e-01]\n",
            " [-1.20397651e+00  1.17692697e+00]\n",
            " [ 1.08141053e+00 -1.41952670e+00]\n",
            " [-9.99188781e-01  9.33887064e-01]\n",
            " [-1.05858684e+00  1.08380425e+00]\n",
            " [ 6.38681650e-03 -1.40522867e-01]\n",
            " [ 1.16312492e+00 -1.52496231e+00]\n",
            " [ 9.27627325e-01 -1.13494813e+00]\n",
            " [ 8.42206657e-01 -1.12878597e+00]\n",
            " [-7.73257852e-01  7.73560226e-01]\n",
            " [ 9.65873837e-01 -1.23584187e+00]\n",
            " [ 1.16027200e+00 -1.48879910e+00]\n",
            " [-8.63493443e-01  9.03951764e-01]\n",
            " [-1.32544541e+00  1.45099223e+00]\n",
            " [ 1.10175753e+00 -1.35155344e+00]\n",
            " [-1.06424630e+00  1.12592232e+00]\n",
            " [-1.15800583e+00  1.21297109e+00]\n",
            " [ 5.16282737e-01 -8.04655969e-01]\n",
            " [-7.65659392e-01  7.58280754e-01]\n",
            " [-1.23625958e+00  1.33330619e+00]\n",
            " [ 1.13608527e+00 -1.40359962e+00]\n",
            " [-2.02101380e-01  9.04691666e-02]\n",
            " [ 1.12990868e+00 -1.43319404e+00]\n",
            " [-1.09829772e+00  1.18176031e+00]\n",
            " [ 6.47605598e-01 -8.03360164e-01]\n",
            " [ 1.39786184e-01 -4.06730950e-01]\n",
            " [ 1.14201295e+00 -1.41632855e+00]\n",
            " [-1.02480936e+00  1.14443886e+00]\n",
            " [ 1.00865757e+00 -1.23147810e+00]\n",
            " [-1.14448702e+00  1.22101963e+00]\n",
            " [-1.18774319e+00  1.33667052e+00]\n",
            " [ 1.05019891e+00 -1.35179269e+00]\n",
            " [ 7.40765482e-02 -1.51693240e-01]\n",
            " [ 9.04344440e-01 -1.14363420e+00]\n",
            " [ 2.33368725e-01 -4.48231131e-01]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.806 [0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1] [0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1\n",
            " 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0\n",
            " 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1\n",
            " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0]\n",
            "##### labels.shape:  (500,) preds.shape:  (500,)\n",
            "Loading Best\n",
            "Eval (boolq, Val): 100% 22/22 [00:05<00:00,  3.94it/s]\n",
            "##### get_accumulated(), logits :  [[ 0.20340872 -0.3243115 ]\n",
            " [-0.77612776  0.73770964]\n",
            " [ 1.1405991  -1.4050856 ]\n",
            " ...\n",
            " [-0.3696399   0.15868008]\n",
            " [-1.3128535   1.4132428 ]\n",
            " [ 1.0385667  -1.2935535 ]]\n",
            "##### compute_metrics_from_preds_and_labels(), acc:  0.7942857142857143 [0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0] [0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1\n",
            " 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0\n",
            " 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1\n",
            " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0\n",
            " 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1\n",
            " 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1\n",
            " 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0]\n",
            "##### labels.shape:  (700,) preds.shape:  (700,)\n",
            "{\n",
            "  \"aggregated\": 0.7942857142857143,\n",
            "  \"boolq\": {\n",
            "    \"loss\": 0.46348802609877154,\n",
            "    \"metrics\": {\n",
            "      \"major\": 0.7942857142857143,\n",
            "      \"minor\": {\n",
            "        \"acc\": 0.7942857142857143\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "Eval (boolq, Test): 100% 22/22 [00:05<00:00,  3.92it/s]\n",
            "##### get_accumulated(), logits :  [[ 0.26991224 -0.54753166]\n",
            " [ 0.9531948  -1.2071425 ]\n",
            " [ 0.29920033 -0.46159497]\n",
            " ...\n",
            " [ 1.1629688  -1.3989002 ]\n",
            " [-1.2184522   1.412976  ]\n",
            " [ 0.9671186  -1.25714   ]]\n",
            "test_task_list : ['boolq']\n",
            "##### write_preds(), task_name:  boolq 704\n",
            "[0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0\n",
            " 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1\n",
            " 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 0\n",
            " 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
            " 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0\n",
            " 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1\n",
            " 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1\n",
            " 1 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
            " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0\n",
            " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1\n",
            " 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1\n",
            " 0]\n",
            "['test-1' 'test-2' 'test-3' 'test-4' 'test-5' 'test-6' 'test-7' 'test-8'\n",
            " 'test-9' 'test-10' 'test-11' 'test-12' 'test-13' 'test-14' 'test-15'\n",
            " 'test-16' 'test-17' 'test-18' 'test-19' 'test-20' 'test-21' 'test-22'\n",
            " 'test-23' 'test-24' 'test-25' 'test-26' 'test-27' 'test-28' 'test-29'\n",
            " 'test-30' 'test-31' 'test-32' 'test-33' 'test-34' 'test-35' 'test-36'\n",
            " 'test-37' 'test-38' 'test-39' 'test-40' 'test-41' 'test-42' 'test-43'\n",
            " 'test-44' 'test-45' 'test-46' 'test-47' 'test-48' 'test-49' 'test-50'\n",
            " 'test-51' 'test-52' 'test-53' 'test-54' 'test-55' 'test-56' 'test-57'\n",
            " 'test-58' 'test-59' 'test-60' 'test-61' 'test-62' 'test-63' 'test-64'\n",
            " 'test-65' 'test-66' 'test-67' 'test-68' 'test-69' 'test-70' 'test-71'\n",
            " 'test-72' 'test-73' 'test-74' 'test-75' 'test-76' 'test-77' 'test-78'\n",
            " 'test-79' 'test-80' 'test-81' 'test-82' 'test-83' 'test-84' 'test-85'\n",
            " 'test-86' 'test-87' 'test-88' 'test-89' 'test-90' 'test-91' 'test-92'\n",
            " 'test-93' 'test-94' 'test-95' 'test-96' 'test-97' 'test-98' 'test-99'\n",
            " 'test-100' 'test-101' 'test-102' 'test-103' 'test-104' 'test-105'\n",
            " 'test-106' 'test-107' 'test-108' 'test-109' 'test-110' 'test-111'\n",
            " 'test-112' 'test-113' 'test-114' 'test-115' 'test-116' 'test-117'\n",
            " 'test-118' 'test-119' 'test-120' 'test-121' 'test-122' 'test-123'\n",
            " 'test-124' 'test-125' 'test-126' 'test-127' 'test-128' 'test-129'\n",
            " 'test-130' 'test-131' 'test-132' 'test-133' 'test-134' 'test-135'\n",
            " 'test-136' 'test-137' 'test-138' 'test-139' 'test-140' 'test-141'\n",
            " 'test-142' 'test-143' 'test-144' 'test-145' 'test-146' 'test-147'\n",
            " 'test-148' 'test-149' 'test-150' 'test-151' 'test-152' 'test-153'\n",
            " 'test-154' 'test-155' 'test-156' 'test-157' 'test-158' 'test-159'\n",
            " 'test-160' 'test-161' 'test-162' 'test-163' 'test-164' 'test-165'\n",
            " 'test-166' 'test-167' 'test-168' 'test-169' 'test-170' 'test-171'\n",
            " 'test-172' 'test-173' 'test-174' 'test-175' 'test-176' 'test-177'\n",
            " 'test-178' 'test-179' 'test-180' 'test-181' 'test-182' 'test-183'\n",
            " 'test-184' 'test-185' 'test-186' 'test-187' 'test-188' 'test-189'\n",
            " 'test-190' 'test-191' 'test-192' 'test-193' 'test-194' 'test-195'\n",
            " 'test-196' 'test-197' 'test-198' 'test-199' 'test-200' 'test-201'\n",
            " 'test-202' 'test-203' 'test-204' 'test-205' 'test-206' 'test-207'\n",
            " 'test-208' 'test-209' 'test-210' 'test-211' 'test-212' 'test-213'\n",
            " 'test-214' 'test-215' 'test-216' 'test-217' 'test-218' 'test-219'\n",
            " 'test-220' 'test-221' 'test-222' 'test-223' 'test-224' 'test-225'\n",
            " 'test-226' 'test-227' 'test-228' 'test-229' 'test-230' 'test-231'\n",
            " 'test-232' 'test-233' 'test-234' 'test-235' 'test-236' 'test-237'\n",
            " 'test-238' 'test-239' 'test-240' 'test-241' 'test-242' 'test-243'\n",
            " 'test-244' 'test-245' 'test-246' 'test-247' 'test-248' 'test-249'\n",
            " 'test-250' 'test-251' 'test-252' 'test-253' 'test-254' 'test-255'\n",
            " 'test-256' 'test-257' 'test-258' 'test-259' 'test-260' 'test-261'\n",
            " 'test-262' 'test-263' 'test-264' 'test-265' 'test-266' 'test-267'\n",
            " 'test-268' 'test-269' 'test-270' 'test-271' 'test-272' 'test-273'\n",
            " 'test-274' 'test-275' 'test-276' 'test-277' 'test-278' 'test-279'\n",
            " 'test-280' 'test-281' 'test-282' 'test-283' 'test-284' 'test-285'\n",
            " 'test-286' 'test-287' 'test-288' 'test-289' 'test-290' 'test-291'\n",
            " 'test-292' 'test-293' 'test-294' 'test-295' 'test-296' 'test-297'\n",
            " 'test-298' 'test-299' 'test-300' 'test-301' 'test-302' 'test-303'\n",
            " 'test-304' 'test-305' 'test-306' 'test-307' 'test-308' 'test-309'\n",
            " 'test-310' 'test-311' 'test-312' 'test-313' 'test-314' 'test-315'\n",
            " 'test-316' 'test-317' 'test-318' 'test-319' 'test-320' 'test-321'\n",
            " 'test-322' 'test-323' 'test-324' 'test-325' 'test-326' 'test-327'\n",
            " 'test-328' 'test-329' 'test-330' 'test-331' 'test-332' 'test-333'\n",
            " 'test-334' 'test-335' 'test-336' 'test-337' 'test-338' 'test-339'\n",
            " 'test-340' 'test-341' 'test-342' 'test-343' 'test-344' 'test-345'\n",
            " 'test-346' 'test-347' 'test-348' 'test-349' 'test-350' 'test-351'\n",
            " 'test-352' 'test-353' 'test-354' 'test-355' 'test-356' 'test-357'\n",
            " 'test-358' 'test-359' 'test-360' 'test-361' 'test-362' 'test-363'\n",
            " 'test-364' 'test-365' 'test-366' 'test-367' 'test-368' 'test-369'\n",
            " 'test-370' 'test-371' 'test-372' 'test-373' 'test-374' 'test-375'\n",
            " 'test-376' 'test-377' 'test-378' 'test-379' 'test-380' 'test-381'\n",
            " 'test-382' 'test-383' 'test-384' 'test-385' 'test-386' 'test-387'\n",
            " 'test-388' 'test-389' 'test-390' 'test-391' 'test-392' 'test-393'\n",
            " 'test-394' 'test-395' 'test-396' 'test-397' 'test-398' 'test-399'\n",
            " 'test-400' 'test-401' 'test-402' 'test-403' 'test-404' 'test-405'\n",
            " 'test-406' 'test-407' 'test-408' 'test-409' 'test-410' 'test-411'\n",
            " 'test-412' 'test-413' 'test-414' 'test-415' 'test-416' 'test-417'\n",
            " 'test-418' 'test-419' 'test-420' 'test-421' 'test-422' 'test-423'\n",
            " 'test-424' 'test-425' 'test-426' 'test-427' 'test-428' 'test-429'\n",
            " 'test-430' 'test-431' 'test-432' 'test-433' 'test-434' 'test-435'\n",
            " 'test-436' 'test-437' 'test-438' 'test-439' 'test-440' 'test-441'\n",
            " 'test-442' 'test-443' 'test-444' 'test-445' 'test-446' 'test-447'\n",
            " 'test-448' 'test-449' 'test-450' 'test-451' 'test-452' 'test-453'\n",
            " 'test-454' 'test-455' 'test-456' 'test-457' 'test-458' 'test-459'\n",
            " 'test-460' 'test-461' 'test-462' 'test-463' 'test-464' 'test-465'\n",
            " 'test-466' 'test-467' 'test-468' 'test-469' 'test-470' 'test-471'\n",
            " 'test-472' 'test-473' 'test-474' 'test-475' 'test-476' 'test-477'\n",
            " 'test-478' 'test-479' 'test-480' 'test-481' 'test-482' 'test-483'\n",
            " 'test-484' 'test-485' 'test-486' 'test-487' 'test-488' 'test-489'\n",
            " 'test-490' 'test-491' 'test-492' 'test-493' 'test-494' 'test-495'\n",
            " 'test-496' 'test-497' 'test-498' 'test-499' 'test-500' 'test-501'\n",
            " 'test-502' 'test-503' 'test-504' 'test-505' 'test-506' 'test-507'\n",
            " 'test-508' 'test-509' 'test-510' 'test-511' 'test-512' 'test-513'\n",
            " 'test-514' 'test-515' 'test-516' 'test-517' 'test-518' 'test-519'\n",
            " 'test-520' 'test-521' 'test-522' 'test-523' 'test-524' 'test-525'\n",
            " 'test-526' 'test-527' 'test-528' 'test-529' 'test-530' 'test-531'\n",
            " 'test-532' 'test-533' 'test-534' 'test-535' 'test-536' 'test-537'\n",
            " 'test-538' 'test-539' 'test-540' 'test-541' 'test-542' 'test-543'\n",
            " 'test-544' 'test-545' 'test-546' 'test-547' 'test-548' 'test-549'\n",
            " 'test-550' 'test-551' 'test-552' 'test-553' 'test-554' 'test-555'\n",
            " 'test-556' 'test-557' 'test-558' 'test-559' 'test-560' 'test-561'\n",
            " 'test-562' 'test-563' 'test-564' 'test-565' 'test-566' 'test-567'\n",
            " 'test-568' 'test-569' 'test-570' 'test-571' 'test-572' 'test-573'\n",
            " 'test-574' 'test-575' 'test-576' 'test-577' 'test-578' 'test-579'\n",
            " 'test-580' 'test-581' 'test-582' 'test-583' 'test-584' 'test-585'\n",
            " 'test-586' 'test-587' 'test-588' 'test-589' 'test-590' 'test-591'\n",
            " 'test-592' 'test-593' 'test-594' 'test-595' 'test-596' 'test-597'\n",
            " 'test-598' 'test-599' 'test-600' 'test-601' 'test-602' 'test-603'\n",
            " 'test-604' 'test-605' 'test-606' 'test-607' 'test-608' 'test-609'\n",
            " 'test-610' 'test-611' 'test-612' 'test-613' 'test-614' 'test-615'\n",
            " 'test-616' 'test-617' 'test-618' 'test-619' 'test-620' 'test-621'\n",
            " 'test-622' 'test-623' 'test-624' 'test-625' 'test-626' 'test-627'\n",
            " 'test-628' 'test-629' 'test-630' 'test-631' 'test-632' 'test-633'\n",
            " 'test-634' 'test-635' 'test-636' 'test-637' 'test-638' 'test-639'\n",
            " 'test-640' 'test-641' 'test-642' 'test-643' 'test-644' 'test-645'\n",
            " 'test-646' 'test-647' 'test-648' 'test-649' 'test-650' 'test-651'\n",
            " 'test-652' 'test-653' 'test-654' 'test-655' 'test-656' 'test-657'\n",
            " 'test-658' 'test-659' 'test-660' 'test-661' 'test-662' 'test-663'\n",
            " 'test-664' 'test-665' 'test-666' 'test-667' 'test-668' 'test-669'\n",
            " 'test-670' 'test-671' 'test-672' 'test-673' 'test-674' 'test-675'\n",
            " 'test-676' 'test-677' 'test-678' 'test-679' 'test-680' 'test-681'\n",
            " 'test-682' 'test-683' 'test-684' 'test-685' 'test-686' 'test-687'\n",
            " 'test-688' 'test-689' 'test-690' 'test-691' 'test-692' 'test-693'\n",
            " 'test-694' 'test-695' 'test-696' 'test-697' 'test-698' 'test-699'\n",
            " 'test-700' 'test-701' 'test-702' 'test-703' 'test-704']\n",
            "##### preds_dic_list:  [{'idx': 1, 'label': 0}, {'idx': 2, 'label': 0}, {'idx': 3, 'label': 0}, {'idx': 4, 'label': 0}, {'idx': 5, 'label': 1}, {'idx': 6, 'label': 0}, {'idx': 7, 'label': 0}, {'idx': 8, 'label': 1}, {'idx': 9, 'label': 1}, {'idx': 10, 'label': 1}, {'idx': 11, 'label': 1}, {'idx': 12, 'label': 0}, {'idx': 13, 'label': 0}, {'idx': 14, 'label': 1}, {'idx': 15, 'label': 0}, {'idx': 16, 'label': 1}, {'idx': 17, 'label': 0}, {'idx': 18, 'label': 1}, {'idx': 19, 'label': 0}, {'idx': 20, 'label': 1}, {'idx': 21, 'label': 0}, {'idx': 22, 'label': 0}, {'idx': 23, 'label': 1}, {'idx': 24, 'label': 1}, {'idx': 25, 'label': 1}, {'idx': 26, 'label': 1}, {'idx': 27, 'label': 1}, {'idx': 28, 'label': 0}, {'idx': 29, 'label': 1}, {'idx': 30, 'label': 0}, {'idx': 31, 'label': 1}, {'idx': 32, 'label': 0}, {'idx': 33, 'label': 1}, {'idx': 34, 'label': 0}, {'idx': 35, 'label': 1}, {'idx': 36, 'label': 1}, {'idx': 37, 'label': 0}, {'idx': 38, 'label': 0}, {'idx': 39, 'label': 0}, {'idx': 40, 'label': 0}, {'idx': 41, 'label': 1}, {'idx': 42, 'label': 1}, {'idx': 43, 'label': 0}, {'idx': 44, 'label': 0}, {'idx': 45, 'label': 1}, {'idx': 46, 'label': 0}, {'idx': 47, 'label': 1}, {'idx': 48, 'label': 0}, {'idx': 49, 'label': 1}, {'idx': 50, 'label': 1}, {'idx': 51, 'label': 0}, {'idx': 52, 'label': 1}, {'idx': 53, 'label': 1}, {'idx': 54, 'label': 0}, {'idx': 55, 'label': 1}, {'idx': 56, 'label': 1}, {'idx': 57, 'label': 0}, {'idx': 58, 'label': 0}, {'idx': 59, 'label': 0}, {'idx': 60, 'label': 0}, {'idx': 61, 'label': 0}, {'idx': 62, 'label': 1}, {'idx': 63, 'label': 1}, {'idx': 64, 'label': 1}, {'idx': 65, 'label': 1}, {'idx': 66, 'label': 0}, {'idx': 67, 'label': 0}, {'idx': 68, 'label': 1}, {'idx': 69, 'label': 0}, {'idx': 70, 'label': 0}, {'idx': 71, 'label': 0}, {'idx': 72, 'label': 1}, {'idx': 73, 'label': 0}, {'idx': 74, 'label': 0}, {'idx': 75, 'label': 0}, {'idx': 76, 'label': 1}, {'idx': 77, 'label': 0}, {'idx': 78, 'label': 1}, {'idx': 79, 'label': 1}, {'idx': 80, 'label': 0}, {'idx': 81, 'label': 0}, {'idx': 82, 'label': 1}, {'idx': 83, 'label': 0}, {'idx': 84, 'label': 0}, {'idx': 85, 'label': 1}, {'idx': 86, 'label': 1}, {'idx': 87, 'label': 1}, {'idx': 88, 'label': 1}, {'idx': 89, 'label': 1}, {'idx': 90, 'label': 1}, {'idx': 91, 'label': 0}, {'idx': 92, 'label': 1}, {'idx': 93, 'label': 1}, {'idx': 94, 'label': 1}, {'idx': 95, 'label': 0}, {'idx': 96, 'label': 1}, {'idx': 97, 'label': 1}, {'idx': 98, 'label': 0}, {'idx': 99, 'label': 1}, {'idx': 100, 'label': 1}, {'idx': 101, 'label': 0}, {'idx': 102, 'label': 1}, {'idx': 103, 'label': 1}, {'idx': 104, 'label': 1}, {'idx': 105, 'label': 0}, {'idx': 106, 'label': 0}, {'idx': 107, 'label': 0}, {'idx': 108, 'label': 0}, {'idx': 109, 'label': 1}, {'idx': 110, 'label': 1}, {'idx': 111, 'label': 1}, {'idx': 112, 'label': 0}, {'idx': 113, 'label': 0}, {'idx': 114, 'label': 1}, {'idx': 115, 'label': 0}, {'idx': 116, 'label': 0}, {'idx': 117, 'label': 1}, {'idx': 118, 'label': 1}, {'idx': 119, 'label': 1}, {'idx': 120, 'label': 0}, {'idx': 121, 'label': 1}, {'idx': 122, 'label': 1}, {'idx': 123, 'label': 0}, {'idx': 124, 'label': 0}, {'idx': 125, 'label': 0}, {'idx': 126, 'label': 1}, {'idx': 127, 'label': 0}, {'idx': 128, 'label': 1}, {'idx': 129, 'label': 0}, {'idx': 130, 'label': 0}, {'idx': 131, 'label': 0}, {'idx': 132, 'label': 0}, {'idx': 133, 'label': 1}, {'idx': 134, 'label': 0}, {'idx': 135, 'label': 0}, {'idx': 136, 'label': 0}, {'idx': 137, 'label': 1}, {'idx': 138, 'label': 1}, {'idx': 139, 'label': 1}, {'idx': 140, 'label': 0}, {'idx': 141, 'label': 0}, {'idx': 142, 'label': 0}, {'idx': 143, 'label': 1}, {'idx': 144, 'label': 1}, {'idx': 145, 'label': 1}, {'idx': 146, 'label': 0}, {'idx': 147, 'label': 0}, {'idx': 148, 'label': 1}, {'idx': 149, 'label': 1}, {'idx': 150, 'label': 0}, {'idx': 151, 'label': 1}, {'idx': 152, 'label': 1}, {'idx': 153, 'label': 1}, {'idx': 154, 'label': 0}, {'idx': 155, 'label': 0}, {'idx': 156, 'label': 1}, {'idx': 157, 'label': 1}, {'idx': 158, 'label': 1}, {'idx': 159, 'label': 1}, {'idx': 160, 'label': 0}, {'idx': 161, 'label': 0}, {'idx': 162, 'label': 0}, {'idx': 163, 'label': 1}, {'idx': 164, 'label': 0}, {'idx': 165, 'label': 0}, {'idx': 166, 'label': 0}, {'idx': 167, 'label': 1}, {'idx': 168, 'label': 0}, {'idx': 169, 'label': 0}, {'idx': 170, 'label': 0}, {'idx': 171, 'label': 1}, {'idx': 172, 'label': 1}, {'idx': 173, 'label': 1}, {'idx': 174, 'label': 0}, {'idx': 175, 'label': 0}, {'idx': 176, 'label': 0}, {'idx': 177, 'label': 1}, {'idx': 178, 'label': 0}, {'idx': 179, 'label': 0}, {'idx': 180, 'label': 1}, {'idx': 181, 'label': 0}, {'idx': 182, 'label': 0}, {'idx': 183, 'label': 0}, {'idx': 184, 'label': 1}, {'idx': 185, 'label': 0}, {'idx': 186, 'label': 0}, {'idx': 187, 'label': 1}, {'idx': 188, 'label': 1}, {'idx': 189, 'label': 1}, {'idx': 190, 'label': 0}, {'idx': 191, 'label': 0}, {'idx': 192, 'label': 1}, {'idx': 193, 'label': 1}, {'idx': 194, 'label': 1}, {'idx': 195, 'label': 0}, {'idx': 196, 'label': 1}, {'idx': 197, 'label': 0}, {'idx': 198, 'label': 1}, {'idx': 199, 'label': 0}, {'idx': 200, 'label': 0}, {'idx': 201, 'label': 0}, {'idx': 202, 'label': 0}, {'idx': 203, 'label': 0}, {'idx': 204, 'label': 1}, {'idx': 205, 'label': 1}, {'idx': 206, 'label': 0}, {'idx': 207, 'label': 0}, {'idx': 208, 'label': 1}, {'idx': 209, 'label': 0}, {'idx': 210, 'label': 1}, {'idx': 211, 'label': 1}, {'idx': 212, 'label': 1}, {'idx': 213, 'label': 1}, {'idx': 214, 'label': 1}, {'idx': 215, 'label': 0}, {'idx': 216, 'label': 0}, {'idx': 217, 'label': 1}, {'idx': 218, 'label': 0}, {'idx': 219, 'label': 1}, {'idx': 220, 'label': 0}, {'idx': 221, 'label': 0}, {'idx': 222, 'label': 1}, {'idx': 223, 'label': 0}, {'idx': 224, 'label': 1}, {'idx': 225, 'label': 1}, {'idx': 226, 'label': 0}, {'idx': 227, 'label': 0}, {'idx': 228, 'label': 0}, {'idx': 229, 'label': 0}, {'idx': 230, 'label': 1}, {'idx': 231, 'label': 0}, {'idx': 232, 'label': 1}, {'idx': 233, 'label': 0}, {'idx': 234, 'label': 1}, {'idx': 235, 'label': 1}, {'idx': 236, 'label': 0}, {'idx': 237, 'label': 1}, {'idx': 238, 'label': 1}, {'idx': 239, 'label': 0}, {'idx': 240, 'label': 1}, {'idx': 241, 'label': 0}, {'idx': 242, 'label': 0}, {'idx': 243, 'label': 1}, {'idx': 244, 'label': 1}, {'idx': 245, 'label': 0}, {'idx': 246, 'label': 1}, {'idx': 247, 'label': 1}, {'idx': 248, 'label': 1}, {'idx': 249, 'label': 0}, {'idx': 250, 'label': 1}, {'idx': 251, 'label': 0}, {'idx': 252, 'label': 1}, {'idx': 253, 'label': 0}, {'idx': 254, 'label': 0}, {'idx': 255, 'label': 1}, {'idx': 256, 'label': 1}, {'idx': 257, 'label': 0}, {'idx': 258, 'label': 1}, {'idx': 259, 'label': 0}, {'idx': 260, 'label': 0}, {'idx': 261, 'label': 0}, {'idx': 262, 'label': 1}, {'idx': 263, 'label': 1}, {'idx': 264, 'label': 1}, {'idx': 265, 'label': 0}, {'idx': 266, 'label': 0}, {'idx': 267, 'label': 1}, {'idx': 268, 'label': 0}, {'idx': 269, 'label': 0}, {'idx': 270, 'label': 1}, {'idx': 271, 'label': 1}, {'idx': 272, 'label': 0}, {'idx': 273, 'label': 1}, {'idx': 274, 'label': 1}, {'idx': 275, 'label': 0}, {'idx': 276, 'label': 0}, {'idx': 277, 'label': 0}, {'idx': 278, 'label': 0}, {'idx': 279, 'label': 1}, {'idx': 280, 'label': 1}, {'idx': 281, 'label': 1}, {'idx': 282, 'label': 0}, {'idx': 283, 'label': 1}, {'idx': 284, 'label': 1}, {'idx': 285, 'label': 0}, {'idx': 286, 'label': 1}, {'idx': 287, 'label': 1}, {'idx': 288, 'label': 1}, {'idx': 289, 'label': 0}, {'idx': 290, 'label': 1}, {'idx': 291, 'label': 0}, {'idx': 292, 'label': 0}, {'idx': 293, 'label': 0}, {'idx': 294, 'label': 0}, {'idx': 295, 'label': 0}, {'idx': 296, 'label': 0}, {'idx': 297, 'label': 0}, {'idx': 298, 'label': 1}, {'idx': 299, 'label': 1}, {'idx': 300, 'label': 1}, {'idx': 301, 'label': 1}, {'idx': 302, 'label': 1}, {'idx': 303, 'label': 1}, {'idx': 304, 'label': 0}, {'idx': 305, 'label': 0}, {'idx': 306, 'label': 1}, {'idx': 307, 'label': 0}, {'idx': 308, 'label': 1}, {'idx': 309, 'label': 1}, {'idx': 310, 'label': 0}, {'idx': 311, 'label': 1}, {'idx': 312, 'label': 0}, {'idx': 313, 'label': 1}, {'idx': 314, 'label': 0}, {'idx': 315, 'label': 0}, {'idx': 316, 'label': 1}, {'idx': 317, 'label': 0}, {'idx': 318, 'label': 0}, {'idx': 319, 'label': 1}, {'idx': 320, 'label': 1}, {'idx': 321, 'label': 1}, {'idx': 322, 'label': 0}, {'idx': 323, 'label': 1}, {'idx': 324, 'label': 1}, {'idx': 325, 'label': 0}, {'idx': 326, 'label': 0}, {'idx': 327, 'label': 1}, {'idx': 328, 'label': 0}, {'idx': 329, 'label': 1}, {'idx': 330, 'label': 1}, {'idx': 331, 'label': 0}, {'idx': 332, 'label': 0}, {'idx': 333, 'label': 0}, {'idx': 334, 'label': 0}, {'idx': 335, 'label': 0}, {'idx': 336, 'label': 1}, {'idx': 337, 'label': 0}, {'idx': 338, 'label': 1}, {'idx': 339, 'label': 0}, {'idx': 340, 'label': 0}, {'idx': 341, 'label': 1}, {'idx': 342, 'label': 1}, {'idx': 343, 'label': 1}, {'idx': 344, 'label': 0}, {'idx': 345, 'label': 1}, {'idx': 346, 'label': 0}, {'idx': 347, 'label': 1}, {'idx': 348, 'label': 1}, {'idx': 349, 'label': 0}, {'idx': 350, 'label': 1}, {'idx': 351, 'label': 1}, {'idx': 352, 'label': 0}, {'idx': 353, 'label': 0}, {'idx': 354, 'label': 0}, {'idx': 355, 'label': 1}, {'idx': 356, 'label': 1}, {'idx': 357, 'label': 1}, {'idx': 358, 'label': 1}, {'idx': 359, 'label': 1}, {'idx': 360, 'label': 1}, {'idx': 361, 'label': 1}, {'idx': 362, 'label': 0}, {'idx': 363, 'label': 1}, {'idx': 364, 'label': 1}, {'idx': 365, 'label': 0}, {'idx': 366, 'label': 0}, {'idx': 367, 'label': 0}, {'idx': 368, 'label': 0}, {'idx': 369, 'label': 1}, {'idx': 370, 'label': 1}, {'idx': 371, 'label': 0}, {'idx': 372, 'label': 0}, {'idx': 373, 'label': 1}, {'idx': 374, 'label': 1}, {'idx': 375, 'label': 0}, {'idx': 376, 'label': 0}, {'idx': 377, 'label': 0}, {'idx': 378, 'label': 1}, {'idx': 379, 'label': 1}, {'idx': 380, 'label': 1}, {'idx': 381, 'label': 1}, {'idx': 382, 'label': 1}, {'idx': 383, 'label': 0}, {'idx': 384, 'label': 0}, {'idx': 385, 'label': 1}, {'idx': 386, 'label': 0}, {'idx': 387, 'label': 0}, {'idx': 388, 'label': 0}, {'idx': 389, 'label': 1}, {'idx': 390, 'label': 1}, {'idx': 391, 'label': 0}, {'idx': 392, 'label': 1}, {'idx': 393, 'label': 0}, {'idx': 394, 'label': 1}, {'idx': 395, 'label': 0}, {'idx': 396, 'label': 1}, {'idx': 397, 'label': 1}, {'idx': 398, 'label': 0}, {'idx': 399, 'label': 1}, {'idx': 400, 'label': 1}, {'idx': 401, 'label': 1}, {'idx': 402, 'label': 1}, {'idx': 403, 'label': 1}, {'idx': 404, 'label': 1}, {'idx': 405, 'label': 1}, {'idx': 406, 'label': 0}, {'idx': 407, 'label': 1}, {'idx': 408, 'label': 1}, {'idx': 409, 'label': 0}, {'idx': 410, 'label': 1}, {'idx': 411, 'label': 0}, {'idx': 412, 'label': 0}, {'idx': 413, 'label': 1}, {'idx': 414, 'label': 0}, {'idx': 415, 'label': 1}, {'idx': 416, 'label': 0}, {'idx': 417, 'label': 1}, {'idx': 418, 'label': 0}, {'idx': 419, 'label': 1}, {'idx': 420, 'label': 0}, {'idx': 421, 'label': 0}, {'idx': 422, 'label': 1}, {'idx': 423, 'label': 0}, {'idx': 424, 'label': 0}, {'idx': 425, 'label': 1}, {'idx': 426, 'label': 1}, {'idx': 427, 'label': 1}, {'idx': 428, 'label': 1}, {'idx': 429, 'label': 1}, {'idx': 430, 'label': 0}, {'idx': 431, 'label': 1}, {'idx': 432, 'label': 0}, {'idx': 433, 'label': 0}, {'idx': 434, 'label': 0}, {'idx': 435, 'label': 0}, {'idx': 436, 'label': 1}, {'idx': 437, 'label': 1}, {'idx': 438, 'label': 1}, {'idx': 439, 'label': 1}, {'idx': 440, 'label': 0}, {'idx': 441, 'label': 0}, {'idx': 442, 'label': 0}, {'idx': 443, 'label': 0}, {'idx': 444, 'label': 1}, {'idx': 445, 'label': 1}, {'idx': 446, 'label': 0}, {'idx': 447, 'label': 0}, {'idx': 448, 'label': 0}, {'idx': 449, 'label': 0}, {'idx': 450, 'label': 0}, {'idx': 451, 'label': 0}, {'idx': 452, 'label': 1}, {'idx': 453, 'label': 1}, {'idx': 454, 'label': 1}, {'idx': 455, 'label': 0}, {'idx': 456, 'label': 1}, {'idx': 457, 'label': 1}, {'idx': 458, 'label': 1}, {'idx': 459, 'label': 1}, {'idx': 460, 'label': 1}, {'idx': 461, 'label': 1}, {'idx': 462, 'label': 0}, {'idx': 463, 'label': 0}, {'idx': 464, 'label': 1}, {'idx': 465, 'label': 0}, {'idx': 466, 'label': 0}, {'idx': 467, 'label': 0}, {'idx': 468, 'label': 1}, {'idx': 469, 'label': 0}, {'idx': 470, 'label': 0}, {'idx': 471, 'label': 0}, {'idx': 472, 'label': 0}, {'idx': 473, 'label': 1}, {'idx': 474, 'label': 0}, {'idx': 475, 'label': 0}, {'idx': 476, 'label': 0}, {'idx': 477, 'label': 1}, {'idx': 478, 'label': 0}, {'idx': 479, 'label': 1}, {'idx': 480, 'label': 1}, {'idx': 481, 'label': 1}, {'idx': 482, 'label': 0}, {'idx': 483, 'label': 0}, {'idx': 484, 'label': 0}, {'idx': 485, 'label': 1}, {'idx': 486, 'label': 0}, {'idx': 487, 'label': 1}, {'idx': 488, 'label': 1}, {'idx': 489, 'label': 1}, {'idx': 490, 'label': 0}, {'idx': 491, 'label': 0}, {'idx': 492, 'label': 1}, {'idx': 493, 'label': 0}, {'idx': 494, 'label': 1}, {'idx': 495, 'label': 1}, {'idx': 496, 'label': 1}, {'idx': 497, 'label': 1}, {'idx': 498, 'label': 1}, {'idx': 499, 'label': 0}, {'idx': 500, 'label': 0}, {'idx': 501, 'label': 0}, {'idx': 502, 'label': 0}, {'idx': 503, 'label': 0}, {'idx': 504, 'label': 0}, {'idx': 505, 'label': 0}, {'idx': 506, 'label': 0}, {'idx': 507, 'label': 0}, {'idx': 508, 'label': 0}, {'idx': 509, 'label': 1}, {'idx': 510, 'label': 0}, {'idx': 511, 'label': 1}, {'idx': 512, 'label': 0}, {'idx': 513, 'label': 0}, {'idx': 514, 'label': 1}, {'idx': 515, 'label': 1}, {'idx': 516, 'label': 0}, {'idx': 517, 'label': 1}, {'idx': 518, 'label': 0}, {'idx': 519, 'label': 1}, {'idx': 520, 'label': 1}, {'idx': 521, 'label': 0}, {'idx': 522, 'label': 1}, {'idx': 523, 'label': 1}, {'idx': 524, 'label': 1}, {'idx': 525, 'label': 1}, {'idx': 526, 'label': 1}, {'idx': 527, 'label': 0}, {'idx': 528, 'label': 0}, {'idx': 529, 'label': 0}, {'idx': 530, 'label': 1}, {'idx': 531, 'label': 0}, {'idx': 532, 'label': 1}, {'idx': 533, 'label': 1}, {'idx': 534, 'label': 1}, {'idx': 535, 'label': 0}, {'idx': 536, 'label': 1}, {'idx': 537, 'label': 0}, {'idx': 538, 'label': 0}, {'idx': 539, 'label': 1}, {'idx': 540, 'label': 0}, {'idx': 541, 'label': 0}, {'idx': 542, 'label': 0}, {'idx': 543, 'label': 0}, {'idx': 544, 'label': 0}, {'idx': 545, 'label': 0}, {'idx': 546, 'label': 0}, {'idx': 547, 'label': 1}, {'idx': 548, 'label': 0}, {'idx': 549, 'label': 0}, {'idx': 550, 'label': 1}, {'idx': 551, 'label': 0}, {'idx': 552, 'label': 1}, {'idx': 553, 'label': 0}, {'idx': 554, 'label': 1}, {'idx': 555, 'label': 0}, {'idx': 556, 'label': 0}, {'idx': 557, 'label': 1}, {'idx': 558, 'label': 1}, {'idx': 559, 'label': 0}, {'idx': 560, 'label': 0}, {'idx': 561, 'label': 0}, {'idx': 562, 'label': 0}, {'idx': 563, 'label': 0}, {'idx': 564, 'label': 0}, {'idx': 565, 'label': 0}, {'idx': 566, 'label': 1}, {'idx': 567, 'label': 0}, {'idx': 568, 'label': 0}, {'idx': 569, 'label': 0}, {'idx': 570, 'label': 1}, {'idx': 571, 'label': 0}, {'idx': 572, 'label': 0}, {'idx': 573, 'label': 1}, {'idx': 574, 'label': 1}, {'idx': 575, 'label': 1}, {'idx': 576, 'label': 1}, {'idx': 577, 'label': 1}, {'idx': 578, 'label': 0}, {'idx': 579, 'label': 0}, {'idx': 580, 'label': 1}, {'idx': 581, 'label': 0}, {'idx': 582, 'label': 0}, {'idx': 583, 'label': 1}, {'idx': 584, 'label': 1}, {'idx': 585, 'label': 0}, {'idx': 586, 'label': 0}, {'idx': 587, 'label': 0}, {'idx': 588, 'label': 1}, {'idx': 589, 'label': 1}, {'idx': 590, 'label': 1}, {'idx': 591, 'label': 0}, {'idx': 592, 'label': 1}, {'idx': 593, 'label': 0}, {'idx': 594, 'label': 0}, {'idx': 595, 'label': 0}, {'idx': 596, 'label': 0}, {'idx': 597, 'label': 0}, {'idx': 598, 'label': 1}, {'idx': 599, 'label': 1}, {'idx': 600, 'label': 1}, {'idx': 601, 'label': 1}, {'idx': 602, 'label': 1}, {'idx': 603, 'label': 1}, {'idx': 604, 'label': 1}, {'idx': 605, 'label': 0}, {'idx': 606, 'label': 1}, {'idx': 607, 'label': 1}, {'idx': 608, 'label': 1}, {'idx': 609, 'label': 0}, {'idx': 610, 'label': 1}, {'idx': 611, 'label': 0}, {'idx': 612, 'label': 0}, {'idx': 613, 'label': 0}, {'idx': 614, 'label': 0}, {'idx': 615, 'label': 0}, {'idx': 616, 'label': 0}, {'idx': 617, 'label': 0}, {'idx': 618, 'label': 1}, {'idx': 619, 'label': 1}, {'idx': 620, 'label': 1}, {'idx': 621, 'label': 0}, {'idx': 622, 'label': 0}, {'idx': 623, 'label': 1}, {'idx': 624, 'label': 1}, {'idx': 625, 'label': 1}, {'idx': 626, 'label': 1}, {'idx': 627, 'label': 0}, {'idx': 628, 'label': 0}, {'idx': 629, 'label': 0}, {'idx': 630, 'label': 0}, {'idx': 631, 'label': 0}, {'idx': 632, 'label': 0}, {'idx': 633, 'label': 0}, {'idx': 634, 'label': 0}, {'idx': 635, 'label': 0}, {'idx': 636, 'label': 1}, {'idx': 637, 'label': 0}, {'idx': 638, 'label': 1}, {'idx': 639, 'label': 0}, {'idx': 640, 'label': 0}, {'idx': 641, 'label': 0}, {'idx': 642, 'label': 0}, {'idx': 643, 'label': 0}, {'idx': 644, 'label': 1}, {'idx': 645, 'label': 1}, {'idx': 646, 'label': 1}, {'idx': 647, 'label': 0}, {'idx': 648, 'label': 0}, {'idx': 649, 'label': 1}, {'idx': 650, 'label': 0}, {'idx': 651, 'label': 0}, {'idx': 652, 'label': 0}, {'idx': 653, 'label': 1}, {'idx': 654, 'label': 1}, {'idx': 655, 'label': 1}, {'idx': 656, 'label': 1}, {'idx': 657, 'label': 1}, {'idx': 658, 'label': 0}, {'idx': 659, 'label': 0}, {'idx': 660, 'label': 0}, {'idx': 661, 'label': 1}, {'idx': 662, 'label': 0}, {'idx': 663, 'label': 0}, {'idx': 664, 'label': 1}, {'idx': 665, 'label': 0}, {'idx': 666, 'label': 1}, {'idx': 667, 'label': 0}, {'idx': 668, 'label': 0}, {'idx': 669, 'label': 1}, {'idx': 670, 'label': 0}, {'idx': 671, 'label': 1}, {'idx': 672, 'label': 1}, {'idx': 673, 'label': 0}, {'idx': 674, 'label': 0}, {'idx': 675, 'label': 0}, {'idx': 676, 'label': 1}, {'idx': 677, 'label': 1}, {'idx': 678, 'label': 0}, {'idx': 679, 'label': 0}, {'idx': 680, 'label': 0}, {'idx': 681, 'label': 1}, {'idx': 682, 'label': 0}, {'idx': 683, 'label': 0}, {'idx': 684, 'label': 0}, {'idx': 685, 'label': 1}, {'idx': 686, 'label': 0}, {'idx': 687, 'label': 0}, {'idx': 688, 'label': 1}, {'idx': 689, 'label': 0}, {'idx': 690, 'label': 0}, {'idx': 691, 'label': 0}, {'idx': 692, 'label': 1}, {'idx': 693, 'label': 0}, {'idx': 694, 'label': 0}, {'idx': 695, 'label': 1}, {'idx': 696, 'label': 1}, {'idx': 697, 'label': 0}, {'idx': 698, 'label': 1}, {'idx': 699, 'label': 1}, {'idx': 700, 'label': 1}, {'idx': 701, 'label': 0}, {'idx': 702, 'label': 0}, {'idx': 703, 'label': 1}, {'idx': 704, 'label': 0}]\n",
            "##### write_json to :  /content/jiant-rev/exp/runs/simple/test_preds.p.boolq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLRZs9-EDjtG",
        "outputId": "fcf4d720-f667-4c8f-976c-61223363315d"
      },
      "source": [
        "!python merge_predict_all.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task results added :  cola 1060\n",
            "task results added :  copa 500\n",
            "task results added :  wic 1246\n",
            "task results added :  boolq 704\n",
            "write to output_flle :  ./test_preds.p.ALL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwKdqXtVQvdx",
        "outputId": "d23df15a-10c0-49d5-de22-9abd0e9076b2"
      },
      "source": [
        "# Task 별 소스 통합\n",
        "# 한번에 전체 Task 수행 (cola, copa, wic, boolq)\n",
        "!python ./run_task_all.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "##### unique_key :  ((768, 768), 140129652178944)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897273856)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129654538240)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897276928)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897280000)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897283072)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129656897536)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897286144)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129683374080)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897298432)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897301504)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897304576)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129666334720)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897307648)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129692811264)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897310720)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129695170560)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897313792)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129697529856)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897316864)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897319936)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897323008)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129716928512)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897326080)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129726365696)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897338368)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897341440)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897344512)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129699889152)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897347584)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129750482944)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897350656)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129752842240)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897353728)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129755201536)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897356800)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897359872)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897362944)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129757560832)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897366016)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129784037376)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897378304)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897381376)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897384448)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129766998016)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897387520)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129793474560)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897390592)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129795833856)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897393664)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129798193152)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897396736)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897399808)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897402880)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129817591808)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897405952)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129827028992)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897418240)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897421312)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897424384)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129800552448)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897427456)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129851146240)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897430528)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129853505536)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897433600)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129855864832)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897436672)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897439744)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897442816)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129858224128)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897445888)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129884700672)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897458176)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897461248)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897464320)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129867661312)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897467392)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129894137856)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897470464)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129896497152)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897473536)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129898856448)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897476608)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897479680)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897482752)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129918255104)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897485824)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129927692288)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897498112)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897501184)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897504256)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129901215744)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897507328)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129951809536)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897510400)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129954168832)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897513472)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129956528128)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897516544)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897519616)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897522688)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129958887424)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897525760)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129985363968)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897538048)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897541120)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897544192)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129968324608)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897547264)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129994801152)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897550336)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129997160448)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897553408)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129999519744)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897556480)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897559552)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897562624)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130018918400)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897565696)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130028355584)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897577984)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897581056)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897584128)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130001879040)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897587200)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129381384192)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897590272)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129383743488)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897593344)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129386102784)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897596416)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897599488)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897602560)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129388462080)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140132897605632)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129347829760)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897617920)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897620992)\n",
            "##### k, v.shape :  taskmodels_dict.cola.encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897624064)\n",
            "##### k, v.shape :  taskmodels_dict.cola.head.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129397899264)\n",
            "##### k, v.shape :  taskmodels_dict.cola.head.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140132897627136)\n",
            "##### k, v.shape :  taskmodels_dict.cola.head.out_proj.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140132897630208)\n",
            "##### k, v.shape :  taskmodels_dict.cola.head.out_proj.bias torch.Size([2])\n",
            "##### unique_key :  ((2,), 140131719707136)\n",
            "Eval (cola, Val): 100% 16/16 [00:00<00:00, 25.58it/s]\n",
            "Loading Best\n",
            "Eval (cola, Val): 100% 64/64 [00:02<00:00, 28.27it/s]\n",
            "{\n",
            "  \"aggregated\": 0.5309048374943173,\n",
            "  \"cola\": {\n",
            "    \"loss\": 0.6329665156081319,\n",
            "    \"metrics\": {\n",
            "      \"major\": 0.5309048374943173,\n",
            "      \"minor\": {\n",
            "        \"mcc\": 0.5309048374943173\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "Eval (cola, Test): 100% 34/34 [00:01<00:00, 28.27it/s]\n",
            "test_task_list : ['cola']\n",
            "##### write_preds(), task_name:  cola 1060\n",
            "##### write_json to :  exp/runs/simple/test_preds.p.cola\n",
            "##### hf_datasets_tasks_download, task_name:  copa , task_data_path:  /content/jiant-rev/exp/tasks/data/copa\n",
            "##### load_dataset(), path= super_glue , name= copa\n",
            "##### is_ko_model :  True\n",
            "Using custom data configuration default-46692d2fe92e6b7c\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-46692d2fe92e6b7c/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n",
            "100% 3/3 [00:00<00:00, 9868.95it/s]\n",
            "100% 3/3 [00:00<00:00, 1067.16it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-46692d2fe92e6b7c/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 851.87it/s]\n",
            "Downloaded and generated configs for 'copa' (1/1)\n",
            "##### run_simple(): Tokenizing Task 'copa' for phases 'train,val,test'\n",
            "CopaTask\n",
            "  [train]: /content/jiant-rev/exp/tasks/data/copa/train.jsonl\n",
            "  [val]: /content/jiant-rev/exp/tasks/data/copa/val.jsonl\n",
            "  [test]: /content/jiant-rev/exp/tasks/data/copa/test.jsonl\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "Tokenizing: 100% 3080/3080 [00:03<00:00, 972.85it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 3080/3080 [00:00<00:00, 86236.30it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  1.64it/s]\n",
            "Tokenizing: 100% 500/500 [00:00<00:00, 1149.90it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 500/500 [00:00<00:00, 89575.94it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00, 10.62it/s]\n",
            "Tokenizing: 100% 500/500 [00:00<00:00, 1213.65it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 500/500 [00:00<00:00, 100361.41it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00, 11.76it/s]\n",
            "Running from start\n",
            "  jiant_task_container_config_path: exp/run_configs/simple_config.json\n",
            "  output_dir: exp/runs/simple\n",
            "  hf_pretrained_model_name_or_path: monologg/koelectra-base-v3-discriminator\n",
            "  model_path: exp/models/electra/model/model.p\n",
            "  model_config_path: exp/models/electra/model/config.json\n",
            "  model_load_mode: from_transformers\n",
            "  do_train: True\n",
            "  do_val: True\n",
            "  do_save: False\n",
            "  do_save_last: False\n",
            "  do_save_best: False\n",
            "  write_val_preds: False\n",
            "  write_test_preds: True\n",
            "  eval_every_steps: 0\n",
            "  save_every_steps: 0\n",
            "  save_checkpoint_every_steps: 0\n",
            "  no_improvements_for_n_evals: 0\n",
            "  keep_checkpoint_when_done: False\n",
            "  force_overwrite: False\n",
            "  seed: -1\n",
            "  learning_rate: 1e-05\n",
            "  adam_epsilon: 1e-08\n",
            "  max_grad_norm: 1.0\n",
            "  optimizer_type: adam\n",
            "  no_cuda: False\n",
            "  fp16: False\n",
            "  fp16_opt_level: O1\n",
            "  local_rank: -1\n",
            "  server_ip: \n",
            "  server_port: \n",
            "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Using seed: 1148897573\n",
            "{\n",
            "  \"jiant_task_container_config_path\": \"exp/run_configs/simple_config.json\",\n",
            "  \"output_dir\": \"exp/runs/simple\",\n",
            "  \"hf_pretrained_model_name_or_path\": \"monologg/koelectra-base-v3-discriminator\",\n",
            "  \"model_path\": \"exp/models/electra/model/model.p\",\n",
            "  \"model_config_path\": \"exp/models/electra/model/config.json\",\n",
            "  \"model_load_mode\": \"from_transformers\",\n",
            "  \"do_train\": true,\n",
            "  \"do_val\": true,\n",
            "  \"do_save\": false,\n",
            "  \"do_save_last\": false,\n",
            "  \"do_save_best\": false,\n",
            "  \"write_val_preds\": false,\n",
            "  \"write_test_preds\": true,\n",
            "  \"eval_every_steps\": 0,\n",
            "  \"save_every_steps\": 0,\n",
            "  \"save_checkpoint_every_steps\": 0,\n",
            "  \"no_improvements_for_n_evals\": 0,\n",
            "  \"keep_checkpoint_when_done\": false,\n",
            "  \"force_overwrite\": false,\n",
            "  \"seed\": 1148897573,\n",
            "  \"learning_rate\": 1e-05,\n",
            "  \"adam_epsilon\": 1e-08,\n",
            "  \"max_grad_norm\": 1.0,\n",
            "  \"optimizer_type\": \"adam\",\n",
            "  \"no_cuda\": false,\n",
            "  \"fp16\": false,\n",
            "  \"fp16_opt_level\": \"O1\",\n",
            "  \"local_rank\": -1,\n",
            "  \"server_ip\": \"\",\n",
            "  \"server_port\": \"\"\n",
            "}\n",
            "1\n",
            "Creating Tasks:\n",
            "    copa (CopaTask): exp/tasks/configs/copa_config.json\n",
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "##### encoder_prefix: electra.\n",
            "##### k :  electra.embeddings.position_ids\n",
            "##### k :  electra.embeddings.word_embeddings.weight\n",
            "##### k :  electra.embeddings.position_embeddings.weight\n",
            "##### k :  electra.embeddings.token_type_embeddings.weight\n",
            "##### k :  electra.embeddings.LayerNorm.weight\n",
            "##### k :  electra.embeddings.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.bias\n",
            "##### k :  discriminator_predictions.dense.weight\n",
            "##### k :  discriminator_predictions.dense.bias\n",
            "##### k :  discriminator_predictions.dense_prediction.weight\n",
            "##### k :  discriminator_predictions.dense_prediction.bias\n",
            "No optimizer decay for:\n",
            "  encoder.embeddings.LayerNorm.weight\n",
            "  encoder.embeddings.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.attention.self.query.bias\n",
            "  encoder.encoder.layer.0.attention.self.key.bias\n",
            "  encoder.encoder.layer.0.attention.self.value.bias\n",
            "  encoder.encoder.layer.0.attention.output.dense.bias\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.intermediate.dense.bias\n",
            "  encoder.encoder.layer.0.output.dense.bias\n",
            "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.attention.self.query.bias\n",
            "  encoder.encoder.layer.1.attention.self.key.bias\n",
            "  encoder.encoder.layer.1.attention.self.value.bias\n",
            "  encoder.encoder.layer.1.attention.output.dense.bias\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.intermediate.dense.bias\n",
            "  encoder.encoder.layer.1.output.dense.bias\n",
            "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.attention.self.query.bias\n",
            "  encoder.encoder.layer.2.attention.self.key.bias\n",
            "  encoder.encoder.layer.2.attention.self.value.bias\n",
            "  encoder.encoder.layer.2.attention.output.dense.bias\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.intermediate.dense.bias\n",
            "  encoder.encoder.layer.2.output.dense.bias\n",
            "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.attention.self.query.bias\n",
            "  encoder.encoder.layer.3.attention.self.key.bias\n",
            "  encoder.encoder.layer.3.attention.self.value.bias\n",
            "  encoder.encoder.layer.3.attention.output.dense.bias\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.intermediate.dense.bias\n",
            "  encoder.encoder.layer.3.output.dense.bias\n",
            "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.attention.self.query.bias\n",
            "  encoder.encoder.layer.4.attention.self.key.bias\n",
            "  encoder.encoder.layer.4.attention.self.value.bias\n",
            "  encoder.encoder.layer.4.attention.output.dense.bias\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.intermediate.dense.bias\n",
            "  encoder.encoder.layer.4.output.dense.bias\n",
            "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.attention.self.query.bias\n",
            "  encoder.encoder.layer.5.attention.self.key.bias\n",
            "  encoder.encoder.layer.5.attention.self.value.bias\n",
            "  encoder.encoder.layer.5.attention.output.dense.bias\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.intermediate.dense.bias\n",
            "  encoder.encoder.layer.5.output.dense.bias\n",
            "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.attention.self.query.bias\n",
            "  encoder.encoder.layer.6.attention.self.key.bias\n",
            "  encoder.encoder.layer.6.attention.self.value.bias\n",
            "  encoder.encoder.layer.6.attention.output.dense.bias\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.intermediate.dense.bias\n",
            "  encoder.encoder.layer.6.output.dense.bias\n",
            "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.attention.self.query.bias\n",
            "  encoder.encoder.layer.7.attention.self.key.bias\n",
            "  encoder.encoder.layer.7.attention.self.value.bias\n",
            "  encoder.encoder.layer.7.attention.output.dense.bias\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.intermediate.dense.bias\n",
            "  encoder.encoder.layer.7.output.dense.bias\n",
            "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.attention.self.query.bias\n",
            "  encoder.encoder.layer.8.attention.self.key.bias\n",
            "  encoder.encoder.layer.8.attention.self.value.bias\n",
            "  encoder.encoder.layer.8.attention.output.dense.bias\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.intermediate.dense.bias\n",
            "  encoder.encoder.layer.8.output.dense.bias\n",
            "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.attention.self.query.bias\n",
            "  encoder.encoder.layer.9.attention.self.key.bias\n",
            "  encoder.encoder.layer.9.attention.self.value.bias\n",
            "  encoder.encoder.layer.9.attention.output.dense.bias\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.intermediate.dense.bias\n",
            "  encoder.encoder.layer.9.output.dense.bias\n",
            "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.attention.self.query.bias\n",
            "  encoder.encoder.layer.10.attention.self.key.bias\n",
            "  encoder.encoder.layer.10.attention.self.value.bias\n",
            "  encoder.encoder.layer.10.attention.output.dense.bias\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.intermediate.dense.bias\n",
            "  encoder.encoder.layer.10.output.dense.bias\n",
            "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.attention.self.query.bias\n",
            "  encoder.encoder.layer.11.attention.self.key.bias\n",
            "  encoder.encoder.layer.11.attention.self.value.bias\n",
            "  encoder.encoder.layer.11.attention.output.dense.bias\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.intermediate.dense.bias\n",
            "  encoder.encoder.layer.11.output.dense.bias\n",
            "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
            "  taskmodels_dict.copa.head.dense.bias\n",
            "  taskmodels_dict.copa.head.out_proj.bias\n",
            "Using AdamW\n",
            "##### do_train #####\n",
            "##### run_train_context() #####\n",
            "##### get_train_dataloader_dict() :  1\n",
            "Training: 100% 578/579 [01:34<00:00,  6.12it/s]\n",
            "Eval (copa, Val): 100% 16/16 [00:01<00:00, 13.77it/s]\n",
            "##### k, v.shape :  encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140129712701440)\n",
            "##### k, v.shape :  encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140128609632256)\n",
            "##### k, v.shape :  encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140130167291904)\n",
            "##### k, v.shape :  encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140129712705536)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712695296)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712711680)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130632335360)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712714752)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130200846336)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712717824)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130603499520)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712720896)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130670608384)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712723968)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712727040)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712730112)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132410720256)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524496896)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140128987119616)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524509184)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524512256)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524515328)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130804826112)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524518400)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131148759040)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524521472)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131643686912)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524524544)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130102542336)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524527616)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524530688)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524533760)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140128996556800)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524536832)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129012285440)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524549120)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524552192)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524555264)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130370977792)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524558336)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130505195520)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524561408)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130706522112)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524564480)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130840739840)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524567552)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524570624)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524573696)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129021722624)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524576768)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129045839872)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524589056)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524592128)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524595200)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131545382912)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524598272)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132379525120)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524601344)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132381884416)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524604416)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132384243712)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524607488)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524610560)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524613632)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129055277056)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524616704)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129079394304)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524628992)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524632064)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524635136)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129088831488)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524638208)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129091190784)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524641280)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129093550080)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524644352)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129095909376)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524647424)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524650496)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524653568)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129112948736)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524656640)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129122385920)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524668928)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524672000)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524675072)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129146503168)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524678144)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129148862464)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524681216)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129151221760)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524684288)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129153581056)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524687360)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524690432)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524693504)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129155940352)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524696576)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129180057600)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524708864)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524711936)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524715008)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129189494784)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524718080)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129191854080)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524721152)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129194213376)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524724224)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129196572672)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524727296)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524730368)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524733440)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129213612032)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524736512)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129223049216)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524748800)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524751872)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524754944)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129247166464)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524758016)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129249525760)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524761088)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129251885056)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524764160)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129254244352)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524767232)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524770304)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524773376)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129256603648)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524776448)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129280720896)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524788736)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524791808)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524794880)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129290158080)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524797952)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129292517376)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524801024)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129294876672)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524804096)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129297235968)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524807168)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524810240)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524813312)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132468391936)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524816384)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140132477829120)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524828672)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524831744)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524834816)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132501946368)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524837888)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132504305664)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524840960)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132506664960)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524844032)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132509024256)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524847104)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524850176)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524853248)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132511383552)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524856320)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140132535500800)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524868608)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524871680)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524874752)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132544937984)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524877824)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132547297280)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524880896)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132549656576)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524883968)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132552015872)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524887040)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524890112)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524893184)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132569055232)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524896256)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140132578492416)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524908544)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524911616)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524914688)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132602609664)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524917760)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132604968960)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524920832)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132607328256)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524923904)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132609687552)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524926976)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524930048)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524933120)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132612046848)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524936192)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140133013651456)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524948480)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524951552)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524954624)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140129712701440)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140128609632256)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140130167291904)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140129712705536)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712695296)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712711680)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130632335360)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712714752)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130200846336)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712717824)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130603499520)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712720896)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130670608384)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712723968)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712727040)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129712730112)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132410720256)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524496896)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140128987119616)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524509184)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524512256)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524515328)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130804826112)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524518400)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131148759040)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524521472)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131643686912)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524524544)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130102542336)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524527616)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524530688)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524533760)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140128996556800)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524536832)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129012285440)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524549120)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524552192)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524555264)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130370977792)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524558336)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130505195520)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524561408)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130706522112)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524564480)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130840739840)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524567552)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524570624)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524573696)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129021722624)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524576768)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129045839872)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524589056)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524592128)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524595200)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131545382912)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524598272)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132379525120)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524601344)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132381884416)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524604416)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132384243712)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524607488)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524610560)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524613632)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129055277056)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524616704)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129079394304)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524628992)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524632064)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524635136)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129088831488)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524638208)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129091190784)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524641280)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129093550080)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524644352)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129095909376)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524647424)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524650496)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524653568)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129112948736)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524656640)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129122385920)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524668928)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524672000)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524675072)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129146503168)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524678144)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129148862464)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524681216)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129151221760)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524684288)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129153581056)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524687360)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524690432)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524693504)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129155940352)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524696576)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129180057600)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524708864)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524711936)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524715008)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129189494784)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524718080)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129191854080)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524721152)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129194213376)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524724224)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129196572672)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524727296)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524730368)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524733440)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129213612032)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524736512)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129223049216)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524748800)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524751872)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524754944)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129247166464)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524758016)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129249525760)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524761088)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129251885056)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524764160)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129254244352)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524767232)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524770304)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524773376)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129256603648)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524776448)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129280720896)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524788736)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524791808)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524794880)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129290158080)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524797952)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129292517376)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524801024)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129294876672)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524804096)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129297235968)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524807168)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524810240)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524813312)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132468391936)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524816384)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140132477829120)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524828672)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524831744)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524834816)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132501946368)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524837888)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132504305664)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524840960)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132506664960)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524844032)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132509024256)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524847104)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524850176)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524853248)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132511383552)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524856320)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140132535500800)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524868608)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524871680)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524874752)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132544937984)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524877824)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132547297280)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524880896)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132549656576)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524883968)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132552015872)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524887040)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524890112)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524893184)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132569055232)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524896256)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140132578492416)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524908544)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524911616)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524914688)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132602609664)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524917760)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132604968960)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524920832)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132607328256)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524923904)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132609687552)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524926976)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524930048)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524933120)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132612046848)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140129524936192)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140133013651456)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524948480)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524951552)\n",
            "##### k, v.shape :  taskmodels_dict.copa.encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524954624)\n",
            "##### k, v.shape :  taskmodels_dict.copa.head.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140133023088640)\n",
            "##### k, v.shape :  taskmodels_dict.copa.head.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140129524957696)\n",
            "##### k, v.shape :  taskmodels_dict.copa.head.out_proj.weight torch.Size([1, 768])\n",
            "##### unique_key :  ((1, 768), 140129524960768)\n",
            "##### k, v.shape :  taskmodels_dict.copa.head.out_proj.bias torch.Size([1])\n",
            "##### unique_key :  ((1,), 140129672887808)\n",
            "Eval (copa, Val): 100% 16/16 [00:01<00:00, 13.82it/s]\n",
            "Loading Best\n",
            "Eval (copa, Val): 100% 16/16 [00:01<00:00, 12.22it/s]\n",
            "{\n",
            "  \"aggregated\": 0.85,\n",
            "  \"copa\": {\n",
            "    \"loss\": 0.3846079553477466,\n",
            "    \"metrics\": {\n",
            "      \"major\": 0.85,\n",
            "      \"minor\": {\n",
            "        \"acc\": 0.85\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "Eval (copa, Test): 100% 16/16 [00:01<00:00, 12.03it/s]\n",
            "test_task_list : ['copa']\n",
            "##### write_preds(), task_name:  copa 500\n",
            "##### write_json to :  exp/runs/simple/test_preds.p.copa\n",
            "##### hf_datasets_tasks_download, task_name:  wic , task_data_path:  /content/jiant-rev/exp/tasks/data/wic\n",
            "##### load_dataset(), path= super_glue , name= wic\n",
            "##### is_ko_model :  True\n",
            "Using custom data configuration default-84f2f5bdc2a05f59\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-84f2f5bdc2a05f59/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n",
            "100% 3/3 [00:00<00:00, 10837.99it/s]\n",
            "100% 3/3 [00:00<00:00, 1220.22it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-84f2f5bdc2a05f59/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 694.69it/s]\n",
            "Downloaded and generated configs for 'wic' (1/1)\n",
            "##### run_simple(): Tokenizing Task 'wic' for phases 'train,val,test'\n",
            "WiCTask\n",
            "  [train]: /content/jiant-rev/exp/tasks/data/wic/train.jsonl\n",
            "  [val]: /content/jiant-rev/exp/tasks/data/wic/val.jsonl\n",
            "  [test]: /content/jiant-rev/exp/tasks/data/wic/test.jsonl\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "Tokenizing:   0% 0/7748 [00:00<?, ?it/s]Project (20, 23) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   1% 63/7748 [00:00<00:12, 622.68it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (18, 20) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   2% 130/7748 [00:00<00:11, 647.40it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:   3% 195/7748 [00:00<00:12, 613.55it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   3% 257/7748 [00:00<00:12, 613.97it/s]Project (3, 6) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (24, 27) into empty span in target sequence\n",
            "Tokenizing:   4% 322/7748 [00:00<00:11, 624.62it/s]Project (17, 20) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   5% 385/7748 [00:00<00:12, 572.54it/s]Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Project (6, 8) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   6% 448/7748 [00:00<00:12, 588.31it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   7% 508/7748 [00:00<00:12, 580.77it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   7% 567/7748 [00:00<00:12, 579.34it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (18, 19) into empty span in target sequence\n",
            "Project (34, 36) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (13, 15) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   8% 633/7748 [00:01<00:11, 602.53it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (6, 9) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   9% 698/7748 [00:01<00:11, 611.94it/s]Project (2, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  10% 769/7748 [00:01<00:10, 640.90it/s]Project (11, 13) into empty span in target sequence\n",
            "Project (13, 14) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  11% 834/7748 [00:01<00:11, 622.27it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  12% 897/7748 [00:01<00:11, 602.21it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (19, 21) into empty span in target sequence\n",
            "Tokenizing:  12% 958/7748 [00:01<00:11, 598.36it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  13% 1019/7748 [00:01<00:11, 591.29it/s]Project (20, 22) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Tokenizing:  14% 1081/7748 [00:01<00:11, 597.51it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (7, 10) into empty span in target sequence\n",
            "Tokenizing:  15% 1142/7748 [00:01<00:11, 600.53it/s]Project (21, 23) into empty span in target sequence\n",
            "Project (21, 23) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  16% 1211/7748 [00:01<00:10, 623.93it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  16% 1277/7748 [00:02<00:10, 633.58it/s]Project (18, 20) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  17% 1341/7748 [00:02<00:10, 603.15it/s]Project (38, 39) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (45, 47) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  18% 1404/7748 [00:02<00:10, 608.70it/s]Project (6, 7) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (12, 13) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  19% 1466/7748 [00:02<00:10, 609.87it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (26, 28) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  20% 1528/7748 [00:02<00:10, 577.16it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (44, 46) into empty span in target sequence\n",
            "Project (16, 17) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  21% 1590/7748 [00:02<00:10, 588.69it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (41, 42) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  21% 1659/7748 [00:02<00:09, 615.47it/s]Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Tokenizing:  22% 1721/7748 [00:02<00:10, 602.28it/s]Project (3, 5) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (6, 8) into empty span in target sequence\n",
            "Tokenizing:  23% 1782/7748 [00:02<00:10, 593.50it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  24% 1847/7748 [00:03<00:09, 608.52it/s]Project (31, 33) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (27, 30) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (18, 19) into empty span in target sequence\n",
            "Tokenizing:  25% 1909/7748 [00:03<00:09, 603.44it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  25% 1973/7748 [00:03<00:09, 613.68it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (31, 33) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  26% 2043/7748 [00:03<00:08, 636.97it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (16, 19) into empty span in target sequence\n",
            "Project (10, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (19, 20) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (31, 33) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  27% 2107/7748 [00:03<00:09, 604.17it/s]Project (32, 33) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  28% 2172/7748 [00:03<00:09, 616.52it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (16, 18) into empty span in target sequence\n",
            "Project (19, 21) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  29% 2237/7748 [00:03<00:08, 625.70it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  30% 2300/7748 [00:03<00:09, 604.77it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Tokenizing:  31% 2366/7748 [00:03<00:08, 618.55it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  31% 2429/7748 [00:03<00:08, 619.06it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (32, 35) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  32% 2492/7748 [00:04<00:08, 617.83it/s]Project (2, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  33% 2559/7748 [00:04<00:08, 632.84it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (23, 26) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  34% 2623/7748 [00:04<00:08, 614.48it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (7, 9) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (32, 33) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Tokenizing:  35% 2692/7748 [00:04<00:07, 634.46it/s]Project (34, 36) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (10, 12) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  36% 2758/7748 [00:04<00:07, 641.11it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (10, 12) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  36% 2823/7748 [00:04<00:07, 628.25it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (7, 8) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (5, 7) into empty span in target sequence\n",
            "Project (24, 26) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  37% 2889/7748 [00:04<00:07, 635.30it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  38% 2961/7748 [00:04<00:07, 657.85it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (26, 27) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  39% 3027/7748 [00:04<00:07, 655.37it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (32, 34) into empty span in target sequence\n",
            "Project (11, 12) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (5, 6) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (7, 10) into empty span in target sequence\n",
            "Tokenizing:  40% 3093/7748 [00:05<00:07, 654.33it/s]Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (20, 22) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  41% 3162/7748 [00:05<00:06, 664.30it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (27, 29) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Tokenizing:  42% 3229/7748 [00:05<00:07, 641.54it/s]Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  43% 3298/7748 [00:05<00:06, 653.68it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (98, 99) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  43% 3364/7748 [00:05<00:08, 521.32it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (7, 9) into empty span in target sequence\n",
            "Tokenizing:  44% 3421/7748 [00:05<00:13, 320.27it/s]Project (139, 141) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  45% 3466/7748 [00:06<00:15, 268.56it/s]Project (56, 57) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  45% 3503/7748 [00:06<00:19, 223.06it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  46% 3533/7748 [00:06<00:22, 190.54it/s]Project (76, 77) into empty span in target sequence\n",
            "Tokenizing:  46% 3558/7748 [00:06<00:22, 183.43it/s]Project (56, 57) into empty span in target sequence\n",
            "Tokenizing:  46% 3580/7748 [00:06<00:22, 182.11it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  46% 3602/7748 [00:07<00:22, 188.22it/s]Project (78, 79) into empty span in target sequence\n",
            "Tokenizing:  47% 3623/7748 [00:07<00:21, 188.82it/s]Project (65, 68) into empty span in target sequence\n",
            "Project (27, 30) into empty span in target sequence\n",
            "Tokenizing:  47% 3644/7748 [00:07<00:22, 184.90it/s]Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  47% 3664/7748 [00:07<00:22, 178.70it/s]Project (67, 68) into empty span in target sequence\n",
            "Tokenizing:  48% 3683/7748 [00:07<00:23, 175.19it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  48% 3701/7748 [00:07<00:24, 162.63it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  49% 3776/7748 [00:08<00:26, 150.73it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  49% 3812/7748 [00:08<00:26, 147.18it/s]Project (204, 205) into empty span in target sequence\n",
            "Project (42, 43) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  50% 3847/7748 [00:08<00:26, 149.03it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  50% 3864/7748 [00:08<00:25, 154.35it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  50% 3902/7748 [00:08<00:23, 167.16it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  51% 3921/7748 [00:09<00:22, 172.63it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  51% 3977/7748 [00:09<00:21, 173.68it/s]Project (39, 40) into empty span in target sequence\n",
            "Tokenizing:  52% 3995/7748 [00:09<00:25, 149.22it/s]Project (21, 22) into empty span in target sequence\n",
            "Project (135, 136) into empty span in target sequence\n",
            "Tokenizing:  52% 4011/7748 [00:09<00:25, 148.03it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  52% 4042/7748 [00:09<00:26, 142.35it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  53% 4072/7748 [00:10<00:30, 119.05it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  54% 4159/7748 [00:10<00:25, 140.97it/s]Project (144, 145) into empty span in target sequence\n",
            "Tokenizing:  54% 4174/7748 [00:10<00:27, 132.17it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  55% 4236/7748 [00:11<00:24, 144.11it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  55% 4251/7748 [00:11<00:27, 128.42it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  55% 4299/7748 [00:11<00:25, 136.47it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  56% 4324/7748 [00:11<00:20, 165.66it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  56% 4345/7748 [00:12<00:19, 176.23it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  56% 4363/7748 [00:12<00:19, 173.33it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  57% 4381/7748 [00:12<00:20, 164.65it/s]Project (196, 198) into empty span in target sequence\n",
            "Tokenizing:  57% 4398/7748 [00:12<00:21, 155.10it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  57% 4414/7748 [00:12<00:26, 124.02it/s]Project (75, 76) into empty span in target sequence\n",
            "Tokenizing:  57% 4431/7748 [00:12<00:25, 132.45it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  58% 4469/7748 [00:12<00:21, 155.16it/s]Project (82, 83) into empty span in target sequence\n",
            "Tokenizing:  58% 4503/7748 [00:13<00:21, 151.54it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  58% 4522/7748 [00:13<00:20, 161.25it/s]Project (67, 68) into empty span in target sequence\n",
            "Tokenizing:  59% 4559/7748 [00:13<00:19, 164.36it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  60% 4648/7748 [00:14<00:20, 152.59it/s]Project (91, 92) into empty span in target sequence\n",
            "Tokenizing:  61% 4703/7748 [00:14<00:19, 159.11it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  61% 4723/7748 [00:14<00:17, 169.65it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  61% 4741/7748 [00:14<00:21, 141.09it/s]Project (88, 89) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  62% 4781/7748 [00:14<00:18, 164.42it/s]Project (57, 59) into empty span in target sequence\n",
            "Tokenizing:  62% 4836/7748 [00:15<00:18, 158.06it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  63% 4878/7748 [00:15<00:16, 171.08it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  64% 4933/7748 [00:15<00:17, 165.17it/s]Project (60, 61) into empty span in target sequence\n",
            "Project (100, 101) into empty span in target sequence\n",
            "Tokenizing:  64% 4967/7748 [00:16<00:17, 158.13it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (36, 37) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  65% 5009/7748 [00:16<00:15, 172.29it/s]Project (1, 2) into empty span in target sequence\n",
            "Project (64, 65) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  65% 5031/7748 [00:16<00:14, 185.03it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  65% 5050/7748 [00:16<00:15, 175.70it/s]Project (84, 85) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  66% 5137/7748 [00:17<00:17, 152.96it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  67% 5153/7748 [00:17<00:17, 144.33it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  67% 5171/7748 [00:17<00:16, 152.03it/s]Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  67% 5194/7748 [00:17<00:14, 172.01it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  67% 5212/7748 [00:17<00:17, 146.54it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  67% 5228/7748 [00:17<00:18, 135.34it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (55, 56) into empty span in target sequence\n",
            "Tokenizing:  69% 5312/7748 [00:18<00:16, 147.75it/s]Project (15, 16) into empty span in target sequence\n",
            "Tokenizing:  69% 5335/7748 [00:18<00:14, 168.13it/s]Project (70, 71) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  69% 5369/7748 [00:18<00:16, 140.89it/s]Project (22, 23) into empty span in target sequence\n",
            "Tokenizing:  70% 5393/7748 [00:18<00:14, 165.31it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  70% 5411/7748 [00:19<00:16, 144.39it/s]Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  70% 5427/7748 [00:19<00:15, 147.01it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  71% 5524/7748 [00:19<00:15, 146.57it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (82, 83) into empty span in target sequence\n",
            "Project (11, 12) into empty span in target sequence\n",
            "Project (165, 166) into empty span in target sequence\n",
            "Tokenizing:  71% 5539/7748 [00:19<00:15, 144.73it/s]Project (91, 92) into empty span in target sequence\n",
            "Tokenizing:  72% 5554/7748 [00:20<00:15, 145.19it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  72% 5584/7748 [00:20<00:17, 126.90it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  72% 5600/7748 [00:20<00:16, 132.51it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  73% 5649/7748 [00:20<00:16, 130.65it/s]Project (34, 36) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  73% 5669/7748 [00:20<00:14, 142.26it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (52, 53) into empty span in target sequence\n",
            "Project (157, 160) into empty span in target sequence\n",
            "Tokenizing:  73% 5693/7748 [00:20<00:12, 167.62it/s]Project (132, 133) into empty span in target sequence\n",
            "Tokenizing:  74% 5711/7748 [00:21<00:12, 169.10it/s]Project (51, 52) into empty span in target sequence\n",
            "Project (204, 205) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  74% 5729/7748 [00:21<00:12, 167.73it/s]Project (6, 7) into empty span in target sequence\n",
            "Tokenizing:  74% 5746/7748 [00:21<00:12, 165.96it/s]Project (77, 80) into empty span in target sequence\n",
            "Tokenizing:  75% 5781/7748 [00:21<00:13, 141.35it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  75% 5831/7748 [00:21<00:12, 150.16it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (67, 68) into empty span in target sequence\n",
            "Tokenizing:  75% 5847/7748 [00:22<00:12, 147.48it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  76% 5863/7748 [00:22<00:13, 143.31it/s]Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  76% 5878/7748 [00:22<00:14, 127.85it/s]Project (47, 49) into empty span in target sequence\n",
            "Tokenizing:  77% 5936/7748 [00:22<00:11, 156.65it/s]Project (51, 54) into empty span in target sequence\n",
            "Tokenizing:  77% 5953/7748 [00:22<00:11, 150.52it/s]Project (31, 32) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  77% 5969/7748 [00:22<00:11, 150.16it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  77% 5985/7748 [00:22<00:13, 134.00it/s]Project (51, 52) into empty span in target sequence\n",
            "Tokenizing:  78% 6022/7748 [00:23<00:11, 154.30it/s]Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  78% 6038/7748 [00:23<00:11, 151.62it/s]Project (29, 30) into empty span in target sequence\n",
            "Project (85, 86) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (39, 40) into empty span in target sequence\n",
            "Project (12, 15) into empty span in target sequence\n",
            "Tokenizing:  79% 6133/7748 [00:24<00:11, 135.70it/s]Project (103, 106) into empty span in target sequence\n",
            "Tokenizing:  80% 6165/7748 [00:24<00:11, 131.94it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  80% 6186/7748 [00:24<00:10, 151.21it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  80% 6202/7748 [00:24<00:11, 140.52it/s]Project (18, 19) into empty span in target sequence\n",
            "Tokenizing:  81% 6260/7748 [00:24<00:10, 136.68it/s]Project (27, 28) into empty span in target sequence\n",
            "Tokenizing:  81% 6275/7748 [00:25<00:10, 138.30it/s]Project (78, 79) into empty span in target sequence\n",
            "Tokenizing:  82% 6368/7748 [00:25<00:10, 136.57it/s]Project (179, 180) into empty span in target sequence\n",
            "Tokenizing:  83% 6395/7748 [00:26<00:13, 103.63it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  83% 6448/7748 [00:26<00:09, 138.63it/s]Project (71, 72) into empty span in target sequence\n",
            "Tokenizing:  83% 6466/7748 [00:26<00:08, 146.32it/s]Project (13, 14) into empty span in target sequence\n",
            "Tokenizing:  84% 6485/7748 [00:26<00:08, 155.89it/s]Project (24, 27) into empty span in target sequence\n",
            "Tokenizing:  84% 6501/7748 [00:26<00:08, 151.64it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (78, 79) into empty span in target sequence\n",
            "Tokenizing:  84% 6517/7748 [00:26<00:08, 138.16it/s]Project (6, 7) into empty span in target sequence\n",
            "Project (99, 102) into empty span in target sequence\n",
            "Tokenizing:  85% 6570/7748 [00:27<00:08, 142.22it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  85% 6586/7748 [00:27<00:07, 145.25it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  85% 6603/7748 [00:27<00:07, 149.31it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  85% 6619/7748 [00:27<00:07, 152.14it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  86% 6636/7748 [00:27<00:07, 151.39it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  86% 6675/7748 [00:27<00:06, 169.02it/s]Project (109, 111) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  87% 6710/7748 [00:28<00:07, 144.52it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  87% 6750/7748 [00:28<00:06, 164.68it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (179, 180) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  88% 6783/7748 [00:28<00:06, 139.86it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (39, 40) into empty span in target sequence\n",
            "Project (109, 111) into empty span in target sequence\n",
            "Tokenizing:  88% 6843/7748 [00:29<00:06, 130.59it/s]Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  89% 6866/7748 [00:29<00:05, 154.96it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  90% 6937/7748 [00:29<00:04, 162.52it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  90% 6954/7748 [00:29<00:05, 151.82it/s]Project (19, 20) into empty span in target sequence\n",
            "Tokenizing:  90% 6988/7748 [00:29<00:05, 142.91it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  91% 7021/7748 [00:30<00:05, 132.32it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  91% 7039/7748 [00:30<00:05, 137.54it/s]Project (52, 53) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  91% 7068/7748 [00:30<00:04, 136.16it/s]Project (20, 21) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  91% 7086/7748 [00:30<00:04, 146.55it/s]Project (1, 2) into empty span in target sequence\n",
            "Tokenizing:  92% 7101/7748 [00:30<00:04, 143.72it/s]Project (26, 28) into empty span in target sequence\n",
            "Tokenizing:  92% 7120/7748 [00:30<00:04, 156.34it/s]Project (31, 32) into empty span in target sequence\n",
            "Project (49, 50) into empty span in target sequence\n",
            "Tokenizing:  92% 7136/7748 [00:30<00:04, 146.35it/s]Project (54, 55) into empty span in target sequence\n",
            "Tokenizing:  92% 7151/7748 [00:31<00:04, 128.22it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  92% 7165/7748 [00:31<00:05, 116.35it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  93% 7188/7748 [00:31<00:03, 143.80it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  93% 7204/7748 [00:31<00:03, 145.05it/s]Project (16, 17) into empty span in target sequence\n",
            "Project (107, 108) into empty span in target sequence\n",
            "Tokenizing:  93% 7236/7748 [00:31<00:03, 148.06it/s]Project (12, 13) into empty span in target sequence\n",
            "Tokenizing:  94% 7256/7748 [00:31<00:03, 160.47it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (125, 126) into empty span in target sequence\n",
            "Project (42, 43) into empty span in target sequence\n",
            "Tokenizing:  94% 7292/7748 [00:32<00:02, 164.06it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  95% 7328/7748 [00:32<00:02, 161.10it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  95% 7381/7748 [00:32<00:02, 166.02it/s]Project (30, 31) into empty span in target sequence\n",
            "Tokenizing:  95% 7398/7748 [00:32<00:02, 144.54it/s]Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  96% 7418/7748 [00:32<00:02, 151.91it/s]Project (1, 2) into empty span in target sequence\n",
            "Project (84, 85) into empty span in target sequence\n",
            "Tokenizing:  96% 7434/7748 [00:32<00:02, 147.46it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (139, 141) into empty span in target sequence\n",
            "Tokenizing:  97% 7482/7748 [00:33<00:01, 138.96it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  97% 7531/7748 [00:33<00:01, 138.56it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  98% 7590/7748 [00:34<00:01, 130.89it/s]Project (126, 127) into empty span in target sequence\n",
            "Tokenizing:  98% 7604/7748 [00:34<00:01, 124.70it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  98% 7619/7748 [00:34<00:00, 130.87it/s]Project (195, 196) into empty span in target sequence\n",
            "Project (55, 56) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  99% 7633/7748 [00:34<00:00, 130.09it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (39, 40) into empty span in target sequence\n",
            "Tokenizing:  99% 7652/7748 [00:34<00:00, 143.88it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  99% 7667/7748 [00:34<00:00, 142.40it/s]Project (165, 166) into empty span in target sequence\n",
            "Tokenizing:  99% 7682/7748 [00:34<00:00, 140.41it/s]Project (97, 98) into empty span in target sequence\n",
            "Tokenizing: 100% 7748/7748 [00:35<00:00, 219.89it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 7748/7748 [00:00<00:00, 96253.43it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:02<00:00,  2.09s/it]\n",
            "Tokenizing:   0% 0/1166 [00:00<?, ?it/s]Project (5, 7) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:   5% 64/1166 [00:00<00:01, 638.77it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (16, 19) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Tokenizing:  11% 128/1166 [00:00<00:01, 559.91it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (12, 14) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  17% 195/1166 [00:00<00:01, 606.50it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  22% 258/1166 [00:00<00:01, 611.83it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (1, 2) into empty span in target sequence\n",
            "Project (17, 19) into empty span in target sequence\n",
            "Tokenizing:  27% 320/1166 [00:00<00:01, 594.63it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (11, 12) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (19, 21) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  33% 388/1166 [00:00<00:01, 618.61it/s]Project (21, 22) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Tokenizing:  40% 464/1166 [00:00<00:01, 662.02it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 13) into empty span in target sequence\n",
            "Tokenizing:  46% 531/1166 [00:00<00:00, 640.20it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  52% 601/1166 [00:00<00:00, 657.81it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (21, 23) into empty span in target sequence\n",
            "Project (51, 52) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (51, 52) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (65, 68) into empty span in target sequence\n",
            "Project (79, 80) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  57% 668/1166 [00:01<00:01, 371.90it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (47, 48) into empty span in target sequence\n",
            "Tokenizing:  62% 720/1166 [00:01<00:01, 244.66it/s]Project (51, 52) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  65% 760/1166 [00:02<00:02, 194.82it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  68% 791/1166 [00:02<00:02, 154.34it/s]Project (41, 42) into empty span in target sequence\n",
            "Tokenizing:  70% 815/1166 [00:02<00:02, 148.86it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  72% 836/1166 [00:02<00:02, 144.64it/s]Project (94, 95) into empty span in target sequence\n",
            "Tokenizing:  77% 893/1166 [00:03<00:01, 141.60it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  78% 910/1166 [00:03<00:01, 146.23it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (51, 52) into empty span in target sequence\n",
            "Tokenizing:  84% 978/1166 [00:03<00:01, 144.63it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  85% 994/1166 [00:03<00:01, 134.63it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  87% 1012/1166 [00:04<00:01, 141.74it/s]Project (26, 27) into empty span in target sequence\n",
            "Tokenizing:  89% 1043/1166 [00:04<00:00, 147.19it/s]Project (26, 27) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  91% 1058/1166 [00:04<00:00, 137.12it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  92% 1074/1166 [00:04<00:00, 142.42it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  95% 1103/1166 [00:04<00:00, 123.06it/s]Project (39, 40) into empty span in target sequence\n",
            "Tokenizing:  96% 1121/1166 [00:04<00:00, 135.77it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  97% 1135/1166 [00:04<00:00, 133.89it/s]Project (46, 47) into empty span in target sequence\n",
            "Tokenizing:  99% 1153/1166 [00:05<00:00, 144.35it/s]Project (1, 2) into empty span in target sequence\n",
            "Tokenizing: 100% 1166/1166 [00:05<00:00, 225.88it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 1166/1166 [00:00<00:00, 91841.47it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  3.38it/s]\n",
            "Tokenizing:   0% 0/1246 [00:00<?, ?it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (29, 31) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (26, 27) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (17, 18) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (25, 27) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:   6% 77/1246 [00:00<00:01, 758.17it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  12% 153/1246 [00:00<00:01, 665.25it/s]Project (25, 26) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Tokenizing:  18% 221/1246 [00:00<00:01, 669.90it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  23% 289/1246 [00:00<00:01, 672.49it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  29% 357/1246 [00:00<00:01, 656.80it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  35% 436/1246 [00:00<00:01, 700.10it/s]Project (3, 5) into empty span in target sequence\n",
            "Project (3, 5) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (23, 24) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  41% 507/1246 [00:00<00:01, 669.70it/s]Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (11, 12) into empty span in target sequence\n",
            "Tokenizing:  46% 575/1246 [00:00<00:01, 659.15it/s]Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Tokenizing:  52% 642/1246 [00:00<00:00, 650.94it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (6, 7) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (0, 1) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Project (147, 150) into empty span in target sequence\n",
            "Tokenizing:  57% 708/1246 [00:01<00:00, 559.04it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Project (26, 27) into empty span in target sequence\n",
            "Tokenizing:  62% 767/1246 [00:01<00:01, 329.44it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (55, 56) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  65% 813/1246 [00:01<00:01, 221.14it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (31, 32) into empty span in target sequence\n",
            "Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  68% 848/1246 [00:02<00:02, 194.01it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  70% 877/1246 [00:02<00:02, 176.92it/s]Project (17, 18) into empty span in target sequence\n",
            "Project (77, 78) into empty span in target sequence\n",
            "Project (36, 37) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  72% 901/1246 [00:02<00:01, 184.57it/s]Project (102, 103) into empty span in target sequence\n",
            "Tokenizing:  80% 998/1246 [00:03<00:01, 147.79it/s]Project (88, 89) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  82% 1016/1246 [00:03<00:01, 151.14it/s]Project (12, 13) into empty span in target sequence\n",
            "Tokenizing:  83% 1032/1246 [00:03<00:01, 126.41it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (139, 141) into empty span in target sequence\n",
            "Tokenizing:  84% 1046/1246 [00:03<00:01, 127.27it/s]Project (39, 40) into empty span in target sequence\n",
            "Project (34, 36) into empty span in target sequence\n",
            "Tokenizing:  85% 1064/1246 [00:03<00:01, 138.67it/s]Project (2, 3) into empty span in target sequence\n",
            "Tokenizing:  87% 1079/1246 [00:03<00:01, 134.75it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  89% 1111/1246 [00:04<00:00, 142.29it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  91% 1140/1246 [00:04<00:01, 100.98it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  93% 1157/1246 [00:04<00:00, 116.06it/s]Project (3, 4) into empty span in target sequence\n",
            "Tokenizing:  98% 1217/1246 [00:05<00:00, 117.89it/s]Project (3, 4) into empty span in target sequence\n",
            "Project (3, 4) into empty span in target sequence\n",
            "Tokenizing: 100% 1246/1246 [00:05<00:00, 232.27it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 1246/1246 [00:00<00:00, 101592.14it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  3.08it/s]\n",
            "Running from start\n",
            "  jiant_task_container_config_path: exp/run_configs/simple_config.json\n",
            "  output_dir: exp/runs/simple\n",
            "  hf_pretrained_model_name_or_path: monologg/koelectra-base-v3-discriminator\n",
            "  model_path: exp/models/electra/model/model.p\n",
            "  model_config_path: exp/models/electra/model/config.json\n",
            "  model_load_mode: from_transformers\n",
            "  do_train: True\n",
            "  do_val: True\n",
            "  do_save: False\n",
            "  do_save_last: False\n",
            "  do_save_best: False\n",
            "  write_val_preds: False\n",
            "  write_test_preds: True\n",
            "  eval_every_steps: 0\n",
            "  save_every_steps: 0\n",
            "  save_checkpoint_every_steps: 0\n",
            "  no_improvements_for_n_evals: 0\n",
            "  keep_checkpoint_when_done: False\n",
            "  force_overwrite: False\n",
            "  seed: -1\n",
            "  learning_rate: 1e-05\n",
            "  adam_epsilon: 1e-08\n",
            "  max_grad_norm: 1.0\n",
            "  optimizer_type: adam\n",
            "  no_cuda: False\n",
            "  fp16: False\n",
            "  fp16_opt_level: O1\n",
            "  local_rank: -1\n",
            "  server_ip: \n",
            "  server_port: \n",
            "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Using seed: 4030181030\n",
            "{\n",
            "  \"jiant_task_container_config_path\": \"exp/run_configs/simple_config.json\",\n",
            "  \"output_dir\": \"exp/runs/simple\",\n",
            "  \"hf_pretrained_model_name_or_path\": \"monologg/koelectra-base-v3-discriminator\",\n",
            "  \"model_path\": \"exp/models/electra/model/model.p\",\n",
            "  \"model_config_path\": \"exp/models/electra/model/config.json\",\n",
            "  \"model_load_mode\": \"from_transformers\",\n",
            "  \"do_train\": true,\n",
            "  \"do_val\": true,\n",
            "  \"do_save\": false,\n",
            "  \"do_save_last\": false,\n",
            "  \"do_save_best\": false,\n",
            "  \"write_val_preds\": false,\n",
            "  \"write_test_preds\": true,\n",
            "  \"eval_every_steps\": 0,\n",
            "  \"save_every_steps\": 0,\n",
            "  \"save_checkpoint_every_steps\": 0,\n",
            "  \"no_improvements_for_n_evals\": 0,\n",
            "  \"keep_checkpoint_when_done\": false,\n",
            "  \"force_overwrite\": false,\n",
            "  \"seed\": 4030181030,\n",
            "  \"learning_rate\": 1e-05,\n",
            "  \"adam_epsilon\": 1e-08,\n",
            "  \"max_grad_norm\": 1.0,\n",
            "  \"optimizer_type\": \"adam\",\n",
            "  \"no_cuda\": false,\n",
            "  \"fp16\": false,\n",
            "  \"fp16_opt_level\": \"O1\",\n",
            "  \"local_rank\": -1,\n",
            "  \"server_ip\": \"\",\n",
            "  \"server_port\": \"\"\n",
            "}\n",
            "1\n",
            "Creating Tasks:\n",
            "    wic (WiCTask): exp/tasks/configs/wic_config.json\n",
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "##### encoder_prefix: electra.\n",
            "##### k :  electra.embeddings.position_ids\n",
            "##### k :  electra.embeddings.word_embeddings.weight\n",
            "##### k :  electra.embeddings.position_embeddings.weight\n",
            "##### k :  electra.embeddings.token_type_embeddings.weight\n",
            "##### k :  electra.embeddings.LayerNorm.weight\n",
            "##### k :  electra.embeddings.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.bias\n",
            "##### k :  discriminator_predictions.dense.weight\n",
            "##### k :  discriminator_predictions.dense.bias\n",
            "##### k :  discriminator_predictions.dense_prediction.weight\n",
            "##### k :  discriminator_predictions.dense_prediction.bias\n",
            "No optimizer decay for:\n",
            "  encoder.embeddings.LayerNorm.weight\n",
            "  encoder.embeddings.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.attention.self.query.bias\n",
            "  encoder.encoder.layer.0.attention.self.key.bias\n",
            "  encoder.encoder.layer.0.attention.self.value.bias\n",
            "  encoder.encoder.layer.0.attention.output.dense.bias\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.intermediate.dense.bias\n",
            "  encoder.encoder.layer.0.output.dense.bias\n",
            "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.attention.self.query.bias\n",
            "  encoder.encoder.layer.1.attention.self.key.bias\n",
            "  encoder.encoder.layer.1.attention.self.value.bias\n",
            "  encoder.encoder.layer.1.attention.output.dense.bias\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.intermediate.dense.bias\n",
            "  encoder.encoder.layer.1.output.dense.bias\n",
            "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.attention.self.query.bias\n",
            "  encoder.encoder.layer.2.attention.self.key.bias\n",
            "  encoder.encoder.layer.2.attention.self.value.bias\n",
            "  encoder.encoder.layer.2.attention.output.dense.bias\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.intermediate.dense.bias\n",
            "  encoder.encoder.layer.2.output.dense.bias\n",
            "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.attention.self.query.bias\n",
            "  encoder.encoder.layer.3.attention.self.key.bias\n",
            "  encoder.encoder.layer.3.attention.self.value.bias\n",
            "  encoder.encoder.layer.3.attention.output.dense.bias\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.intermediate.dense.bias\n",
            "  encoder.encoder.layer.3.output.dense.bias\n",
            "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.attention.self.query.bias\n",
            "  encoder.encoder.layer.4.attention.self.key.bias\n",
            "  encoder.encoder.layer.4.attention.self.value.bias\n",
            "  encoder.encoder.layer.4.attention.output.dense.bias\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.intermediate.dense.bias\n",
            "  encoder.encoder.layer.4.output.dense.bias\n",
            "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.attention.self.query.bias\n",
            "  encoder.encoder.layer.5.attention.self.key.bias\n",
            "  encoder.encoder.layer.5.attention.self.value.bias\n",
            "  encoder.encoder.layer.5.attention.output.dense.bias\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.intermediate.dense.bias\n",
            "  encoder.encoder.layer.5.output.dense.bias\n",
            "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.attention.self.query.bias\n",
            "  encoder.encoder.layer.6.attention.self.key.bias\n",
            "  encoder.encoder.layer.6.attention.self.value.bias\n",
            "  encoder.encoder.layer.6.attention.output.dense.bias\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.intermediate.dense.bias\n",
            "  encoder.encoder.layer.6.output.dense.bias\n",
            "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.attention.self.query.bias\n",
            "  encoder.encoder.layer.7.attention.self.key.bias\n",
            "  encoder.encoder.layer.7.attention.self.value.bias\n",
            "  encoder.encoder.layer.7.attention.output.dense.bias\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.intermediate.dense.bias\n",
            "  encoder.encoder.layer.7.output.dense.bias\n",
            "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.attention.self.query.bias\n",
            "  encoder.encoder.layer.8.attention.self.key.bias\n",
            "  encoder.encoder.layer.8.attention.self.value.bias\n",
            "  encoder.encoder.layer.8.attention.output.dense.bias\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.intermediate.dense.bias\n",
            "  encoder.encoder.layer.8.output.dense.bias\n",
            "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.attention.self.query.bias\n",
            "  encoder.encoder.layer.9.attention.self.key.bias\n",
            "  encoder.encoder.layer.9.attention.self.value.bias\n",
            "  encoder.encoder.layer.9.attention.output.dense.bias\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.intermediate.dense.bias\n",
            "  encoder.encoder.layer.9.output.dense.bias\n",
            "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.attention.self.query.bias\n",
            "  encoder.encoder.layer.10.attention.self.key.bias\n",
            "  encoder.encoder.layer.10.attention.self.value.bias\n",
            "  encoder.encoder.layer.10.attention.output.dense.bias\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.intermediate.dense.bias\n",
            "  encoder.encoder.layer.10.output.dense.bias\n",
            "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.attention.self.query.bias\n",
            "  encoder.encoder.layer.11.attention.self.key.bias\n",
            "  encoder.encoder.layer.11.attention.self.value.bias\n",
            "  encoder.encoder.layer.11.attention.output.dense.bias\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.intermediate.dense.bias\n",
            "  encoder.encoder.layer.11.output.dense.bias\n",
            "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
            "  taskmodels_dict.wic.head.span_attention_extractor._global_attention._module.bias\n",
            "  taskmodels_dict.wic.head.classifier.bias\n",
            "Using AdamW\n",
            "##### do_train #####\n",
            "##### run_train_context() #####\n",
            "##### get_train_dataloader_dict() :  1\n",
            "Training: 100% 1454/1455 [08:57<00:00,  2.71it/s]\n",
            "Eval (wic, Val): 100% 16/16 [00:03<00:00,  5.11it/s]\n",
            "##### k, v.shape :  encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140128719200256)\n",
            "##### k, v.shape :  encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140131025551360)\n",
            "##### k, v.shape :  encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140131267117056)\n",
            "##### k, v.shape :  encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140128719204352)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720808960)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719210496)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131663085568)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719213568)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131667804160)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719216640)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131679600640)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719219712)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125969317888)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719222784)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719225856)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719228928)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140126304862208)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128719232000)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129884700672)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719244288)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719247360)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719250432)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125971677184)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719253504)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125974036480)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719256576)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125976395776)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719259648)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130086027264)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719262720)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719265792)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719268864)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130354462720)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128719271936)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130622898176)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720815104)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720818176)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720821248)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130088386560)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720824320)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130090745856)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720827392)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130093105152)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720830464)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131000385536)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720833536)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720836608)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720839680)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140131595976704)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720842752)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140131864412160)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720855040)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720858112)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720861184)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131002744832)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720864256)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131005104128)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720867328)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131007463424)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720870400)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132132847616)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720873472)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720876544)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720879616)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132401283072)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720882688)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140133034622976)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720894976)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720898048)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720901120)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132135206912)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720904192)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132137566208)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720907264)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132139925504)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720910336)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131706077184)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720913408)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720916480)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720919552)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140124828467200)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720922624)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140124895576064)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720934912)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720937984)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720941056)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140124837904384)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720944128)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140124905013248)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720947200)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131708436480)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720950272)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131710795776)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720953344)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720956416)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720959488)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140124956393472)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720962560)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140124968976384)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720974848)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720977920)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720980992)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140124965830656)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720984064)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140124978413568)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720987136)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131713155072)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720990208)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125023502336)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720993280)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720996352)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720999424)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125025861632)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721002496)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125036085248)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721014784)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721017856)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721020928)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125045522432)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721024000)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125164011520)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721027072)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125166370816)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721030144)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125168730112)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721033216)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721036288)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721039360)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125231120384)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721042432)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125291937792)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721054720)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721057792)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721060864)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125240557568)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721063936)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125301374976)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721067008)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125171089408)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721070080)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125173448704)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721073152)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721076224)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721079296)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125304520704)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721082368)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125359046656)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721094656)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721097728)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721100800)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125313957888)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721103872)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125368483840)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721106944)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125371629568)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721110016)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125373988864)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721113088)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721116160)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721119232)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125426155520)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721122304)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125438738432)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721134592)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721137664)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721140736)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125435592704)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721143808)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125448175616)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721146880)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125376348160)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721149952)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125378707456)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721153024)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721156096)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721159168)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125499555840)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721162240)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125566664704)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721174528)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721177600)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721180672)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125381066752)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721183744)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125508993024)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721186816)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125576101888)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721189888)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125627482112)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721192960)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721196032)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721199104)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125629841408)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721202176)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125640065024)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721214464)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721217536)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721220608)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140128719200256)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140131025551360)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140131267117056)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140128719204352)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720808960)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719210496)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131663085568)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719213568)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131667804160)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719216640)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131679600640)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719219712)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125969317888)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719222784)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719225856)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719228928)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140126304862208)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128719232000)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129884700672)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719244288)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719247360)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719250432)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125971677184)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719253504)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125974036480)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719256576)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125976395776)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719259648)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130086027264)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719262720)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719265792)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719268864)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130354462720)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128719271936)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130622898176)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720815104)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720818176)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720821248)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130088386560)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720824320)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130090745856)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720827392)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130093105152)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720830464)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131000385536)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720833536)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720836608)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720839680)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140131595976704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720842752)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140131864412160)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720855040)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720858112)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720861184)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131002744832)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720864256)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131005104128)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720867328)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131007463424)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720870400)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132132847616)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720873472)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720876544)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720879616)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132401283072)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720882688)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140133034622976)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720894976)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720898048)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720901120)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132135206912)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720904192)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132137566208)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720907264)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132139925504)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720910336)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131706077184)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720913408)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720916480)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720919552)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140124828467200)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720922624)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140124895576064)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720934912)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720937984)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720941056)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140124837904384)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720944128)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140124905013248)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720947200)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131708436480)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720950272)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131710795776)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720953344)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720956416)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720959488)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140124956393472)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720962560)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140124968976384)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720974848)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720977920)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720980992)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140124965830656)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720984064)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140124978413568)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720987136)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131713155072)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720990208)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125023502336)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720993280)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720996352)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720999424)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125025861632)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721002496)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125036085248)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721014784)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721017856)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721020928)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125045522432)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721024000)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125164011520)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721027072)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125166370816)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721030144)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125168730112)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721033216)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721036288)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721039360)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125231120384)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721042432)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125291937792)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721054720)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721057792)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721060864)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125240557568)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721063936)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125301374976)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721067008)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125171089408)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721070080)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125173448704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721073152)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721076224)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721079296)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125304520704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721082368)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125359046656)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721094656)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721097728)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721100800)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125313957888)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721103872)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125368483840)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721106944)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125371629568)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721110016)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125373988864)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721113088)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721116160)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721119232)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125426155520)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721122304)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125438738432)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721134592)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721137664)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721140736)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125435592704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721143808)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125448175616)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721146880)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125376348160)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721149952)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125378707456)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721153024)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721156096)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721159168)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125499555840)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721162240)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125566664704)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721174528)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721177600)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721180672)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125381066752)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721183744)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125508993024)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721186816)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125576101888)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721189888)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140125627482112)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721192960)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721196032)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721199104)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140125629841408)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721202176)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140125640065024)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721214464)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721217536)\n",
            "##### k, v.shape :  taskmodels_dict.wic.encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721220608)\n",
            "##### k, v.shape :  taskmodels_dict.wic.head.span_attention_extractor._global_attention._module.weight torch.Size([1, 768])\n",
            "##### unique_key :  ((1, 768), 140128721223680)\n",
            "##### k, v.shape :  taskmodels_dict.wic.head.span_attention_extractor._global_attention._module.bias torch.Size([1])\n",
            "##### unique_key :  ((1,), 140128719311872)\n",
            "##### k, v.shape :  taskmodels_dict.wic.head.classifier.weight torch.Size([2, 1536])\n",
            "##### unique_key :  ((2, 1536), 140128721226752)\n",
            "##### k, v.shape :  taskmodels_dict.wic.head.classifier.bias torch.Size([2])\n",
            "##### unique_key :  ((2,), 140128719313920)\n",
            "Eval (wic, Val): 100% 16/16 [00:03<00:00,  5.08it/s]\n",
            "Loading Best\n",
            "Eval (wic, Val): 100% 37/37 [00:07<00:00,  5.07it/s]\n",
            "{\n",
            "  \"aggregated\": 0.8104631217838765,\n",
            "  \"wic\": {\n",
            "    \"loss\": 0.4231454504502786,\n",
            "    \"metrics\": {\n",
            "      \"major\": 0.8104631217838765,\n",
            "      \"minor\": {\n",
            "        \"acc\": 0.8104631217838765\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "Eval (wic, Test): 100% 39/39 [00:09<00:00,  4.13it/s]\n",
            "test_task_list : ['wic']\n",
            "##### write_preds(), task_name:  wic 1246\n",
            "##### write_json to :  exp/runs/simple/test_preds.p.wic\n",
            "##### hf_datasets_tasks_download, task_name:  boolq , task_data_path:  /content/jiant-rev/exp/tasks/data/boolq\n",
            "##### load_dataset(), path= super_glue , name= boolq\n",
            "##### is_ko_model :  True\n",
            "Using custom data configuration default-a2d2e1e4afb0d488\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-a2d2e1e4afb0d488/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n",
            "100% 3/3 [00:00<00:00, 10255.02it/s]\n",
            "100% 3/3 [00:00<00:00, 1235.56it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-a2d2e1e4afb0d488/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 944.52it/s]\n",
            "Downloaded and generated configs for 'boolq' (1/1)\n",
            "##### run_simple(): Tokenizing Task 'boolq' for phases 'train,val,test'\n",
            "BoolQTask\n",
            "  [train]: /content/jiant-rev/exp/tasks/data/boolq/train.jsonl\n",
            "  [val]: /content/jiant-rev/exp/tasks/data/boolq/val.jsonl\n",
            "  [test]: /content/jiant-rev/exp/tasks/data/boolq/test.jsonl\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "Tokenizing: 100% 3665/3665 [00:03<00:00, 1179.42it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 3665/3665 [00:00<00:00, 103591.33it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:01<00:00,  1.19s/it]\n",
            "Tokenizing: 100% 700/700 [00:00<00:00, 1104.61it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 700/700 [00:00<00:00, 54481.59it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  3.95it/s]\n",
            "Tokenizing: 100% 704/704 [00:00<00:00, 1219.55it/s]\n",
            "Smart truncate chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Smart truncate chunk-datum: 100% 704/704 [00:00<00:00, 101060.65it/s]\n",
            "Smart truncate chunks: 100% 1/1 [00:00<00:00,  4.29it/s]\n",
            "Running from start\n",
            "  jiant_task_container_config_path: exp/run_configs/simple_config.json\n",
            "  output_dir: exp/runs/simple\n",
            "  hf_pretrained_model_name_or_path: monologg/koelectra-base-v3-discriminator\n",
            "  model_path: exp/models/electra/model/model.p\n",
            "  model_config_path: exp/models/electra/model/config.json\n",
            "  model_load_mode: from_transformers\n",
            "  do_train: True\n",
            "  do_val: True\n",
            "  do_save: False\n",
            "  do_save_last: False\n",
            "  do_save_best: False\n",
            "  write_val_preds: False\n",
            "  write_test_preds: True\n",
            "  eval_every_steps: 0\n",
            "  save_every_steps: 0\n",
            "  save_checkpoint_every_steps: 0\n",
            "  no_improvements_for_n_evals: 0\n",
            "  keep_checkpoint_when_done: False\n",
            "  force_overwrite: False\n",
            "  seed: -1\n",
            "  learning_rate: 1e-05\n",
            "  adam_epsilon: 1e-08\n",
            "  max_grad_norm: 1.0\n",
            "  optimizer_type: adam\n",
            "  no_cuda: False\n",
            "  fp16: False\n",
            "  fp16_opt_level: O1\n",
            "  local_rank: -1\n",
            "  server_ip: \n",
            "  server_port: \n",
            "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Using seed: 1288575560\n",
            "{\n",
            "  \"jiant_task_container_config_path\": \"exp/run_configs/simple_config.json\",\n",
            "  \"output_dir\": \"exp/runs/simple\",\n",
            "  \"hf_pretrained_model_name_or_path\": \"monologg/koelectra-base-v3-discriminator\",\n",
            "  \"model_path\": \"exp/models/electra/model/model.p\",\n",
            "  \"model_config_path\": \"exp/models/electra/model/config.json\",\n",
            "  \"model_load_mode\": \"from_transformers\",\n",
            "  \"do_train\": true,\n",
            "  \"do_val\": true,\n",
            "  \"do_save\": false,\n",
            "  \"do_save_last\": false,\n",
            "  \"do_save_best\": false,\n",
            "  \"write_val_preds\": false,\n",
            "  \"write_test_preds\": true,\n",
            "  \"eval_every_steps\": 0,\n",
            "  \"save_every_steps\": 0,\n",
            "  \"save_checkpoint_every_steps\": 0,\n",
            "  \"no_improvements_for_n_evals\": 0,\n",
            "  \"keep_checkpoint_when_done\": false,\n",
            "  \"force_overwrite\": false,\n",
            "  \"seed\": 1288575560,\n",
            "  \"learning_rate\": 1e-05,\n",
            "  \"adam_epsilon\": 1e-08,\n",
            "  \"max_grad_norm\": 1.0,\n",
            "  \"optimizer_type\": \"adam\",\n",
            "  \"no_cuda\": false,\n",
            "  \"fp16\": false,\n",
            "  \"fp16_opt_level\": \"O1\",\n",
            "  \"local_rank\": -1,\n",
            "  \"server_ip\": \"\",\n",
            "  \"server_port\": \"\"\n",
            "}\n",
            "1\n",
            "Creating Tasks:\n",
            "    boolq (BoolQTask): exp/tasks/configs/boolq_config.json\n",
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "##### AutoTokenizer.from_pretrained() #####\n",
            "##### encoder_prefix: electra.\n",
            "##### k :  electra.embeddings.position_ids\n",
            "##### k :  electra.embeddings.word_embeddings.weight\n",
            "##### k :  electra.embeddings.position_embeddings.weight\n",
            "##### k :  electra.embeddings.token_type_embeddings.weight\n",
            "##### k :  electra.embeddings.LayerNorm.weight\n",
            "##### k :  electra.embeddings.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.0.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.0.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.dense.weight\n",
            "##### k :  electra.encoder.layer.0.output.dense.bias\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.0.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.1.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.1.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.dense.weight\n",
            "##### k :  electra.encoder.layer.1.output.dense.bias\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.1.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.2.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.2.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.dense.weight\n",
            "##### k :  electra.encoder.layer.2.output.dense.bias\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.2.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.3.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.3.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.dense.weight\n",
            "##### k :  electra.encoder.layer.3.output.dense.bias\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.3.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.4.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.4.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.dense.weight\n",
            "##### k :  electra.encoder.layer.4.output.dense.bias\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.4.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.5.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.5.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.dense.weight\n",
            "##### k :  electra.encoder.layer.5.output.dense.bias\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.5.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.6.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.6.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.dense.weight\n",
            "##### k :  electra.encoder.layer.6.output.dense.bias\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.6.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.7.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.7.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.dense.weight\n",
            "##### k :  electra.encoder.layer.7.output.dense.bias\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.7.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.8.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.8.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.dense.weight\n",
            "##### k :  electra.encoder.layer.8.output.dense.bias\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.8.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.9.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.9.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.dense.weight\n",
            "##### k :  electra.encoder.layer.9.output.dense.bias\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.9.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.10.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.10.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.dense.weight\n",
            "##### k :  electra.encoder.layer.10.output.dense.bias\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.10.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.query.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.key.bias\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.weight\n",
            "##### k :  electra.encoder.layer.11.attention.self.value.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.weight\n",
            "##### k :  electra.encoder.layer.11.intermediate.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.dense.weight\n",
            "##### k :  electra.encoder.layer.11.output.dense.bias\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.weight\n",
            "##### k :  electra.encoder.layer.11.output.LayerNorm.bias\n",
            "##### k :  discriminator_predictions.dense.weight\n",
            "##### k :  discriminator_predictions.dense.bias\n",
            "##### k :  discriminator_predictions.dense_prediction.weight\n",
            "##### k :  discriminator_predictions.dense_prediction.bias\n",
            "No optimizer decay for:\n",
            "  encoder.embeddings.LayerNorm.weight\n",
            "  encoder.embeddings.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.attention.self.query.bias\n",
            "  encoder.encoder.layer.0.attention.self.key.bias\n",
            "  encoder.encoder.layer.0.attention.self.value.bias\n",
            "  encoder.encoder.layer.0.attention.output.dense.bias\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.0.intermediate.dense.bias\n",
            "  encoder.encoder.layer.0.output.dense.bias\n",
            "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.attention.self.query.bias\n",
            "  encoder.encoder.layer.1.attention.self.key.bias\n",
            "  encoder.encoder.layer.1.attention.self.value.bias\n",
            "  encoder.encoder.layer.1.attention.output.dense.bias\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.1.intermediate.dense.bias\n",
            "  encoder.encoder.layer.1.output.dense.bias\n",
            "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.attention.self.query.bias\n",
            "  encoder.encoder.layer.2.attention.self.key.bias\n",
            "  encoder.encoder.layer.2.attention.self.value.bias\n",
            "  encoder.encoder.layer.2.attention.output.dense.bias\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.2.intermediate.dense.bias\n",
            "  encoder.encoder.layer.2.output.dense.bias\n",
            "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.attention.self.query.bias\n",
            "  encoder.encoder.layer.3.attention.self.key.bias\n",
            "  encoder.encoder.layer.3.attention.self.value.bias\n",
            "  encoder.encoder.layer.3.attention.output.dense.bias\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.3.intermediate.dense.bias\n",
            "  encoder.encoder.layer.3.output.dense.bias\n",
            "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.attention.self.query.bias\n",
            "  encoder.encoder.layer.4.attention.self.key.bias\n",
            "  encoder.encoder.layer.4.attention.self.value.bias\n",
            "  encoder.encoder.layer.4.attention.output.dense.bias\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.4.intermediate.dense.bias\n",
            "  encoder.encoder.layer.4.output.dense.bias\n",
            "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.attention.self.query.bias\n",
            "  encoder.encoder.layer.5.attention.self.key.bias\n",
            "  encoder.encoder.layer.5.attention.self.value.bias\n",
            "  encoder.encoder.layer.5.attention.output.dense.bias\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.5.intermediate.dense.bias\n",
            "  encoder.encoder.layer.5.output.dense.bias\n",
            "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.attention.self.query.bias\n",
            "  encoder.encoder.layer.6.attention.self.key.bias\n",
            "  encoder.encoder.layer.6.attention.self.value.bias\n",
            "  encoder.encoder.layer.6.attention.output.dense.bias\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.6.intermediate.dense.bias\n",
            "  encoder.encoder.layer.6.output.dense.bias\n",
            "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.attention.self.query.bias\n",
            "  encoder.encoder.layer.7.attention.self.key.bias\n",
            "  encoder.encoder.layer.7.attention.self.value.bias\n",
            "  encoder.encoder.layer.7.attention.output.dense.bias\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.7.intermediate.dense.bias\n",
            "  encoder.encoder.layer.7.output.dense.bias\n",
            "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.attention.self.query.bias\n",
            "  encoder.encoder.layer.8.attention.self.key.bias\n",
            "  encoder.encoder.layer.8.attention.self.value.bias\n",
            "  encoder.encoder.layer.8.attention.output.dense.bias\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.8.intermediate.dense.bias\n",
            "  encoder.encoder.layer.8.output.dense.bias\n",
            "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.attention.self.query.bias\n",
            "  encoder.encoder.layer.9.attention.self.key.bias\n",
            "  encoder.encoder.layer.9.attention.self.value.bias\n",
            "  encoder.encoder.layer.9.attention.output.dense.bias\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.9.intermediate.dense.bias\n",
            "  encoder.encoder.layer.9.output.dense.bias\n",
            "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.attention.self.query.bias\n",
            "  encoder.encoder.layer.10.attention.self.key.bias\n",
            "  encoder.encoder.layer.10.attention.self.value.bias\n",
            "  encoder.encoder.layer.10.attention.output.dense.bias\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.10.intermediate.dense.bias\n",
            "  encoder.encoder.layer.10.output.dense.bias\n",
            "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.attention.self.query.bias\n",
            "  encoder.encoder.layer.11.attention.self.key.bias\n",
            "  encoder.encoder.layer.11.attention.self.value.bias\n",
            "  encoder.encoder.layer.11.attention.output.dense.bias\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "  encoder.encoder.layer.11.intermediate.dense.bias\n",
            "  encoder.encoder.layer.11.output.dense.bias\n",
            "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
            "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
            "  taskmodels_dict.boolq.head.dense.bias\n",
            "  taskmodels_dict.boolq.head.out_proj.bias\n",
            "Using AdamW\n",
            "##### do_train #####\n",
            "##### run_train_context() #####\n",
            "##### get_train_dataloader_dict() :  1\n",
            "Training: 100% 689/690 [04:49<00:00,  2.38it/s]\n",
            "Eval (boolq, Val): 100% 16/16 [00:04<00:00,  3.96it/s]\n",
            "##### k, v.shape :  encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140128719193600)\n",
            "##### k, v.shape :  encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140131159769088)\n",
            "##### k, v.shape :  encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140129568030720)\n",
            "##### k, v.shape :  encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140128719197696)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720821248)\n",
            "##### k, v.shape :  encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719203840)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130370977792)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719206912)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130488680448)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719209984)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130491039744)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719213056)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130493399040)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719216128)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719219200)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719222272)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130531672064)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128719225344)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140126512480256)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719237632)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719240704)\n",
            "##### k, v.shape :  encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719243776)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130495758336)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719246848)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140126521917440)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719249920)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129012285440)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719252992)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129014644736)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719256064)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719259136)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719262208)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129347829760)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128719265280)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129784037376)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719277568)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719280640)\n",
            "##### k, v.shape :  encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719283712)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129357266944)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719286784)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129793474560)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720827392)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129017004032)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720830464)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129019363328)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720833536)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720836608)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720839680)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130086027264)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720842752)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130388017152)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720855040)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720858112)\n",
            "##### k, v.shape :  encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720861184)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129021722624)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720864256)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130095464448)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720867328)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130397454336)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720870400)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130690007040)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720873472)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720876544)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720879616)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130692366336)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720882688)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140131403038720)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720894976)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720898048)\n",
            "##### k, v.shape :  encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720901120)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131412475904)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720904192)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131730194432)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720907264)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131732553728)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720910336)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131734913024)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720913408)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720916480)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720919552)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132032184320)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720922624)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140132334174208)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720934912)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720937984)\n",
            "##### k, v.shape :  encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720941056)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132041621504)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720944128)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132343611392)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720947200)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131737272320)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720950272)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131739631616)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720953344)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720956416)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720959488)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140133013651456)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720962560)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140133055594496)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720974848)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720977920)\n",
            "##### k, v.shape :  encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720980992)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140133023088640)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720984064)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140133065031680)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720987136)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130555789312)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720990208)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130558148608)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720993280)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720996352)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720999424)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130560507904)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721002496)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130589343744)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721014784)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721017856)\n",
            "##### k, v.shape :  encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721020928)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130569945088)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721024000)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130572304384)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721027072)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130598780928)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721030144)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130601140224)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721033216)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721036288)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721039360)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130622898176)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721042432)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130632335360)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721054720)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721057792)\n",
            "##### k, v.shape :  encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721060864)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130603499520)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721063936)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130605858816)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721067008)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130656452608)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721070080)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130658811904)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721073152)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721076224)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721079296)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130661171200)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721082368)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130757115904)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721094656)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721097728)\n",
            "##### k, v.shape :  encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721100800)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130670608384)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721103872)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130672967680)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721106944)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130766553088)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721110016)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130768912384)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721113088)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721116160)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721119232)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130790670336)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721122304)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130800107520)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721134592)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721137664)\n",
            "##### k, v.shape :  encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721140736)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130771271680)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721143808)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130773630976)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721146880)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130824224768)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721149952)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130826584064)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721153024)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721156096)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721159168)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130828943360)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721162240)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130857779200)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721174528)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721177600)\n",
            "##### k, v.shape :  encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721180672)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130838380544)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721183744)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130840739840)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721186816)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130867216384)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721189888)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130869575680)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721192960)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721196032)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721199104)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140131000385536)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721202176)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140131009822720)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721214464)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721217536)\n",
            "##### k, v.shape :  encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721220608)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.position_ids torch.Size([1, 512])\n",
            "##### unique_key :  ((1, 512), 140128719193600)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.word_embeddings.weight torch.Size([35000, 768])\n",
            "##### unique_key :  ((35000, 768), 140131159769088)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "##### unique_key :  ((512, 768), 140129568030720)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140128719197696)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720821248)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.embeddings.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719203840)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130370977792)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719206912)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130488680448)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719209984)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130491039744)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719213056)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130493399040)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719216128)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719219200)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719222272)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130531672064)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128719225344)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140126512480256)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719237632)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719240704)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719243776)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130495758336)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719246848)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140126521917440)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719249920)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129012285440)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719252992)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129014644736)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719256064)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719259136)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719262208)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140129347829760)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128719265280)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140129784037376)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719277568)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719280640)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719283712)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129357266944)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128719286784)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129793474560)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720827392)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129017004032)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720830464)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129019363328)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720833536)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720836608)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720839680)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130086027264)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720842752)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130388017152)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720855040)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720858112)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720861184)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140129021722624)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720864256)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130095464448)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720867328)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130397454336)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720870400)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130690007040)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720873472)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720876544)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720879616)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130692366336)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720882688)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140131403038720)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720894976)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720898048)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720901120)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131412475904)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720904192)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131730194432)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720907264)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131732553728)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720910336)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131734913024)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720913408)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720916480)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720919552)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140132032184320)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720922624)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140132334174208)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720934912)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720937984)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720941056)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132041621504)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720944128)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140132343611392)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720947200)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131737272320)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720950272)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140131739631616)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720953344)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720956416)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720959488)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140133013651456)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128720962560)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140133055594496)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720974848)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720977920)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720980992)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140133023088640)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720984064)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140133065031680)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720987136)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130555789312)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720990208)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130558148608)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720993280)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720996352)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128720999424)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130560507904)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721002496)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130589343744)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721014784)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721017856)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721020928)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130569945088)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721024000)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130572304384)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721027072)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130598780928)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721030144)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130601140224)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721033216)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721036288)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721039360)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130622898176)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721042432)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130632335360)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721054720)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721057792)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721060864)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130603499520)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721063936)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130605858816)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721067008)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130656452608)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721070080)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130658811904)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721073152)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721076224)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721079296)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130661171200)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721082368)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130757115904)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721094656)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721097728)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721100800)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130670608384)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721103872)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130672967680)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721106944)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130766553088)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721110016)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130768912384)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721113088)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721116160)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721119232)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130790670336)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721122304)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130800107520)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721134592)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721137664)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721140736)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130771271680)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721143808)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130773630976)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721146880)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130824224768)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721149952)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130826584064)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721153024)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721156096)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721159168)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140130828943360)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721162240)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140130857779200)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721174528)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721177600)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721180672)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130838380544)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721183744)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130840739840)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721186816)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130867216384)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721189888)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130869575680)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721192960)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721196032)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721199104)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "##### unique_key :  ((3072, 768), 140131000385536)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "##### unique_key :  ((3072,), 140128721202176)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "##### unique_key :  ((768, 3072), 140131009822720)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721214464)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721217536)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.encoder.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721220608)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.head.dense.weight torch.Size([768, 768])\n",
            "##### unique_key :  ((768, 768), 140130871934976)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.head.dense.bias torch.Size([768])\n",
            "##### unique_key :  ((768,), 140128721223680)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.head.out_proj.weight torch.Size([2, 768])\n",
            "##### unique_key :  ((2, 768), 140128721226752)\n",
            "##### k, v.shape :  taskmodels_dict.boolq.head.out_proj.bias torch.Size([2])\n",
            "##### unique_key :  ((2,), 140128719337472)\n",
            "Eval (boolq, Val): 100% 16/16 [00:04<00:00,  3.92it/s]\n",
            "Loading Best\n",
            "Eval (boolq, Val): 100% 22/22 [00:05<00:00,  3.92it/s]\n",
            "{\n",
            "  \"aggregated\": 0.7871428571428571,\n",
            "  \"boolq\": {\n",
            "    \"loss\": 0.48839491470293567,\n",
            "    \"metrics\": {\n",
            "      \"major\": 0.7871428571428571,\n",
            "      \"minor\": {\n",
            "        \"acc\": 0.7871428571428571\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "Eval (boolq, Test): 100% 22/22 [00:05<00:00,  3.91it/s]\n",
            "test_task_list : ['boolq']\n",
            "##### write_preds(), task_name:  boolq 704\n",
            "##### write_json to :  exp/runs/simple/test_preds.p.boolq\n",
            "task results added :  cola 1060\n",
            "task results added :  copa 500\n",
            "task results added :  wic 1246\n",
            "task results added :  boolq 704\n",
            "write to output_flle :  ./test_preds.p.ALL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhmDNEcqRn52",
        "outputId": "226735b9-91a1-4ce6-a7b8-45b1d3b41f12"
      },
      "source": [
        "!ls -l /content/jiant-rev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 216\n",
            "drwxr-xr-x 2 root root   4096 Nov  6 11:31 dataset\n",
            "drwxr-xr-x 7 root root   4096 Nov  6 11:35 exp\n",
            "drwxr-xr-x 9 root root   4096 Nov  6 11:35 jiant\n",
            "-rw-r--r-- 1 root root    989 Nov  6 11:31 merge_predict_all.py\n",
            "-rw-r--r-- 1 root root    623 Nov  6 11:31 predict_boolq.py\n",
            "-rw-r--r-- 1 root root    620 Nov  6 11:31 predict_cola.py\n",
            "-rw-r--r-- 1 root root    620 Nov  6 11:31 predict_copa.py\n",
            "-rw-r--r-- 1 root root    617 Nov  6 11:31 predict_wic.py\n",
            "-rw-r--r-- 1 root root   1393 Nov  6 11:31 README.md\n",
            "-rw-r--r-- 1 root root    419 Nov  6 11:34 requirements-no-torch.txt\n",
            "-rw-r--r-- 1 root root     96 Nov  6 11:31 requirements.txt\n",
            "-rw-r--r-- 1 root root 172701 Nov  6 12:09 test_preds.p.ALL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xHsYxRzx7Hc"
      },
      "source": [
        "#!python /content/format_check.py -p /content/jiant-rev/test_preds.p.ALL"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}